{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DevICHI Ablation bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBk71lC-6Nn0",
        "outputId": "d26d8e64-188e-45be-e3ca-f8c694acf7f7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun  3 06:52:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEG9iXoz6joq"
      },
      "source": [
        "# percentages dobe till\n",
        "# fraction:[0.30]\n",
        "# accuracy:[0.656]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqx9cKKKkqBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85bfe31-4379-4c86-aa33-e42d2c0c30c2"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!git checkout 896a0eb1fd861bc37097a9b669ebf4cb8d523de7\n",
        "%cd ..\n",
        "!git clone https://github.com/joyousprakhar/ICHI-dataset.git\n",
        "!cp -a ICHI-dataset/. transformers/\n",
        "%cd transformers/\n",
        "!mkdir examples/cadec/\n",
        "!mkdir examples/ichi/\n",
        "!pip install -r requirements.txt\n",
        "!pip install .\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 73980, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (276/276), done.\u001b[K\n",
            "remote: Total 73980 (delta 159), reused 159 (delta 52), pack-reused 73629\u001b[K\n",
            "Receiving objects: 100% (73980/73980), 57.15 MiB | 28.63 MiB/s, done.\n",
            "Resolving deltas: 100% (52550/52550), done.\n",
            "/content/transformers\n",
            "Note: checking out '896a0eb1fd861bc37097a9b669ebf4cb8d523de7'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 896a0eb1f Merge pull request #2459 from Perseus14/patch-4\n",
            "/content\n",
            "Cloning into 'ICHI-dataset'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 54 (delta 21), reused 42 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n",
            "/content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/cb/3e8902d528538972873d0e9e4e47a31d1849a98e057009e9d383637c96fb/tokenizers-0.0.11-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 8.8MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/7c/f7fadb2d3d001d6fb9b8aab6038520e8aab2bb174e2fdb98505df5bbff19/boto3-1.17.86-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 49.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.9MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.86\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/7b/6869c8e68929313a182ba3c1becfee65a7de4cf6d9e7f691fcb42baec8b2/botocore-1.20.86-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 51.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.86->boto3->-r requirements.txt (line 3)) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.86 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses\n",
            "Successfully installed boto3-1.17.86 botocore-1.20.86 jmespath-0.10.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.0.11\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.19.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.17.86)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.45)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.86 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.20.86)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.86->boto3->transformers==2.3.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp37-none-any.whl size=451173 sha256=c66f3bf5aacba1f46e1f32311e9a7b2ff2b9775c1362a054cb43be73c1c13b67\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y0or5175/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.3.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5w9d13N2Dnf"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"/content/transformers/data/ichi/train.tsv\",sep=\"\\t\")\n",
        "percentage = 1.0\n",
        "Classes = df_train.Category.unique()\n",
        "Classes\n",
        "df_final = pd.DataFrame(columns = ['Category','Title','Question','Concepts'])\n",
        "for i,cat in enumerate(Classes):\n",
        "  if i==0:\n",
        "    df_final = df_train[df_train[\"Category\"] == cat]\n",
        "    df_final = df_final.sample(frac=percentage)\n",
        "  else:\n",
        "    df_temp = df_train[df_train[\"Category\"] == cat]\n",
        "\n",
        "    # here random state is use as seed. See here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
        "    df_temp = df_temp.sample(frac=percentage, random_state=50)\n",
        "    frames = [df_final,df_temp]\n",
        "    df_final = pd.concat(frames)\n",
        "df_final = df_final.sample(frac=1)\n",
        "df_final.to_csv('/content/transformers/data/ichi/tmp_train.tsv',sep=\"\\t\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8-Y-1q5m2qR7",
        "outputId": "88a32602-fb7f-475a-b50d-e077f08de56d"
      },
      "source": [
        "df=pd.read_csv(\"/content/transformers/data/ichi/tmp_train.tsv\",sep=\"\\t\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Question</th>\n",
              "      <th>Concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FAML</td>\n",
              "      <td>11 year old on zoloft - headaches?</td>\n",
              "      <td>My son has been on zoloft for just over two mo...</td>\n",
              "      <td>allergy tests|scan|referred pain|pain|bronchit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>Surgical menopause</td>\n",
              "      <td>It has been a year since my TOTAL hysterectomy...</td>\n",
              "      <td>cracked nails|pain|vaginal|lot|back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PREG</td>\n",
              "      <td>Plan B After 22 Hours</td>\n",
              "      <td>my partner and me had sex and the condom broke...</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>Side Effects of Gardasil</td>\n",
              "      <td>My daughter is 15 and on Thurs June 5, 2008 sh...</td>\n",
              "      <td>bronchitis|said|Bronchitis|treatment|diagnosed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FAML</td>\n",
              "      <td>Child's Compulsive Need to be right by manufac...</td>\n",
              "      <td>We have a 12 yr old grandson that constantly f...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>FAML</td>\n",
              "      <td>odd behaviour</td>\n",
              "      <td>I have a friend and her two an a half year old...</td>\n",
              "      <td>hand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>FAML</td>\n",
              "      <td>7 year old son still poops in his pants daily</td>\n",
              "      <td>Hi, I have been having problems with my 7 year...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>Foot Pain.</td>\n",
              "      <td>Hi! I have a little question and I hope you ca...</td>\n",
              "      <td>massage|painful|pain|foot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Western Blot Test</td>\n",
              "      <td>Hi,I took a HSV test that was positive for HSV...</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>DISE</td>\n",
              "      <td>what i do now?</td>\n",
              "      <td>hi to all.i am 24 years old male.i am patient ...</td>\n",
              "      <td>hepatitis c|injections|liver|body</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                           Concepts\n",
              "0        FAML  ...  allergy tests|scan|referred pain|pain|bronchit...\n",
              "1        TRMT  ...                cracked nails|pain|vaginal|lot|back\n",
              "2        PREG  ...                                               back\n",
              "3        TRMT  ...  bronchitis|said|Bronchitis|treatment|diagnosed...\n",
              "4        FAML  ...                                                NaN\n",
              "...       ...  ...                                                ...\n",
              "7995     FAML  ...                                               hand\n",
              "7996     FAML  ...                                                NaN\n",
              "7997     SOCL  ...                          massage|painful|pain|foot\n",
              "7998     DISE  ...                                               back\n",
              "7999     DISE  ...                  hepatitis c|injections|liver|body\n",
              "\n",
              "[8000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D79M5NpS8vh"
      },
      "source": [
        "# ########### Uncomment it to download Glove Vectors\n",
        "\n",
        "# !curl -O -J -L http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-EzqBB_PvmT"
      },
      "source": [
        "# ########### Uncomment it to download BioASQ Embeddings\n",
        "\n",
        "# !curl -O -J -L http://bioasq.lip6.fr/tools/BioASQword2vec/\n",
        "# !tar -xvzf biomedicalWordVectors.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0KtyeJkv6Z"
      },
      "source": [
        "# class ICHIDataset(Dataset):\n",
        "#     def __init__(self, fname, tokenizer):\n",
        "#         fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#         lines = fin.readlines()\n",
        "#         fin.close()\n",
        "\n",
        "#         all_data = []\n",
        "#         for i in range(0, len(lines), 3):\n",
        "#             text_left, _, text_right = [s.lower().strip() for s in lines[i].partition(\"$T$\")]\n",
        "#             aspect = lines[i + 1].lower().strip()\n",
        "#             polarity = lines[i + 2].strip()\n",
        "\n",
        "#             text_raw_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
        "#             text_raw_without_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
        "#             text_left_indices = tokenizer.text_to_sequence(text_left)\n",
        "#             text_left_with_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
        "#             text_right_indices = tokenizer.text_to_sequence(text_right, reverse=True)\n",
        "#             text_right_with_aspect_indices = tokenizer.text_to_sequence(\" \" + aspect + \" \" + text_right, reverse=True)\n",
        "#             aspect_indices = tokenizer.text_to_sequence(aspect)\n",
        "#             left_context_len = np.sum(text_left_indices != 0)\n",
        "#             aspect_len = np.sum(aspect_indices != 0)\n",
        "#             aspect_in_text = torch.tensor([left_context_len.item(), (left_context_len + aspect_len - 1).item()])\n",
        "#             polarity = int(polarity) + 1\n",
        "\n",
        "#             text_bert_indices = tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
        "#             bert_segments_ids = np.asarray([0] * (np.sum(text_raw_indices != 0) + 2) + [1] * (aspect_len + 1))\n",
        "#             bert_segments_ids = pad_and_truncate(bert_segments_ids, tokenizer.max_seq_len)\n",
        "\n",
        "#             text_raw_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
        "#             aspect_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
        "\n",
        "#             data = {\n",
        "#                 'text_bert_indices': text_bert_indices,\n",
        "#                 'bert_segments_ids': bert_segments_ids,\n",
        "#                 'text_raw_bert_indices': text_raw_bert_indices,\n",
        "#                 'aspect_bert_indices': aspect_bert_indices,\n",
        "#                 'text_raw_indices': text_raw_indices,\n",
        "#                 'text_raw_without_aspect_indices': text_raw_without_aspect_indices,\n",
        "#                 'text_left_indices': text_left_indices,\n",
        "#                 'text_left_with_aspect_indices': text_left_with_aspect_indices,\n",
        "#                 'text_right_indices': text_right_indices,\n",
        "#                 'text_right_with_aspect_indices': text_right_with_aspect_indices,\n",
        "#                 'aspect_indices': aspect_indices,\n",
        "#                 'aspect_in_text': aspect_in_text,\n",
        "#                 'polarity': polarity,\n",
        "#             }\n",
        "\n",
        "#             all_data.append(data)\n",
        "#         self.data = all_data\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         return self.data[index]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8YjUsTm2Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47432220-b36c-404f-e538-1a80a703d648"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGkNpSjDrXjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba7ce7a-7c7e-45c3-afa3-0573f80116a7"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/utils_ichi.py\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "from transformers.file_utils import is_tf_available \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "if is_tf_available():\n",
        "    import tensorflow as tf\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def acc_and_f1(preds, labels):\n",
        "    acc = simple_accuracy(preds, labels)\n",
        "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    # return {\"acc\": simple_accuracy(preds, labels)}\n",
        "    return acc_and_f1(preds, labels)\n",
        "\n",
        "\n",
        "def pad_and_truncate(sequence, maxlen, dtype='int64', padding='pre', truncating='post', value=0):\n",
        "    x = (np.ones(maxlen) * value).astype(dtype)\n",
        "    if truncating == 'pre':\n",
        "        trunc = sequence[-maxlen:]\n",
        "    else:\n",
        "        trunc = sequence[:maxlen]\n",
        "    trunc = np.asarray(trunc, dtype=dtype)\n",
        "    if padding == 'post':\n",
        "        x[:len(trunc)] = trunc\n",
        "    else:\n",
        "        x[-len(trunc):] = trunc\n",
        "    return x\n",
        "\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, max_seq_len, max_num_words=None,lower=True):\n",
        "        self.lower = lower\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.word2idx = {}\n",
        "        self.word_freq = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx2word[0] = '<PAD>'\n",
        "        self.word2idx['<PAD>'] = 0\n",
        "        self.word_freq['<PAD>'] = 100000\n",
        "        self.idx = 1\n",
        "        self.max_num_words = max_num_words\n",
        "\n",
        "    def fit_on_text(self, text):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = self.idx\n",
        "                self.word_freq[word] = 1\n",
        "                self.idx2word[self.idx] = word\n",
        "                self.idx += 1\n",
        "            else:\n",
        "                self.word_freq[word] = self.word_freq[word] + 1\n",
        "    \n",
        "    def update_tokenizer(self):\n",
        "        if self.max_num_words == None:\n",
        "            return\n",
        "        elif self.max_num_words >= self.idx:\n",
        "            return \n",
        "        else:\n",
        "            del self.word_freq['<PAD>']\n",
        "            self.word_freq = {k: v for k, v in sorted(self.word_freq.items(), key=lambda item: item[1], reverse=True)}\n",
        "            self.word2idx = {}\n",
        "            self.idx2word = {}\n",
        "            self.idx2word[0] = '<PAD>'\n",
        "            self.word2idx['<PAD>'] = 0\n",
        "            self.idx = 1\n",
        "            for i, key in enumerate(self.word_freq):\n",
        "                if i >= self.max_num_words:\n",
        "                    break\n",
        "                else:\n",
        "                    self.word2idx[key] = i+1\n",
        "                    self.idx2word[i+1] = key\n",
        "                    self.idx += 1\n",
        "            self.word_freq['<PAD>'] = 100000\n",
        "\n",
        "\n",
        "\n",
        "    def fit_on_examples(self, examples):\n",
        "        is_tf_dataset = False\n",
        "        if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "            is_tf_dataset = True\n",
        "        processor = ICHIProcessor()\n",
        "        for example in examples:\n",
        "            if is_tf_dataset:\n",
        "                example = processor.get_example_from_tensor_dict(example)\n",
        "                example = processor.tfds_map(example)\n",
        "            self.fit_on_text(example.clean_text)\n",
        "\n",
        "    def text_to_sequence(self, text, reverse=False, padding='pre', truncating='post'):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        unknownidx = len(self.word2idx)+1\n",
        "        if (self.max_num_words == None) or (self.max_num_words >= self.idx):\n",
        "            sequence = [self.word2idx[w] if w in self.word2idx else unknownidx for w in words]\n",
        "        else:\n",
        "            sequence = []\n",
        "            for w in words:\n",
        "                if w in self.word2idx:\n",
        "                    if self.word2idx[w] > self.max_num_words:\n",
        "                        sequence.append(unknownidx)\n",
        "                    else:\n",
        "                        sequence.append(self.word2idx[w])\n",
        "                else:\n",
        "                    sequence.append(unknownidx)\n",
        "        if len(sequence) == 0:\n",
        "            sequence = [0]\n",
        "        if reverse:\n",
        "            sequence = sequence[::-1]\n",
        "        return pad_and_truncate(sequence, self.max_seq_len, padding=padding, truncating=truncating)\n",
        "\n",
        "def _load_word_vec_glove(path, word2idx=None):\n",
        "    fin = open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    word_vec = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split()\n",
        "        if word2idx is None or tokens[0] in word2idx.keys():\n",
        "            try:\n",
        "                word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')\n",
        "            except:\n",
        "                pass\n",
        "    return word_vec\n",
        "    \n",
        "def build_embedding_matrix_glove(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(glove): ', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(glove)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        fname = fname + '/glove.twitter.27B/glove.twitter.27B.' + str(embed_dim) + 'd.txt' \\\n",
        "            if embed_dim != 300 else fname + '/glove.840B.300d.txt'\n",
        "        word_vec = _load_word_vec_glove(fname, word2idx=word2idx)\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            vec = word_vec.get(word)\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def build_embedding_matrix_BioASQ(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(BioASQ):', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(BioASQ)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        f = open(fname + \"/word2vecTools/types.txt\",\"r\")\n",
        "        i = 0\n",
        "        names = []\n",
        "        for line in f:\n",
        "            names.append(line.split('\\n')[0])\n",
        "            i = i + 1\n",
        "        vectors = np.loadtxt(fname + \"/word2vecTools/vectors.txt\")\n",
        "        word_vec = {}\n",
        "        for (index, name) in enumerate(names):\n",
        "            word_vec[name] = index\n",
        "\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            if word in word_vec.keys():\n",
        "                vec = vectors[word_vec[word]]\n",
        "            else:\n",
        "                vec = None\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    tokenizer,\n",
        "    tokenizer_cleantext,\n",
        "    max_length=512,\n",
        "    task=None,\n",
        "    label_list=None,\n",
        "    output_mode=None,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a data file into a list of ``ICHI_InputFeatures``\n",
        "\n",
        "    Args:\n",
        "        examples: List of ``ICHI_InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
        "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
        "        tokenizer_cleantext: Instance of a tokenizer that will tokenize the examples clean text(used for our medical module) \n",
        "        max_length: Maximum example length\n",
        "        task: GLUE task\n",
        "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
        "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
        "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
        "        pad_token: Padding token\n",
        "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
        "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
        "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
        "            actual values)\n",
        "\n",
        "    Returns:\n",
        "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
        "        containing the task-specific features. If the input is a list of ``ICHI_InputExamples``, will return\n",
        "        a list of task-specific ``ICHI_InputFeatures`` which can be fed to the model.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    is_tf_dataset = False\n",
        "    if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "        is_tf_dataset = True\n",
        "\n",
        "    \"\"\"      Initialisation of Data Processor    \"\"\"\n",
        "    if task is not None:\n",
        "        processor = ICHIProcessor()  \n",
        "        if label_list is None:\n",
        "            label_list = processor.get_labels()\n",
        "            logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
        "        if output_mode is None:\n",
        "            output_mode = \"classification\"\n",
        "            logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    \"\"\"      Processing the examples    \"\"\"\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d/%d\" % (ex_index, len(examples)))\n",
        "        if is_tf_dataset:\n",
        "            example = processor.get_example_from_tensor_dict(example)\n",
        "            example = processor.tfds_map(example)\n",
        "        \"\"\"      Assuming that each aspect consist of max 4 tokens hence making sure that aspects total tokens coming from aspects are not greater than max sequence length    \"\"\"\n",
        "        aspect_present = bool(example.aspects is not None)\n",
        "        if aspect_present:\n",
        "            if 4 * len(example.aspects) > max_length:\n",
        "                example.aspects = random.sample(example.aspects, k = int(max_length/4))\n",
        "                \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the global features are encoded as [<special token> + text_tokens + <special token> + heading_tokens + <special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        inputs_global = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,) ######## edittttttt\n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the local features(medical module) are encoded as [<special token> + text_tokens + <special token>] \"\"\"\n",
        "        inputs_local = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,)\n",
        "        \"\"\" Generating tokens for the clean_text i.e. tokenising text based on glove or BioASQ \"\"\"\n",
        "        text_clean_indices = tokenizer_cleantext.text_to_sequence(example.clean_text)\n",
        "        \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the aspect_indices are encoded as [<special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        if len(example.aspects) > 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], example.aspects[2:], add_special_tokens=False, max_length=max_length,)\n",
        "        elif len(example.aspects) == 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], add_special_tokens=False, max_length=max_length,)\n",
        "        else:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], add_special_tokens=False, max_length=max_length,)\n",
        "        \n",
        "        input_global_ids, token_global_type_ids = inputs_global[\"input_ids\"], inputs_global[\"token_type_ids\"]\n",
        "        input_local_ids, token_local_type_ids = inputs_local[\"input_ids\"], inputs_local[\"token_type_ids\"]\n",
        "        \n",
        "        aspect_indices = aspect_indices[\"input_ids\"]\n",
        "        padding_length_aspect = max_length - len(aspect_indices)\n",
        "        aspect_indices = aspect_indices + ([pad_token] * padding_length_aspect)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask_global = [1 if mask_padding_with_zero else 0] * len(input_global_ids)\n",
        "        attention_mask_local = [1 if mask_padding_with_zero else 0] * len(input_local_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length_global = max_length - len(input_global_ids)\n",
        "        padding_length_local = max_length - len(input_local_ids)\n",
        "        if pad_on_left:\n",
        "            input_global_ids = ([pad_token] * padding_length_global) + input_global_ids\n",
        "            attention_mask_global = ([0 if mask_padding_with_zero else 1] * padding_length_global) + attention_mask_global\n",
        "            token_global_type_ids = ([pad_token_segment_id] * padding_length_global) + token_global_type_ids\n",
        "            input_local_ids = ([pad_token] * padding_length_local) + input_local_ids\n",
        "            attention_mask_local = ([0 if mask_padding_with_zero else 1] * padding_length_local) + attention_mask_local\n",
        "            token_local_type_ids = ([pad_token_segment_id] * padding_length_local) + token_local_type_ids\n",
        "        else:\n",
        "            input_global_ids = input_global_ids + ([pad_token] * padding_length_global)\n",
        "            attention_mask_global = attention_mask_global + ([0 if mask_padding_with_zero else 1] * padding_length_global)\n",
        "            token_global_type_ids = token_global_type_ids + ([pad_token_segment_id] * padding_length_global)\n",
        "            input_local_ids = input_local_ids + ([pad_token] * padding_length_local)\n",
        "            attention_mask_local = attention_mask_local + ([0 if mask_padding_with_zero else 1] * padding_length_local)\n",
        "            token_local_type_ids = token_local_type_ids + ([pad_token_segment_id] * padding_length_local)\n",
        "\n",
        "        assert len(input_global_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_global_ids), max_length)\n",
        "        assert len(input_local_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_local_ids), max_length)\n",
        "        assert len(attention_mask_global) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_global), max_length\n",
        "        )\n",
        "        assert len(attention_mask_local) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_local), max_length\n",
        "        )\n",
        "        assert len(token_global_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_global_type_ids), max_length\n",
        "        )\n",
        "        assert len(token_local_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_local_type_ids), max_length\n",
        "        )\n",
        "\n",
        "        if output_mode == \"classification\":\n",
        "            label = label_map[example.label]\n",
        "        elif output_mode == \"regression\":\n",
        "            label = float(example.label)\n",
        "        else:\n",
        "            raise KeyError(output_mode)\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"input_global_ids: %s\" % \" \".join([str(x) for x in input_global_ids]))\n",
        "            logger.info(\"attention_mask_global: %s\" % \" \".join([str(x) for x in attention_mask_global]))\n",
        "            logger.info(\"token_global_type_ids: %s\" % \" \".join([str(x) for x in token_global_type_ids]))\n",
        "            logger.info(\"input_local_ids: %s\" % \" \".join([str(x) for x in input_local_ids]))\n",
        "            logger.info(\"attention_mask_local: %s\" % \" \".join([str(x) for x in attention_mask_local]))\n",
        "            logger.info(\"token_local_type_ids: %s\" % \" \".join([str(x) for x in token_local_type_ids]))\n",
        "            logger.info(\"text_clean_indices: %s\" % \" \".join([str(x) for x in text_clean_indices]))\n",
        "            logger.info(\"aspect_indices: %s\" % \" \".join([str(x) for x in aspect_indices]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (example.label, label))\n",
        "\n",
        "        features.append(\n",
        "            ICHI_InputFeatures(\n",
        "                input_global_ids=input_global_ids, input_local_ids=input_local_ids, attention_mask_global=attention_mask_global, attention_mask_local=attention_mask_local,\n",
        "                token_global_type_ids=token_global_type_ids, token_local_type_ids=token_local_type_ids, text_clean_indices=text_clean_indices, aspect_indices=aspect_indices, label=label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if is_tf_available() and is_tf_dataset:\n",
        "\n",
        "        def gen():\n",
        "            for ex in features:\n",
        "                yield (\n",
        "                    {\n",
        "                        \"input_global_ids\": ex.input_global_ids,\n",
        "                        \"input_local_ids\": ex.input_local_ids,\n",
        "                        \"attention_mask_global\": ex.attention_mask_global,\n",
        "                        \"attention_mask_local\": ex.attention_mask_local,\n",
        "                        \"token_global_type_ids\": ex.token_global_type_ids,\n",
        "                        \"token_local_type_ids\": ex.token_local_type_ids,\n",
        "                        \"text_clean_indices\": ex.text_clean_indices,\n",
        "                        \"aspect_indices\": ex.aspect_indices,\n",
        "                    },\n",
        "                    ex.label,\n",
        "                )\n",
        "\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            gen,\n",
        "            ({\"input_global_ids\": tf.int32, \"input_local_ids\": tf.int32, \"attention_mask_global\": tf.int32, \"attention_mask_local\": tf.int32, \"token_global_type_ids\": tf.int32, \"token_local_type_ids\": tf.int32, \"text_clean_indices\": tf.int32, \"aspect_indices\": tf.int32}, tf.int64),\n",
        "            (\n",
        "                {\n",
        "                    \"input_global_ids\": tf.TensorShape([None]),\n",
        "                    \"input_local_ids\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_global\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_local\": tf.TensorShape([None]),\n",
        "                    \"token_global_type_ids\": tf.TensorShape([None]),\n",
        "                    \"token_local_type_ids\": tf.TensorShape([None]),\n",
        "                    \"text_clean_indices\": tf.TensorShape([None]),\n",
        "                    \"aspect_indices\": tf.TensorShape([None]),\n",
        "                },\n",
        "                tf.TensorShape([]),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    return features\n",
        "\n",
        "class ICHIProcessor(object):\n",
        "    \"\"\"Processor for the ICHI data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return ICHI_InputExample(tensor_dict['idx'].numpy(),\n",
        "                            tensor_dict['heading'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['clean_text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['aspects'].numpy().decode('utf-8'),\n",
        "                            str(tensor_dict['label'].numpy()))\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"tmp_train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")),\n",
        "            \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"DEMO\", \"DISE\", \"TRMT\", \"GOAL\", \"PREG\", \"FAML\", \"SOCL\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            label = line[0]\n",
        "            heading = None\n",
        "            text = line[1] + ' ' + line[2]\n",
        "            try:\n",
        "                aspects = [' ' + x for x in line[3].split('|')]\n",
        "                temp_clean_text = \" \".join(line[3].split('|'))\n",
        "            except:\n",
        "                aspects = None\n",
        "                temp_clean_text = \"\"\n",
        "                print(\"Sed\")\n",
        "            \n",
        "            # print(aspects)\n",
        "            \"\"\"    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT   \"\"\"\n",
        "            clean_text = self.clean_str( text, lemmatizer) ######## for using glove embeddings over sentence\n",
        "            # clean_text = self.clean_str( temp_clean_text, lemmatizer) ##### for using BioASQ embeddings in aspects\n",
        "            examples.append(\n",
        "                ICHI_InputExample(guid=guid, heading=heading, text=text, clean_text=clean_text, aspects=aspects, label=label))\n",
        "        return examples\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are.\n",
        "        This method converts examples to the correct format.\"\"\"\n",
        "        if len(self.get_labels()) > 1:\n",
        "            example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    def clean_str(self, string1, lemmatizer):\n",
        "        \"\"\"\n",
        "        Tokenization/string cleaning for dataset\n",
        "        Every dataset is lower cased except\n",
        "        \"\"\"\n",
        "        str_stop = \"\"\n",
        "        string1 = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '',string1)\n",
        "        string1 = re.sub(r\"\\\\\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\'\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\\"\", \" \", string1)   \n",
        "        string1 = re.sub(r'(\\W)\\1+', r'\\1', string1)\n",
        "        word_list=string1.split(\" \")\n",
        "        filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
        "        for kj in filtered_words:\n",
        "            new=lemmatizer.lemmatize(str(kj)) \n",
        "            str_stop=str_stop +\" \"+new\n",
        "            str_stop.encode('utf-8')\n",
        "        return str_stop.strip().lower()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))\n",
        "\n",
        "class ICHI_InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        heading: string. The untokenized heading of the sequence\n",
        "        text: string. The untokenized text part of the sequence.\n",
        "        clean_text: string. The untokenized text part of the sequence used for medical module(as tokenization will be different for glove and BioASQ than BERT).\n",
        "        aspects: list of string. The untokenized aspects for the sequence as a list of strings\n",
        "        Only must be specified for sequence pair tasks.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, heading, text, clean_text, aspects, label=None):\n",
        "        self.guid = guid\n",
        "        self.heading = heading\n",
        "        self.text = text\n",
        "        self.clean_text = clean_text\n",
        "        self.aspects = aspects\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class ICHI_InputFeatures(object):\n",
        "    \"\"\"\n",
        "    A single set of features of data.\n",
        "\n",
        "    Args:\n",
        "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
        "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
        "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
        "        label: Label corresponding to the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_global_ids, input_local_ids, attention_mask_global=None, attention_mask_local=None, token_global_type_ids=None, token_local_type_ids=None, text_clean_indices=None, aspect_indices=None, label=None):\n",
        "        self.input_global_ids = input_global_ids\n",
        "        self.attention_mask_global = attention_mask_global\n",
        "        self.token_global_type_ids = token_global_type_ids\n",
        "        self.input_local_ids = input_local_ids\n",
        "        self.attention_mask_local = attention_mask_local\n",
        "        self.token_local_type_ids = token_local_type_ids\n",
        "        self.text_clean_indices = text_clean_indices\n",
        "        self.aspect_indices = aspect_indices\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, task, tokenizer, tokenizer_cleantext, evaluate=False):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    processor = ICHIProcessor()  \n",
        "    output_mode = \"classification\"\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}_{}\".format(\n",
        "            \"dev\" if evaluate else \"train\",\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_length),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    \"\"\" Load saved tokenizer for the clean_text\"\"\"\n",
        "    cached_tokenizer_cleantext_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedtokenizer_{}_{}_{}\".format(\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.embedding_type),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "    \"\"\" if overwrite cache is disabled and saved feature and tokenizer file exists then load from the saved file else process them \"\"\"\n",
        "    if os.path.exists(cached_features_file) and os.path.exists(cached_tokenizer_cleantext_file) and not args.overwrite_cache:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "        tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "        if task in [\"mnli\", \"mnli-mm\"] and args.model_type in [\"roberta\", \"xlmroberta\"]:\n",
        "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
        "            label_list[1], label_list[2] = label_list[2], label_list[1]\n",
        "        examples = (\n",
        "            processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
        "        )\n",
        "        if (not evaluate):\n",
        "            tokenizer_cleantext.fit_on_examples(examples)\n",
        "            tokenizer_cleantext.update_tokenizer()\n",
        "        \"\"\" features are created using this function which is defined above\"\"\"\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            tokenizer_cleantext,\n",
        "            label_list=label_list,\n",
        "            max_length=args.max_seq_length,\n",
        "            output_mode=output_mode,\n",
        "            pad_on_left=bool(args.model_type in [\"xlnet\"]),  # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "            pickle.dump(tokenizer_cleantext, open(cached_tokenizer_cleantext_file, 'wb'))\n",
        "\n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_global_ids = torch.tensor([f.input_global_ids for f in features], dtype=torch.long)\n",
        "    all_input_local_ids = torch.tensor([f.input_local_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask_global = torch.tensor([f.attention_mask_global for f in features], dtype=torch.long)\n",
        "    all_attention_mask_local = torch.tensor([f.attention_mask_local for f in features], dtype=torch.long)\n",
        "    all_token_global_type_ids = torch.tensor([f.token_global_type_ids for f in features], dtype=torch.long)\n",
        "    all_token_local_type_ids = torch.tensor([f.token_local_type_ids for f in features], dtype=torch.long)\n",
        "    all_text_clean_indices = torch.tensor([f.text_clean_indices for f in features], dtype=torch.long)\n",
        "    all_aspect_indices = torch.tensor([f.aspect_indices for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "    \n",
        "    dataset = TensorDataset(all_input_global_ids, all_input_local_ids, all_attention_mask_global, all_attention_mask_local, all_token_global_type_ids, all_token_local_type_ids, all_text_clean_indices, all_aspect_indices, all_labels)\n",
        "    \n",
        "    return dataset, tokenizer_cleantext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/utils_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyy-AEpoS8Lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a352fd89-aceb-4de6-f602-c3a825d22bf1"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/lcf_ichi.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "from transformers.modeling_bert import BertPooler, BertSelfAttention, BertPreTrainedModel, BertModel\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "def compute_average_with_padding(tensor, padding):\n",
        "    \"\"\"\n",
        "    :param tensor: dimension batch_size, seq_length, hidden_size\n",
        "    :param padding: dimension batch_size, seq_length\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    batch_size, seq_length, emb_size = tensor.shape\n",
        "    entry_sizes = torch.sum(padding, axis=1)\n",
        "    return torch.sum(tensor, axis=1) / entry_sizes\n",
        "\n",
        "\n",
        "class BertMaxPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = compute_average_with_padding(hidden_states, mask)\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config, args):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.args = args\n",
        "        self.SA = BertSelfAttention(config)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        zero_tensor = torch.tensor(np.zeros((inputs.size(0), 1, 1, self.args.max_seq_length),\n",
        "                                            dtype=np.float32), dtype=torch.float32).to(self.args.device)\n",
        "        SA_out = self.SA(inputs, zero_tensor)\n",
        "        return self.tanh(SA_out[0])\n",
        "\n",
        "\n",
        "class lcf_BERT(BertPreTrainedModel):\n",
        "    def __init__(self, config, args):\n",
        "        super(lcf_BERT, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.args = args\n",
        "        self.config =config\n",
        "        self.bert = BertModel(config)\n",
        "        # self.bert_global_focus = self.bert\n",
        "        # self.bert_local_focus = copy.deepcopy(self.bert_global_focus) if args.use_single_bert else self.bert_global_focus\n",
        "        # self.embedder = nn.Embedding.from_pretrained(torch.from_numpy(args.word2vec).float(), freeze=True, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.lstm = nn.LSTM(args.emb_size, 100, 1, batch_first=True, bidirectional=True)\n",
        "        # Co = 100\n",
        "        # self.conv13 = nn.Conv2d(1, Co, (3, 2*args.emb_size))\n",
        "        # self.conv14 = nn.Conv2d(1, Co, (4, 2*args.emb_size))\n",
        "        # self.conv15 = nn.Conv2d(1, Co, (5, 2*args.emb_size))\n",
        "        # self.dropout_1 = nn.Dropout(0.4)\n",
        "        # self.fc1 = nn.Linear(3*Co, config.num_labels)\n",
        "        # self.fc = nn.Linear(200, config.num_labels)\n",
        "        self.bert_SA = SelfAttention(config, args) ### change\n",
        "        self.linear_double_cdm_or_cdw = nn.Linear(config.hidden_size * 2,config.hidden_size)\n",
        "        self.linear_triple_lcf_global = nn.Linear(config.hidden_size * 3, config.hidden_size)\n",
        "        self.bert_pooler_org = BertPooler(config)\n",
        "        self.bert_pooler = BertMaxPooler(config) ### change\n",
        "        self.dense = nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.init_weights()\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.gelu(conv(x)).squeeze(3) # (n, Co, W)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x\n",
        "\n",
        "    def feature_dynamic_mask(self, text_local_indices, aspect_indices):\n",
        "        texts = text_local_indices\n",
        "        # mask_len = self.args.SRD\n",
        "        masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "                                          dtype=torch.float)\n",
        "        \n",
        "        masked_text_raw_indices[:, 0, :] = torch.ones((text_local_indices.size(0), self.config.hidden_size), dtype=torch.float) \n",
        "        zero_tensor = torch.tensor(0).to(self.args.device)\n",
        "        for i in range(aspect_indices.shape[0]):\n",
        "            for j in range(aspect_indices[i].shape[0]):\n",
        "                if aspect_indices[i][j] == zero_tensor:\n",
        "                    break\n",
        "                else:\n",
        "                    indices = (text_local_indices[i] == aspect_indices[i][j]).nonzero()\n",
        "                    for k in indices:\n",
        "                        masked_text_raw_indices[i][k] = torch.ones(self.config.hidden_size, dtype=torch.float)\n",
        "        return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    # # create the weights tensor for local context features\n",
        "    # def feature_dynamic_weighted(self, text_local_indices, aspect_indices):\n",
        "    #     texts = text_local_indices\n",
        "    #     asps = aspect_indices\n",
        "    #     # mask_len = self.args.SRD\n",
        "    #     masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "    #                                       dtype=torch.float)\n",
        "    #     for text_i, asp_i in zip(range(len(texts)), range(len(asps))):\n",
        "    #         asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "    #         try:\n",
        "    #             asp_begin = np.argwhere(texts[text_i] == asps[asp_i][1])[0][0]\n",
        "    #             asp_avg_index = (asp_begin * 2 + asp_len) / 2\n",
        "    #         except:\n",
        "    #             continue\n",
        "    #         distances = np.zeros(np.count_nonzero(texts[text_i]), dtype=np.float32)\n",
        "    #         for i in range(1, np.count_nonzero(texts[text_i])-1):\n",
        "    #             if abs(i - asp_avg_index) + asp_len / 2 > self.args.SRD:\n",
        "    #                 distances[i] = 1 - (abs(i - asp_avg_index)+asp_len/2\n",
        "    #                                     - self.args.SRD)/np.count_nonzero(texts[text_i])\n",
        "    #             else:\n",
        "    #                 distances[i] = 1\n",
        "    #         for i in range(len(distances)):\n",
        "    #             masked_text_raw_indices[text_i][i] = masked_text_raw_indices[text_i][i] * distances[i]\n",
        "    #     # masked_text_raw_indices = torch.from_numpy(masked_text_raw_indices)\n",
        "    #     return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_global_ids=None,\n",
        "        attention_mask_global=None,\n",
        "        token_global_type_ids=None,\n",
        "        input_local_ids=None,\n",
        "        attention_mask_local=None,\n",
        "        token_local_type_ids=None,\n",
        "        text_clean_indices=None,\n",
        "        aspect_indices=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        # word_vectors = self.embedder(text_clean_indices)\n",
        "        # self.lstm.flatten_parameters()\n",
        "        # out, _ = self.lstm(word_vectors)\n",
        "        # # out = out.unsqueeze(1)   #### for using CNN\n",
        "        # # print(out.size())\n",
        "        # # print(out)\n",
        "        # logits = self.fc(out[:, -1, :])\n",
        "        # # print(logits.size())\n",
        "        # # print(logits)\n",
        "        # # raise ValueError\n",
        "        # # logits = self.fc(torch.div(word_vectors.sum(axis=1), word_vectors.shape[1]))\n",
        "\n",
        "        # global_outputs, _ = self.bert(\n",
        "        #     input_global_ids,\n",
        "        #     attention_mask=attention_mask_global,\n",
        "        #     token_type_ids=token_global_type_ids,\n",
        "        #     position_ids=position_ids,\n",
        "        #     head_mask=head_mask,\n",
        "        #     inputs_embeds=inputs_embeds,\n",
        "        # )\n",
        "\n",
        "        local_outputs, _ = self.bert(\n",
        "            input_local_ids,\n",
        "            attention_mask=attention_mask_local,\n",
        "            token_type_ids=token_local_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "        \n",
        "        # if self.args.local_context_focus == 'cdm':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'cdw':\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'lcf_fusion':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(text_local_indices, aspect_indices)\n",
        "        #     masked_local_out = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(text_local_indices, aspect_indices)\n",
        "        #     weighted_local_out = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((masked_local_out, global_outputs, weighted_local_out), dim=-1)\n",
        "        #     out_cat = self.linear_triple_lcf_global(out_cat)\n",
        "\n",
        "        # self_attention_out = self.bert_SA(local_outputs)\n",
        "        self_attention_out = self.dropout(local_outputs)\n",
        "        local_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # self_attention_out = self.dropout(global_outputs)\n",
        "        # global_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # pooled_out = torch.cat((local_pooled_out, global_pooled_out), dim=-1)\n",
        "        logits = self.dense(local_pooled_out)\n",
        "        outputs = (logits,)\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/lcf_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhlcZgHS8a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5c8be2-c62a-417b-bcce-fd74b050b11a"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/run_ichi.py\n",
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AlbertConfig,\n",
        "    AlbertForSequenceClassification,\n",
        "    AlbertTokenizer,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    XLMConfig,\n",
        "    XLMForSequenceClassification,\n",
        "    XLMRobertaConfig,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMTokenizer,\n",
        "    XLNetConfig,\n",
        "    XLNetForSequenceClassification,\n",
        "    XLNetTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from lcf_ichi import lcf_BERT#, lcf_XLNET, lcf_XLM, lcf_Roberta, lcf_DistilBert, lcf_Albert, lcf_XLMRoberta\n",
        "from utils_ichi import convert_examples_to_features, ICHIProcessor, compute_metrics, load_and_cache_examples, Tokenizer, pad_and_truncate, build_embedding_matrix_glove, build_embedding_matrix_BioASQ\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ALL_MODELS = sum(\n",
        "    (\n",
        "        tuple(conf.pretrained_config_archive_map.keys())\n",
        "        for conf in (\n",
        "            BertConfig,\n",
        "            XLNetConfig,\n",
        "            XLMConfig,\n",
        "            RobertaConfig,\n",
        "            DistilBertConfig,\n",
        "            AlbertConfig,\n",
        "            XLMRobertaConfig,\n",
        "        )\n",
        "    ),\n",
        "    (),\n",
        ")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer, lcf_BERT),\n",
        "}\n",
        "#     \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer, lcf_XLNET),\n",
        "#     \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer, lcf_XLM),\n",
        "#     \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, lcf_Roberta),\n",
        "#     \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer, lcf_DistilBert),\n",
        "#     \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, lcf_Albert),\n",
        "#     \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer, lcf_XLMRoberta),\n",
        "# }\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def train(args, train_dataset, model, tokenizer, tokenizer_cleantext):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True,\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        # set global_step to gobal_step of last saved checkpoint from model path\n",
        "        global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
        "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0],\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_global_type_ids\"] = (\n",
        "                    batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "                inputs[\"token_local_type_ids\"] = (\n",
        "                    batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "            # inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            # if args.model_type != \"distilbert\":\n",
        "            #     inputs[\"token_type_ids\"] = (\n",
        "            #         batch[2] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "            #     )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                #     # Save model checkpoint\n",
        "                #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                #     if not os.path.exists(output_dir):\n",
        "                #         os.makedirs(output_dir)\n",
        "                #     # model_to_save = (\n",
        "                #     #     model.module if hasattr(model, \"module\") else model\n",
        "                #     # )  # Take care of distributed/parallel training\n",
        "                #     # model_to_save.save_pretrained(output_dir)\n",
        "                #     torch.save(model.state_dict(), args.output_dir)\n",
        "                #     tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                #     torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                #     torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                #     logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "\n",
        "def evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_task_names = (\"ichi\",)\n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "\n",
        "    results = {}\n",
        "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
        "        eval_dataset, tokenizer_cleantext = load_and_cache_examples(args, eval_task, tokenizer, tokenizer_cleantext, evaluate=True)\n",
        "\n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        # Note that DistributedSampler samples randomly\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        # multi-gpu eval\n",
        "        if args.n_gpu > 1:\n",
        "            model = torch.nn.DataParallel(model)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        preds_original = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "                if args.model_type != \"distilbert\":\n",
        "                    inputs[\"token_global_type_ids\"] = (\n",
        "                        batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )\n",
        "                    inputs[\"token_local_type_ids\"] = (\n",
        "                        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                preds_original = logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                preds_original = np.append(preds_original, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        result = compute_metrics(preds, out_label_ids) ######################update kar !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "            # for a in preds:\n",
        "            #     writer.write(str(a)+'\\n')\n",
        "            writer.write('[')\n",
        "            for a in preds_original:\n",
        "                writer.write('[')\n",
        "                for c in range(len(a)):\n",
        "                    b = a[c]\n",
        "                    if c!=6:\n",
        "                        writer.write(str(b)+',')\n",
        "                    else:\n",
        "                        writer.write(str(b))\n",
        "                writer.write(']')\n",
        "                writer.write('\\n')\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_type\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "        \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--embedding_dim_word2vec\",\n",
        "        default=300,\n",
        "        type=int,\n",
        "        help=\"embedding dimension for the word vectors in the medical module\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\", action=\"store_true\", help=\"Rul evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=10000, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Prepare GLUE task\n",
        "    args.task_name = 'ichi'\n",
        "    processor = ICHIProcessor()\n",
        "    args.output_mode = \"classification\"\n",
        "    label_list = processor.get_labels()\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class, lcf_model = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(\n",
        "        args.config_name if args.config_name else args.model_name_or_path,\n",
        "        num_labels=num_labels,\n",
        "        finetuning_task=args.task_name,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer_cleantext = Tokenizer(max_seq_len = 1600, max_num_words=20000,lower=True)\n",
        "    # model = model_class.from_pretrained(\n",
        "    #     args.model_name_or_path,\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    args.use_single_bert = False\n",
        "    args.local_context_focus = 'cdm'\n",
        "    args.embedding_type = 'glove'\n",
        "\n",
        "    cached_embeddingmatrix_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedword2vec_{}_{}\".format(\n",
        "            str(args.task_name),\n",
        "            str(\"glove\"),\n",
        "        ),\n",
        "    )\n",
        "    cached_embeddingmatrix_path = \".\"\n",
        "    \n",
        "    train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "    # embedding_matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_embeddingmatrix_file, cached_embeddingmatrix_path)\n",
        "    # print(embedding_matrix.shape)\n",
        "    # print(tokenizer_cleantext.word2idx)\n",
        "    \n",
        "    # args.word2vec = embedding_matrix\n",
        "    # args.emb_size = embedding_matrix.shape[1]\n",
        "    model = lcf_model.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        args=args,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    # model = lcf_Roberta.from_pretrained(\n",
        "    #     \"/home/bt1/17CS10037/new_transformers/transformers/roberta-large-pytorch_model.bin\",\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     args=args,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "    \n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        # train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "        # matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_glove_embeddingmatrix_file, cached_glove_embeddingmatrix_path)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, tokenizer_cleantext)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    result = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        # model_to_save = (\n",
        "        #     model.module if hasattr(model, \"module\") else model\n",
        "        # )  # Take care of distributed/parallel training\n",
        "        # model_to_save.save_pretrained(args.output_dir)\n",
        "        model_name = \"{}.pt\".format(args.model_type)\n",
        "        torch.save(model.state_dict(), os.path.join(args.output_dir,model_name))\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        # model = model_class.from_pretrained(args.output_dir)\n",
        "        model = lcf_model(config, args)\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        cached_tokenizer_cleantext_file = os.path.join(\n",
        "            args.data_dir,\n",
        "            \"cachedtokenizer_{}_{}_{}\".format(\n",
        "                list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "                str(args.embedding_type),\n",
        "                str(args.task_name),\n",
        "            ),\n",
        "        )\n",
        "        if os.path.exists(cached_tokenizer_cleantext_file):\n",
        "            print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "            tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            # model = model_class.from_pretrained(checkpoint)\n",
        "            # model = lcf_model.from_pretrained(\n",
        "            #     args.model_name_or_path,\n",
        "            #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "            #     config=config,\n",
        "            #     args=args,\n",
        "            #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "            # )\n",
        "\n",
        "            model = lcf_model(config, args)\n",
        "            model_name = \"{}.pt\".format(args.model_type)\n",
        "            model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/run_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpFdc6sbALY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a322f961-e3c4-4d9e-e938-36b3a7bf47e8"
      },
      "source": [
        "!python ./examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir ./data/ichi --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir ./tmp/ichi_bert_base_new --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-03 06:53:32.449138: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/03/2021 06:53:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/03/2021 06:53:34 - INFO - filelock -   Lock 139742913695568 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "06/03/2021 06:53:34 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpo1ml17ak\n",
            "Downloading: 100% 433/433 [00:00<00:00, 400kB/s]\n",
            "06/03/2021 06:53:34 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/03/2021 06:53:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/03/2021 06:53:34 - INFO - filelock -   Lock 139742913695568 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "06/03/2021 06:53:34 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/03/2021 06:53:34 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"ichi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "06/03/2021 06:53:35 - INFO - filelock -   Lock 139742913849104 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "06/03/2021 06:53:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp4lumdz_m\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 901kB/s]\n",
            "06/03/2021 06:53:35 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/03/2021 06:53:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/03/2021 06:53:35 - INFO - filelock -   Lock 139742913849104 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "06/03/2021 06:53:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/03/2021 06:53:35 - INFO - utils_ichi -   Creating features from dataset file at ./data/ichi\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   Writing example 0/8000\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   guid: train-1\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_global_ids: 101 2340 2095 2214 2006 1062 12898 6199 1011 14978 2015 1029 2026 2365 2038 2042 2006 1062 12898 6199 2005 2074 2058 2048 2706 1012 2002 2318 2006 2423 11460 1012 2010 13004 2001 3728 3445 2000 2753 11460 1012 2306 1016 3134 1997 1996 3623 1010 2002 2038 2018 1037 14978 1010 3701 2006 1996 2157 2217 1997 2010 2132 2012 1996 3379 1012 2002 2018 2036 2042 2006 2060 20992 2005 1037 8254 2271 8985 1998 22953 12680 13706 1006 16405 13728 11261 5339 1010 17235 5643 2595 1998 1060 26915 10288 1009 2019 3424 26591 1007 1012 2002 2003 2085 2125 1997 2087 1997 2216 19960 2015 1006 3272 1996 3424 26591 1007 1010 2061 1045 3984 1045 2064 16519 2008 2216 19960 2015 2020 2025 1996 3120 1997 2010 14978 1012 2009 2038 2042 2524 2005 2033 2000 5646 2073 1996 14978 2003 2746 2013 1010 2021 2085 1045 2572 4208 2006 1996 1062 12898 6199 1011 2009 2003 1996 2028 8335 19960 2002 2003 2145 2006 1012 2057 2031 2525 2464 2019 2035 2121 24063 1006 2145 2383 2035 24395 5852 1007 1010 2019 4372 2102 1998 1037 4440 2000 1996 9413 1012 1999 1996 9413 2057 2018 1037 2117 4937 13594 2589 1006 1996 2034 4937 13594 2001 1037 3204 2077 2029 3271 2149 2000 5646 2008 2002 2018 1037 8254 2271 8985 1010 2029 2031 2468 11888 1007 1996 2117 4937 13594 3662 1037 4121 7620 1999 2010 8254 25581 1010 2061 2057 2113 2008 2002 2003 102\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_local_ids: 101 2340 2095 2214 2006 1062 12898 6199 1011 14978 2015 1029 2026 2365 2038 2042 2006 1062 12898 6199 2005 2074 2058 2048 2706 1012 2002 2318 2006 2423 11460 1012 2010 13004 2001 3728 3445 2000 2753 11460 1012 2306 1016 3134 1997 1996 3623 1010 2002 2038 2018 1037 14978 1010 3701 2006 1996 2157 2217 1997 2010 2132 2012 1996 3379 1012 2002 2018 2036 2042 2006 2060 20992 2005 1037 8254 2271 8985 1998 22953 12680 13706 1006 16405 13728 11261 5339 1010 17235 5643 2595 1998 1060 26915 10288 1009 2019 3424 26591 1007 1012 2002 2003 2085 2125 1997 2087 1997 2216 19960 2015 1006 3272 1996 3424 26591 1007 1010 2061 1045 3984 1045 2064 16519 2008 2216 19960 2015 2020 2025 1996 3120 1997 2010 14978 1012 2009 2038 2042 2524 2005 2033 2000 5646 2073 1996 14978 2003 2746 2013 1010 2021 2085 1045 2572 4208 2006 1996 1062 12898 6199 1011 2009 2003 1996 2028 8335 19960 2002 2003 2145 2006 1012 2057 2031 2525 2464 2019 2035 2121 24063 1006 2145 2383 2035 24395 5852 1007 1010 2019 4372 2102 1998 1037 4440 2000 1996 9413 1012 1999 1996 9413 2057 2018 1037 2117 4937 13594 2589 1006 1996 2034 4937 13594 2001 1037 3204 2077 2029 3271 2149 2000 5646 2008 2002 2018 1037 8254 2271 8985 1010 2029 2031 2468 11888 1007 1996 2117 4937 13594 3662 1037 4121 7620 1999 2010 8254 25581 1010 2061 2057 2113 2008 2002 2003 102\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 639 2 13 3386 51 9742 8 59 3386 63 460 10 41 919 3973 381 937 150 819 1039 3973 497 28 15 11255 3387 1903 43 112 178 17277 10 17 398 1040 286 6532 20002 20002 20002 1575 20002 10 551 5680 20002 1 562 1 9743 551 2000 3388 31 149 2055 444 316 5313 1 3202 3386 51 11 2056 551 30 680 78 296 304 9744 4769 1138 20002 2627 1708 5681 165 931 241 1679 545 110 1373 55 1679 545 23 1126 133 2055 1040 2057 305 20002 12 241 1679 545 382 820 2628 17278 5 4770 4325 78 17 32 56 563 672 51 195 1468 18 7723 10 444 28 15 51 466 28 15 3386 937 819 13437 78 36 3521 6 13438 6081 59 498 141 664 882 2942 1496 178 13439 241 13440 1775 444 11256 177 20002 366 7 1497 20002 51 17279\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   aspect_indices: 2035 24395 5852 13594 3615 3255 3255 22953 12680 13706 8985 3379 4372 2102 2132 3239 1009 3424 26591 24479 3424 26591 2157 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   label: FAML (id = 5)\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   guid: train-2\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_global_ids: 101 11707 2273 29477 8557 2009 2038 2042 1037 2095 2144 2026 2561 1044 27268 7869 6593 16940 1012 1045 2031 2464 2176 27885 6292 2078 8325 1005 1055 2144 2059 1012 2025 2028 2038 2445 2033 2151 6998 2055 2044 2729 1012 1045 2572 2006 9765 22991 1006 2659 13004 1007 1012 2026 9765 22991 2504 2003 2145 2659 2247 2007 2035 1996 5876 1012 1045 2572 2383 2358 10441 2818 3255 1010 2026 3096 2003 23277 19839 2135 1010 12436 24965 4318 2791 1010 9630 10063 1010 1037 2843 1997 2067 3255 1010 2305 7518 2015 1010 1045 2572 5122 2035 1996 2051 1010 3348 5293 2009 2005 1996 3255 2003 24257 1010 24471 2378 12509 2015 2035 2058 1010 6245 1010 6888 18755 1998 1037 2843 2062 1012 1012 1012 1012 2003 2045 2151 6040 2041 2045 2005 2033 19723 6692 17080 3070 2054 2000 2079 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_local_ids: 101 11707 2273 29477 8557 2009 2038 2042 1037 2095 2144 2026 2561 1044 27268 7869 6593 16940 1012 1045 2031 2464 2176 27885 6292 2078 8325 1005 1055 2144 2059 1012 2025 2028 2038 2445 2033 2151 6998 2055 2044 2729 1012 1045 2572 2006 9765 22991 1006 2659 13004 1007 1012 2026 9765 22991 2504 2003 2145 2659 2247 2007 2035 1996 5876 1012 1045 2572 2383 2358 10441 2818 3255 1010 2026 3096 2003 23277 19839 2135 1010 12436 24965 4318 2791 1010 9630 10063 1010 1037 2843 1997 2067 3255 1010 2305 7518 2015 1010 1045 2572 5122 2035 1996 2051 1010 3348 5293 2009 2005 1996 3255 2003 24257 1010 24471 2378 12509 2015 2035 2058 1010 6245 1010 6888 18755 1998 1037 2843 2062 1012 1012 1012 1012 2003 2045 2151 6040 2041 2045 2005 2033 19723 6692 17080 3070 2054 2000 2079 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2517 1831 31 2 37 754 2629 1 304 437 2136 760 37 2001 353 11 357 341 2776 1 2091 11257 20002 8 2091 185 30 249 326 20002 1 20002 548 308 20002 458 11258 4771 7042 123 24 548 120 6082 1 6533 342 66 1875 18 13441 20002 4135 3106 4548 1052 3107 123 20002 202 17280 374\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   aspect_indices: 9630 10063 3255 12436 24965 2843 2067 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   label: TRMT (id = 2)\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   guid: train-3\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_global_ids: 101 2933 1038 2044 2570 2847 1000 2026 4256 1998 2033 2018 3348 1998 1996 20910 3631 2006 2149 2000 2256 5213 1012 2009 2001 2026 3416 2461 2061 2043 1045 2234 2009 2347 1005 1056 2004 2524 1013 2844 2004 1996 3083 1006 1045 2109 1037 4487 4246 1012 20910 2748 2077 3087 5176 1007 1012 2016 2347 2102 2006 4182 2491 2004 2016 2003 18517 2000 2031 1037 3460 1005 1055 10439 2102 1012 5958 2000 2131 2070 1012 2044 1996 1000 1000 5043 1000 1000 2016 2165 4933 2041 1998 2921 2893 2023 2317 4933 2021 2009 2071 2031 2042 2014 1039 1008 1049 1010 1998 2043 2057 4102 2169 2060 1005 1055 2009 2134 1005 1056 2514 2066 3067 1012 1999 2755 2045 1005 1055 1037 3382 1045 2134 1005 1056 1008 1008 1008 1999 2014 1012 2174 2045 2003 3653 1011 1041 3900 19879 3508 1997 2607 1012 2146 2466 2460 1010 2057 2165 2895 1012 2570 2847 2101 1006 2016 2018 2000 2175 2000 2082 1998 2147 8670 2278 1011 2000 1011 2067 28939 2057 2071 2079 2505 1007 1012 2057 4149 2047 29094 1010 2016 2288 18315 10343 1010 1998 2016 2165 1037 2933 1038 17357 2570 2847 2044 1998 2074 2165 1996 3416 2028 2260 2847 2101 1012 1045 2113 1996 19059 2017 2202 2009 1996 3020 1996 3382 1010 2021 1045 2036 2657 1059 1013 1999 2484 2847 2003 1037 2428 2204 2518 1012 2129 5191 2323 1045 2022 1029 18411 2860 2014 3083 2154 1997 102\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_local_ids: 101 2933 1038 2044 2570 2847 1000 2026 4256 1998 2033 2018 3348 1998 1996 20910 3631 2006 2149 2000 2256 5213 1012 2009 2001 2026 3416 2461 2061 2043 1045 2234 2009 2347 1005 1056 2004 2524 1013 2844 2004 1996 3083 1006 1045 2109 1037 4487 4246 1012 20910 2748 2077 3087 5176 1007 1012 2016 2347 2102 2006 4182 2491 2004 2016 2003 18517 2000 2031 1037 3460 1005 1055 10439 2102 1012 5958 2000 2131 2070 1012 2044 1996 1000 1000 5043 1000 1000 2016 2165 4933 2041 1998 2921 2893 2023 2317 4933 2021 2009 2071 2031 2042 2014 1039 1008 1049 1010 1998 2043 2057 4102 2169 2060 1005 1055 2009 2134 1005 1056 2514 2066 3067 1012 1999 2755 2045 1005 1055 1037 3382 1045 2134 1005 1056 1008 1008 1008 1999 2014 1012 2174 2045 2003 3653 1011 1041 3900 19879 3508 1997 2607 1012 2146 2466 2460 1010 2057 2165 2895 1012 2570 2847 2101 1006 2016 2018 2000 2175 2000 2082 1998 2147 8670 2278 1011 2000 1011 2067 28939 2057 2071 2079 2505 1007 1012 2057 4149 2047 29094 1010 2016 2288 18315 10343 1010 1998 2016 2165 1037 2933 1038 17357 2570 2847 2044 1998 2074 2165 1996 3416 2028 2260 2847 2101 1012 1045 2113 1996 19059 2017 2202 2009 1996 3020 1996 3382 1010 2021 1045 2036 2657 1059 1013 1999 2484 2847 2003 1037 2428 2204 2518 1012 2129 5191 2323 1045 2022 1029 18411 2860 2014 3083 2154 1997 102\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 538 795 232 1074 9745 644 66 769 1053 133 7043 812 1041 100 20002 777 415 155 13442 769 1359 50 20002 1680 278 247 9746 29 3292 762 3 8580 2002 96 716 735 65 263 716 14 20002 1730 21 4 3522 576 407 1139 358 480 17281 20002 655 5011 96 8581 1074 173 207 2456 16 115 92 20002 1288 14 17282 1625 83 13443 44 20002 96 538 795 219 1074 173 96 812 11 418 173 1166 5 7044 34 1054 20002 17 309 11259 804 173 25 76 1414 176 20002 777 6 27 38 20002 1415 274 27 95 23 1055 17283 380 13444 3108 20002 1109 11260 2003\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   aspect_indices: 2067 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   label: PREG (id = 4)\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   guid: train-4\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_global_ids: 101 2217 3896 1997 11721 13639 27572 2026 2684 2003 2321 1998 2006 16215 9236 2238 1019 1010 2263 2016 2363 2014 2117 2915 1997 11721 13639 27572 1012 1037 3232 1997 2847 2101 2016 10865 1997 7669 5505 1012 1045 2165 2014 2000 1996 9413 2073 2027 2071 2424 2498 3308 2007 2014 1998 2081 2033 2514 2004 2065 1045 2020 4689 2000 2228 2009 2001 1996 11721 13639 27572 2915 1012 2027 2435 2014 1037 11265 8569 28863 3949 2029 2134 1005 1056 2393 1998 2741 2014 2188 2007 1037 2566 22483 3258 2005 2632 8569 27833 1010 2029 2205 2038 2025 3271 1012 2119 2014 3078 3460 1998 2019 2035 2121 24063 1045 2165 2014 2000 2056 2009 2763 2001 2025 1996 11721 13639 27572 1998 11441 2014 2007 22953 12680 13706 1012 2016 2038 2053 5751 1997 22953 12680 13706 1010 2053 6887 16930 1010 19340 2030 1059 21030 6774 1012 2026 6887 27292 6305 2923 2056 2057 2342 2000 3613 2007 1037 2367 5448 2144 22953 12680 13706 2467 2038 2070 4066 1997 1059 21030 6774 1010 21454 2030 6887 16930 1012 2026 2684 2001 3294 7965 2127 2016 2363 2008 2915 1012 2064 3087 2393 2033 1029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_local_ids: 101 2217 3896 1997 11721 13639 27572 2026 2684 2003 2321 1998 2006 16215 9236 2238 1019 1010 2263 2016 2363 2014 2117 2915 1997 11721 13639 27572 1012 1037 3232 1997 2847 2101 2016 10865 1997 7669 5505 1012 1045 2165 2014 2000 1996 9413 2073 2027 2071 2424 2498 3308 2007 2014 1998 2081 2033 2514 2004 2065 1045 2020 4689 2000 2228 2009 2001 1996 11721 13639 27572 2915 1012 2027 2435 2014 1037 11265 8569 28863 3949 2029 2134 1005 1056 2393 1998 2741 2014 2188 2007 1037 2566 22483 3258 2005 2632 8569 27833 1010 2029 2205 2038 2025 3271 1012 2119 2014 3078 3460 1998 2019 2035 2121 24063 1045 2165 2014 2000 2056 2009 2763 2001 2025 1996 11721 13639 27572 1998 11441 2014 2007 22953 12680 13706 1012 2016 2038 2053 5751 1997 22953 12680 13706 1010 2053 6887 16930 1010 19340 2030 1059 21030 6774 1012 2026 6887 27292 6305 2923 2056 2057 2342 2000 3613 2007 1037 2367 5448 2144 22953 12680 13706 2467 2038 2070 4066 1997 1059 21030 6774 1010 21454 2030 6887 16930 1012 2026 2684 2001 3294 7965 2127 2016 2363 2008 2915 1012 2064 3087 2393 2033 1029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 112 7724 13445 8 102 464 11261 775 4772 1576 833 241 430 20002 148 200 173 207 3523 1179 7045 1 96 931 14 126 136 216 201 21 1 966 33 13445 3109 145 257 13446 292 19 564 130 7046 20002 4136 1709 1776 29 9744 1 96 22 485 13445 258 11262 40 452 20002 20002 1577 20002 8 4549 22 46 675 254 780 37 6532 77 721 20002 2372 20002 8 102 534 319 833 3109 193 50 19 736\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   aspect_indices: 22953 12680 13706 2056 22953 12680 13706 3949 11441 21454 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   label: TRMT (id = 2)\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   guid: train-5\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_global_ids: 101 2775 1005 1055 4012 14289 4877 3512 2342 2000 2022 2157 2011 5814 3441 2057 2031 1037 2260 1061 2099 2214 7631 2008 7887 8313 8520 3441 2053 3043 2054 1996 3395 1010 2073 2002 4150 1996 3691 1998 4282 2673 2055 2673 1012 2023 2003 2130 2065 2002 4282 2498 2055 1996 3395 1012 2002 2097 2425 2017 2129 2242 2573 1010 2130 2065 2002 2987 1005 1056 2031 1037 9789 1012 2002 2003 2200 4408 1998 2003 8302 1999 1996 12785 2336 2565 2012 2082 1012 2057 1005 2128 5191 2008 2023 5248 2097 4287 2058 2046 2010 2397 13496 1998 4639 2086 1012 2057 2215 2000 3921 1996 3008 2021 2024 6603 2129 2190 2000 2079 2009 1012 2064 2017 6592 2242 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   input_local_ids: 101 2775 1005 1055 4012 14289 4877 3512 2342 2000 2022 2157 2011 5814 3441 2057 2031 1037 2260 1061 2099 2214 7631 2008 7887 8313 8520 3441 2053 3043 2054 1996 3395 1010 2073 2002 4150 1996 3691 1998 4282 2673 2055 2673 1012 2023 2003 2130 2065 2002 4282 2498 2055 1996 3395 1012 2002 2097 2425 2017 2129 2242 2573 1010 2130 2065 2002 2987 1005 1056 2031 1037 9789 1012 2002 2003 2200 4408 1998 2003 8302 1999 1996 12785 2336 2565 2012 2082 1012 2057 1005 2128 5191 2008 2023 5248 2097 4287 2058 2046 2010 2397 13496 1998 4639 2086 1012 2057 2215 2000 3921 1996 3008 2021 2024 6603 2129 2190 2000 2079 2009 1012 2064 2017 6592 2242 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67 6083 46 43 9747 655 78 418 179 13 1432 546 20002 655 483 8582 1498 2630 5 154 1341 82 39 5 136 8583 10 74 62 4550 39 13447 10 889 6534 5314 3974 1110 20002 176 251 1499 314 1967 1216 431 78 20 2058 367 161 269 88 193 1056 3645\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 06:55:24 - INFO - utils_ichi -   label: FAML (id = 5)\n",
            "06/03/2021 06:56:10 - INFO - utils_ichi -   Saving features into cached file ./data/ichi/cached_train_bert-base-uncased_256_ichi\n",
            "06/03/2021 06:56:18 - INFO - filelock -   Lock 139742763832976 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "06/03/2021 06:56:18 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpl7jvgcmc\n",
            "Downloading: 100% 440M/440M [00:11<00:00, 37.7MB/s]\n",
            "06/03/2021 06:56:30 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/03/2021 06:56:30 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/03/2021 06:56:30 - INFO - filelock -   Lock 139742763832976 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "06/03/2021 06:56:30 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/03/2021 06:56:33 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "06/03/2021 06:56:33 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "06/03/2021 06:56:44 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data/ichi', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='./tmp/ichi_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='ichi', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "06/03/2021 06:56:44 - INFO - __main__ -   ***** Running training *****\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Num examples = 8000\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Num Epochs = 2\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "06/03/2021 06:56:44 - INFO - __main__ -     Total optimization steps = 1000\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   0% 1/500 [00:00<08:09,  1.02it/s]\u001b[A\n",
            "Iteration:   0% 2/500 [00:01<07:28,  1.11it/s]\u001b[A\n",
            "Iteration:   1% 3/500 [00:02<07:01,  1.18it/s]\u001b[A\n",
            "Iteration:   1% 4/500 [00:03<06:41,  1.24it/s]\u001b[A\n",
            "Iteration:   1% 5/500 [00:03<06:26,  1.28it/s]\u001b[A\n",
            "Iteration:   1% 6/500 [00:04<06:16,  1.31it/s]\u001b[A\n",
            "Iteration:   1% 7/500 [00:05<06:09,  1.34it/s]\u001b[A\n",
            "Iteration:   2% 8/500 [00:06<06:04,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 9/500 [00:06<06:00,  1.36it/s]\u001b[A\n",
            "Iteration:   2% 10/500 [00:07<05:58,  1.37it/s]\u001b[A\n",
            "Iteration:   2% 11/500 [00:08<05:55,  1.38it/s]\u001b[A\n",
            "Iteration:   2% 12/500 [00:08<05:53,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 13/500 [00:09<05:51,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 14/500 [00:10<05:51,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 15/500 [00:11<05:50,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 16/500 [00:11<05:49,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 17/500 [00:12<05:50,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 18/500 [00:13<05:49,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 19/500 [00:13<05:48,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 20/500 [00:14<05:48,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 21/500 [00:15<05:48,  1.37it/s]\u001b[A\n",
            "Iteration:   4% 22/500 [00:16<05:48,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 23/500 [00:16<05:47,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 24/500 [00:17<05:47,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 25/500 [00:18<05:46,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 26/500 [00:19<05:45,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 27/500 [00:19<05:46,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 28/500 [00:20<05:45,  1.37it/s]\u001b[A\n",
            "Iteration:   6% 29/500 [00:21<05:46,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 30/500 [00:22<05:44,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 31/500 [00:22<05:44,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 32/500 [00:23<05:43,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 33/500 [00:24<05:43,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 34/500 [00:24<05:42,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 35/500 [00:25<05:42,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 36/500 [00:26<05:45,  1.34it/s]\u001b[A\n",
            "Iteration:   7% 37/500 [00:27<05:43,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 38/500 [00:27<05:41,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 39/500 [00:28<05:40,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 40/500 [00:29<05:40,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 41/500 [00:30<05:38,  1.36it/s]\u001b[A\n",
            "Iteration:   8% 42/500 [00:30<05:38,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 43/500 [00:31<05:37,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 44/500 [00:32<05:36,  1.36it/s]\u001b[A\n",
            "Iteration:   9% 45/500 [00:33<05:36,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 46/500 [00:33<05:35,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 47/500 [00:34<05:35,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 48/500 [00:35<05:35,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 49/500 [00:36<05:35,  1.35it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"learning_rate\": 9.5e-05, \"loss\": 1.5693407130241395, \"step\": 50}\n",
            "\n",
            "Iteration:  10% 50/500 [00:36<05:35,  1.34it/s]\u001b[A\n",
            "Iteration:  10% 51/500 [00:37<05:33,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 52/500 [00:38<05:32,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 53/500 [00:39<05:38,  1.32it/s]\u001b[A\n",
            "Iteration:  11% 54/500 [00:39<05:34,  1.33it/s]\u001b[A\n",
            "Iteration:  11% 55/500 [00:40<05:36,  1.32it/s]\u001b[A\n",
            "Iteration:  11% 56/500 [00:41<05:33,  1.33it/s]\u001b[A\n",
            "Iteration:  11% 57/500 [00:42<05:31,  1.34it/s]\u001b[A\n",
            "Iteration:  12% 58/500 [00:42<05:31,  1.33it/s]\u001b[A\n",
            "Iteration:  12% 59/500 [00:43<05:30,  1.33it/s]\u001b[A\n",
            "Iteration:  12% 60/500 [00:44<05:29,  1.33it/s]\u001b[A\n",
            "Iteration:  12% 61/500 [00:45<05:28,  1.34it/s]\u001b[A\n",
            "Iteration:  12% 62/500 [00:45<05:28,  1.33it/s]\u001b[A\n",
            "Iteration:  13% 63/500 [00:46<05:26,  1.34it/s]\u001b[A\n",
            "Iteration:  13% 64/500 [00:47<05:26,  1.34it/s]\u001b[A\n",
            "Iteration:  13% 65/500 [00:48<05:25,  1.34it/s]\u001b[A\n",
            "Iteration:  13% 66/500 [00:48<05:25,  1.33it/s]\u001b[A\n",
            "Iteration:  13% 67/500 [00:49<05:25,  1.33it/s]\u001b[A\n",
            "Iteration:  14% 68/500 [00:50<05:23,  1.33it/s]\u001b[A\n",
            "Iteration:  14% 69/500 [00:51<05:23,  1.33it/s]\u001b[A\n",
            "Iteration:  14% 70/500 [00:51<05:23,  1.33it/s]\u001b[A\n",
            "Iteration:  14% 71/500 [00:52<05:22,  1.33it/s]\u001b[A\n",
            "Iteration:  14% 72/500 [00:53<05:21,  1.33it/s]\u001b[A\n",
            "Iteration:  15% 73/500 [00:54<05:20,  1.33it/s]\u001b[A\n",
            "Iteration:  15% 74/500 [00:54<05:20,  1.33it/s]\u001b[A\n",
            "Iteration:  15% 75/500 [00:55<05:20,  1.33it/s]\u001b[A\n",
            "Iteration:  15% 76/500 [00:56<05:20,  1.32it/s]\u001b[A\n",
            "Iteration:  15% 77/500 [00:57<05:20,  1.32it/s]\u001b[A\n",
            "Iteration:  16% 78/500 [00:57<05:19,  1.32it/s]\u001b[A\n",
            "Iteration:  16% 79/500 [00:58<05:18,  1.32it/s]\u001b[A\n",
            "Iteration:  16% 80/500 [00:59<05:17,  1.32it/s]\u001b[A\n",
            "Iteration:  16% 81/500 [01:00<05:17,  1.32it/s]\u001b[A\n",
            "Iteration:  16% 82/500 [01:00<05:17,  1.32it/s]\u001b[A\n",
            "Iteration:  17% 83/500 [01:01<05:16,  1.32it/s]\u001b[A\n",
            "Iteration:  17% 84/500 [01:02<05:15,  1.32it/s]\u001b[A\n",
            "Iteration:  17% 85/500 [01:03<05:15,  1.31it/s]\u001b[A\n",
            "Iteration:  17% 86/500 [01:03<05:15,  1.31it/s]\u001b[A\n",
            "Iteration:  17% 87/500 [01:04<05:12,  1.32it/s]\u001b[A\n",
            "Iteration:  18% 88/500 [01:05<05:13,  1.31it/s]\u001b[A\n",
            "Iteration:  18% 89/500 [01:06<05:12,  1.31it/s]\u001b[A\n",
            "Iteration:  18% 90/500 [01:06<05:12,  1.31it/s]\u001b[A\n",
            "Iteration:  18% 91/500 [01:07<05:10,  1.32it/s]\u001b[A\n",
            "Iteration:  18% 92/500 [01:08<05:10,  1.31it/s]\u001b[A\n",
            "Iteration:  19% 93/500 [01:09<05:10,  1.31it/s]\u001b[A\n",
            "Iteration:  19% 94/500 [01:10<05:09,  1.31it/s]\u001b[A\n",
            "Iteration:  19% 95/500 [01:10<05:09,  1.31it/s]\u001b[A\n",
            "Iteration:  19% 96/500 [01:11<05:10,  1.30it/s]\u001b[A\n",
            "Iteration:  19% 97/500 [01:12<05:09,  1.30it/s]\u001b[A\n",
            "Iteration:  20% 98/500 [01:13<05:08,  1.30it/s]\u001b[A\n",
            "Iteration:  20% 99/500 [01:13<05:08,  1.30it/s]\u001b[A{\"learning_rate\": 9e-05, \"loss\": 1.1510108363628389, \"step\": 100}\n",
            "\n",
            "Iteration:  20% 100/500 [01:14<05:07,  1.30it/s]\u001b[A\n",
            "Iteration:  20% 101/500 [01:15<05:07,  1.30it/s]\u001b[A\n",
            "Iteration:  20% 102/500 [01:16<05:06,  1.30it/s]\u001b[A\n",
            "Iteration:  21% 103/500 [01:16<05:05,  1.30it/s]\u001b[A\n",
            "Iteration:  21% 104/500 [01:17<05:06,  1.29it/s]\u001b[A\n",
            "Iteration:  21% 105/500 [01:18<05:04,  1.30it/s]\u001b[A\n",
            "Iteration:  21% 106/500 [01:19<05:03,  1.30it/s]\u001b[A\n",
            "Iteration:  21% 107/500 [01:20<05:03,  1.30it/s]\u001b[A\n",
            "Iteration:  22% 108/500 [01:20<05:02,  1.30it/s]\u001b[A\n",
            "Iteration:  22% 109/500 [01:21<05:02,  1.29it/s]\u001b[A\n",
            "Iteration:  22% 110/500 [01:22<05:01,  1.29it/s]\u001b[A\n",
            "Iteration:  22% 111/500 [01:23<05:01,  1.29it/s]\u001b[A\n",
            "Iteration:  22% 112/500 [01:23<05:00,  1.29it/s]\u001b[A\n",
            "Iteration:  23% 113/500 [01:24<04:59,  1.29it/s]\u001b[A\n",
            "Iteration:  23% 114/500 [01:25<05:00,  1.29it/s]\u001b[A\n",
            "Iteration:  23% 115/500 [01:26<05:00,  1.28it/s]\u001b[A\n",
            "Iteration:  23% 116/500 [01:27<05:00,  1.28it/s]\u001b[A\n",
            "Iteration:  23% 117/500 [01:27<05:01,  1.27it/s]\u001b[A\n",
            "Iteration:  24% 118/500 [01:28<04:59,  1.28it/s]\u001b[A\n",
            "Iteration:  24% 119/500 [01:29<04:57,  1.28it/s]\u001b[A\n",
            "Iteration:  24% 120/500 [01:30<04:56,  1.28it/s]\u001b[A\n",
            "Iteration:  24% 121/500 [01:30<04:55,  1.28it/s]\u001b[A\n",
            "Iteration:  24% 122/500 [01:31<04:55,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 123/500 [01:32<04:54,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 124/500 [01:33<04:53,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 125/500 [01:34<04:52,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 126/500 [01:34<04:52,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 127/500 [01:35<04:52,  1.28it/s]\u001b[A\n",
            "Iteration:  26% 128/500 [01:36<04:52,  1.27it/s]\u001b[A\n",
            "Iteration:  26% 129/500 [01:37<04:50,  1.28it/s]\u001b[A\n",
            "Iteration:  26% 130/500 [01:38<04:49,  1.28it/s]\u001b[A\n",
            "Iteration:  26% 131/500 [01:38<04:49,  1.27it/s]\u001b[A\n",
            "Iteration:  26% 132/500 [01:39<04:50,  1.27it/s]\u001b[A\n",
            "Iteration:  27% 133/500 [01:40<04:49,  1.27it/s]\u001b[A\n",
            "Iteration:  27% 134/500 [01:41<04:48,  1.27it/s]\u001b[A\n",
            "Iteration:  27% 135/500 [01:41<04:49,  1.26it/s]\u001b[A\n",
            "Iteration:  27% 136/500 [01:42<04:47,  1.27it/s]\u001b[A\n",
            "Iteration:  27% 137/500 [01:43<04:46,  1.27it/s]\u001b[A\n",
            "Iteration:  28% 138/500 [01:44<04:45,  1.27it/s]\u001b[A\n",
            "Iteration:  28% 139/500 [01:45<04:44,  1.27it/s]\u001b[A\n",
            "Iteration:  28% 140/500 [01:45<04:43,  1.27it/s]\u001b[A\n",
            "Iteration:  28% 141/500 [01:46<04:42,  1.27it/s]\u001b[A\n",
            "Iteration:  28% 142/500 [01:47<04:42,  1.27it/s]\u001b[A\n",
            "Iteration:  29% 143/500 [01:48<04:41,  1.27it/s]\u001b[A\n",
            "Iteration:  29% 144/500 [01:49<04:40,  1.27it/s]\u001b[A\n",
            "Iteration:  29% 145/500 [01:49<04:40,  1.26it/s]\u001b[A\n",
            "Iteration:  29% 146/500 [01:50<04:40,  1.26it/s]\u001b[A\n",
            "Iteration:  29% 147/500 [01:51<04:41,  1.25it/s]\u001b[A\n",
            "Iteration:  30% 148/500 [01:52<04:41,  1.25it/s]\u001b[A\n",
            "Iteration:  30% 149/500 [01:53<04:40,  1.25it/s]\u001b[A{\"learning_rate\": 8.5e-05, \"loss\": 1.1258865451812745, \"step\": 150}\n",
            "\n",
            "Iteration:  30% 150/500 [01:53<04:37,  1.26it/s]\u001b[A\n",
            "Iteration:  30% 151/500 [01:54<04:38,  1.25it/s]\u001b[A\n",
            "Iteration:  30% 152/500 [01:55<04:38,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 153/500 [01:56<04:36,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 154/500 [01:57<04:36,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 155/500 [01:57<04:35,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 156/500 [01:58<04:34,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 157/500 [01:59<04:32,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 158/500 [02:00<04:31,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 159/500 [02:01<04:30,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 160/500 [02:01<04:29,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 161/500 [02:02<04:28,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 162/500 [02:03<04:28,  1.26it/s]\u001b[A\n",
            "Iteration:  33% 163/500 [02:04<04:27,  1.26it/s]\u001b[A\n",
            "Iteration:  33% 164/500 [02:05<04:27,  1.25it/s]\u001b[A\n",
            "Iteration:  33% 165/500 [02:05<04:26,  1.26it/s]\u001b[A\n",
            "Iteration:  33% 166/500 [02:06<04:25,  1.26it/s]\u001b[A\n",
            "Iteration:  33% 167/500 [02:07<04:25,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 168/500 [02:08<04:24,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 169/500 [02:09<04:23,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 170/500 [02:09<04:24,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 171/500 [02:10<04:23,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 172/500 [02:11<04:22,  1.25it/s]\u001b[A\n",
            "Iteration:  35% 173/500 [02:12<04:21,  1.25it/s]\u001b[A\n",
            "Iteration:  35% 174/500 [02:13<04:20,  1.25it/s]\u001b[A\n",
            "Iteration:  35% 175/500 [02:13<04:20,  1.25it/s]\u001b[A\n",
            "Iteration:  35% 176/500 [02:14<04:17,  1.26it/s]\u001b[A\n",
            "Iteration:  35% 177/500 [02:15<04:17,  1.26it/s]\u001b[A\n",
            "Iteration:  36% 178/500 [02:16<04:17,  1.25it/s]\u001b[A\n",
            "Iteration:  36% 179/500 [02:16<04:15,  1.25it/s]\u001b[A\n",
            "Iteration:  36% 180/500 [02:17<04:16,  1.25it/s]\u001b[A\n",
            "Iteration:  36% 181/500 [02:18<04:15,  1.25it/s]\u001b[A\n",
            "Iteration:  36% 182/500 [02:19<04:15,  1.25it/s]\u001b[A\n",
            "Iteration:  37% 183/500 [02:20<04:14,  1.24it/s]\u001b[A\n",
            "Iteration:  37% 184/500 [02:21<04:14,  1.24it/s]\u001b[A\n",
            "Iteration:  37% 185/500 [02:21<04:14,  1.24it/s]\u001b[A\n",
            "Iteration:  37% 186/500 [02:22<04:14,  1.24it/s]\u001b[A\n",
            "Iteration:  37% 187/500 [02:23<04:13,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 188/500 [02:24<04:12,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 189/500 [02:25<04:11,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 190/500 [02:25<04:11,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 191/500 [02:26<04:10,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 192/500 [02:27<04:09,  1.23it/s]\u001b[A\n",
            "Iteration:  39% 193/500 [02:28<04:08,  1.23it/s]\u001b[A\n",
            "Iteration:  39% 194/500 [02:29<04:07,  1.24it/s]\u001b[A\n",
            "Iteration:  39% 195/500 [02:29<04:06,  1.24it/s]\u001b[A\n",
            "Iteration:  39% 196/500 [02:30<04:06,  1.24it/s]\u001b[A\n",
            "Iteration:  39% 197/500 [02:31<04:05,  1.23it/s]\u001b[A\n",
            "Iteration:  40% 198/500 [02:32<04:04,  1.23it/s]\u001b[A\n",
            "Iteration:  40% 199/500 [02:33<04:04,  1.23it/s]\u001b[A{\"learning_rate\": 8e-05, \"loss\": 1.0827317535877228, \"step\": 200}\n",
            "\n",
            "Iteration:  40% 200/500 [02:33<04:02,  1.24it/s]\u001b[A\n",
            "Iteration:  40% 201/500 [02:34<04:01,  1.24it/s]\u001b[A\n",
            "Iteration:  40% 202/500 [02:35<04:00,  1.24it/s]\u001b[A\n",
            "Iteration:  41% 203/500 [02:36<04:00,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 204/500 [02:37<04:00,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 205/500 [02:38<03:58,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 206/500 [02:38<03:58,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 207/500 [02:39<03:57,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 208/500 [02:40<03:56,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 209/500 [02:41<03:56,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 210/500 [02:42<03:55,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 211/500 [02:42<03:55,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 212/500 [02:43<03:53,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 213/500 [02:44<03:53,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 214/500 [02:45<03:52,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 215/500 [02:46<03:51,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 216/500 [02:46<03:50,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 217/500 [02:47<03:49,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 218/500 [02:48<03:48,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 219/500 [02:49<03:48,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 220/500 [02:50<03:47,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 221/500 [02:51<03:46,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 222/500 [02:51<03:45,  1.23it/s]\u001b[A\n",
            "Iteration:  45% 223/500 [02:52<03:45,  1.23it/s]\u001b[A\n",
            "Iteration:  45% 224/500 [02:53<03:45,  1.22it/s]\u001b[A\n",
            "Iteration:  45% 225/500 [02:54<03:44,  1.22it/s]\u001b[A\n",
            "Iteration:  45% 226/500 [02:55<03:43,  1.22it/s]\u001b[A\n",
            "Iteration:  45% 227/500 [02:55<03:43,  1.22it/s]\u001b[A\n",
            "Iteration:  46% 228/500 [02:56<03:42,  1.22it/s]\u001b[A\n",
            "Iteration:  46% 229/500 [02:57<03:41,  1.22it/s]\u001b[A\n",
            "Iteration:  46% 230/500 [02:58<03:41,  1.22it/s]\u001b[A\n",
            "Iteration:  46% 231/500 [02:59<03:40,  1.22it/s]\u001b[A\n",
            "Iteration:  46% 232/500 [03:00<03:39,  1.22it/s]\u001b[A\n",
            "Iteration:  47% 233/500 [03:00<03:38,  1.22it/s]\u001b[A\n",
            "Iteration:  47% 234/500 [03:01<03:37,  1.22it/s]\u001b[A\n",
            "Iteration:  47% 235/500 [03:02<03:37,  1.22it/s]\u001b[A\n",
            "Iteration:  47% 236/500 [03:03<03:36,  1.22it/s]\u001b[A\n",
            "Iteration:  47% 237/500 [03:04<03:35,  1.22it/s]\u001b[A\n",
            "Iteration:  48% 238/500 [03:04<03:35,  1.22it/s]\u001b[A\n",
            "Iteration:  48% 239/500 [03:05<03:33,  1.22it/s]\u001b[A\n",
            "Iteration:  48% 240/500 [03:06<03:32,  1.22it/s]\u001b[A\n",
            "Iteration:  48% 241/500 [03:07<03:32,  1.22it/s]\u001b[A\n",
            "Iteration:  48% 242/500 [03:08<03:31,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 243/500 [03:09<03:31,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 244/500 [03:09<03:29,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 245/500 [03:10<03:28,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 246/500 [03:11<03:28,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 247/500 [03:12<03:27,  1.22it/s]\u001b[A\n",
            "Iteration:  50% 248/500 [03:13<03:27,  1.22it/s]\u001b[A\n",
            "Iteration:  50% 249/500 [03:13<03:26,  1.22it/s]\u001b[A{\"learning_rate\": 7.500000000000001e-05, \"loss\": 1.0473747104406357, \"step\": 250}\n",
            "\n",
            "Iteration:  50% 250/500 [03:14<03:25,  1.22it/s]\u001b[A\n",
            "Iteration:  50% 251/500 [03:15<03:25,  1.21it/s]\u001b[A\n",
            "Iteration:  50% 252/500 [03:16<03:24,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 253/500 [03:17<03:23,  1.22it/s]\u001b[A\n",
            "Iteration:  51% 254/500 [03:18<03:22,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 255/500 [03:18<03:22,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 256/500 [03:19<03:21,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 257/500 [03:20<03:20,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 258/500 [03:21<03:20,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 259/500 [03:22<03:19,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 260/500 [03:23<03:18,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 261/500 [03:23<03:17,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 262/500 [03:24<03:17,  1.21it/s]\u001b[A\n",
            "Iteration:  53% 263/500 [03:25<03:16,  1.21it/s]\u001b[A\n",
            "Iteration:  53% 264/500 [03:26<03:16,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 265/500 [03:27<03:15,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 266/500 [03:28<03:14,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 267/500 [03:28<03:13,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 268/500 [03:29<03:12,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 269/500 [03:30<03:11,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 270/500 [03:31<03:10,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 271/500 [03:32<03:09,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 272/500 [03:33<03:08,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 273/500 [03:33<03:07,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 274/500 [03:34<03:07,  1.20it/s]\u001b[A\n",
            "Iteration:  55% 275/500 [03:35<03:06,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 276/500 [03:36<03:05,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 277/500 [03:37<03:04,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 278/500 [03:38<03:03,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 279/500 [03:38<03:03,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 280/500 [03:39<03:02,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 281/500 [03:40<03:01,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 282/500 [03:41<03:01,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 283/500 [03:42<02:59,  1.21it/s]\u001b[A\n",
            "Iteration:  57% 284/500 [03:42<02:59,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 285/500 [03:43<02:58,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 286/500 [03:44<02:58,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 287/500 [03:45<02:56,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 288/500 [03:46<02:55,  1.21it/s]\u001b[A\n",
            "Iteration:  58% 289/500 [03:47<02:55,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 290/500 [03:47<02:54,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 291/500 [03:48<02:53,  1.21it/s]\u001b[A\n",
            "Iteration:  58% 292/500 [03:49<02:52,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 293/500 [03:50<02:52,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 294/500 [03:51<02:52,  1.19it/s]\u001b[A\n",
            "Iteration:  59% 295/500 [03:52<02:51,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 296/500 [03:52<02:50,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 297/500 [03:53<02:49,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 298/500 [03:54<02:48,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 299/500 [03:55<02:48,  1.19it/s]\u001b[A{\"learning_rate\": 7e-05, \"loss\": 1.0572323286533356, \"step\": 300}\n",
            "\n",
            "Iteration:  60% 300/500 [03:56<02:47,  1.19it/s]\u001b[A\n",
            "Iteration:  60% 301/500 [03:57<02:45,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 302/500 [03:57<02:45,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 303/500 [03:58<02:44,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 304/500 [03:59<02:43,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 305/500 [04:00<02:42,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 306/500 [04:01<02:41,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 307/500 [04:02<02:41,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 308/500 [04:03<02:40,  1.19it/s]\u001b[A\n",
            "Iteration:  62% 309/500 [04:03<02:39,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 310/500 [04:04<02:39,  1.19it/s]\u001b[A\n",
            "Iteration:  62% 311/500 [04:05<02:37,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 312/500 [04:06<02:36,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 313/500 [04:07<02:35,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 314/500 [04:07<02:34,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 315/500 [04:08<02:34,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 316/500 [04:09<02:33,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 317/500 [04:10<02:32,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 318/500 [04:11<02:31,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 319/500 [04:12<02:30,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 320/500 [04:12<02:29,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 321/500 [04:13<02:28,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 322/500 [04:14<02:28,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 323/500 [04:15<02:27,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 324/500 [04:16<02:26,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 325/500 [04:17<02:25,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 326/500 [04:17<02:24,  1.21it/s]\u001b[A\n",
            "Iteration:  65% 327/500 [04:18<02:23,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 328/500 [04:19<02:22,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 329/500 [04:20<02:22,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 330/500 [04:21<02:21,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 331/500 [04:22<02:20,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 332/500 [04:22<02:19,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 333/500 [04:23<02:18,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 334/500 [04:24<02:17,  1.21it/s]\u001b[A\n",
            "Iteration:  67% 335/500 [04:25<02:17,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 336/500 [04:26<02:16,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 337/500 [04:27<02:15,  1.21it/s]\u001b[A\n",
            "Iteration:  68% 338/500 [04:27<02:14,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 339/500 [04:28<02:13,  1.21it/s]\u001b[A\n",
            "Iteration:  68% 340/500 [04:29<02:12,  1.21it/s]\u001b[A\n",
            "Iteration:  68% 341/500 [04:30<02:12,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 342/500 [04:31<02:11,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 343/500 [04:32<02:10,  1.21it/s]\u001b[A\n",
            "Iteration:  69% 344/500 [04:32<02:09,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 345/500 [04:33<02:08,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 346/500 [04:34<02:07,  1.21it/s]\u001b[A\n",
            "Iteration:  69% 347/500 [04:35<02:07,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 348/500 [04:36<02:06,  1.21it/s]\u001b[A\n",
            "Iteration:  70% 349/500 [04:37<02:05,  1.20it/s]\u001b[A{\"learning_rate\": 6.500000000000001e-05, \"loss\": 0.985585076212883, \"step\": 350}\n",
            "\n",
            "Iteration:  70% 350/500 [04:37<02:04,  1.21it/s]\u001b[A\n",
            "Iteration:  70% 351/500 [04:38<02:04,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 352/500 [04:39<02:02,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 353/500 [04:40<02:02,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 354/500 [04:41<02:01,  1.21it/s]\u001b[A\n",
            "Iteration:  71% 355/500 [04:42<02:00,  1.21it/s]\u001b[A\n",
            "Iteration:  71% 356/500 [04:42<01:58,  1.21it/s]\u001b[A\n",
            "Iteration:  71% 357/500 [04:43<01:58,  1.21it/s]\u001b[A\n",
            "Iteration:  72% 358/500 [04:44<01:57,  1.21it/s]\u001b[A\n",
            "Iteration:  72% 359/500 [04:45<01:56,  1.21it/s]\u001b[A\n",
            "Iteration:  72% 360/500 [04:46<01:55,  1.21it/s]\u001b[A\n",
            "Iteration:  72% 361/500 [04:47<01:55,  1.20it/s]\u001b[A\n",
            "Iteration:  72% 362/500 [04:47<01:54,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 363/500 [04:48<01:53,  1.21it/s]\u001b[A\n",
            "Iteration:  73% 364/500 [04:49<01:52,  1.21it/s]\u001b[A\n",
            "Iteration:  73% 365/500 [04:50<01:52,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 366/500 [04:51<01:51,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 367/500 [04:52<01:50,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 368/500 [04:52<01:49,  1.21it/s]\u001b[A\n",
            "Iteration:  74% 369/500 [04:53<01:49,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 370/500 [04:54<01:47,  1.21it/s]\u001b[A\n",
            "Iteration:  74% 371/500 [04:55<01:47,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 372/500 [04:56<01:46,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 373/500 [04:57<01:45,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 374/500 [04:57<01:44,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 375/500 [04:58<01:43,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 376/500 [04:59<01:42,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 377/500 [05:00<01:42,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 378/500 [05:01<01:40,  1.21it/s]\u001b[A\n",
            "Iteration:  76% 379/500 [05:01<01:40,  1.21it/s]\u001b[A\n",
            "Iteration:  76% 380/500 [05:02<01:39,  1.21it/s]\u001b[A\n",
            "Iteration:  76% 381/500 [05:03<01:38,  1.21it/s]\u001b[A\n",
            "Iteration:  76% 382/500 [05:04<01:37,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 383/500 [05:05<01:36,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 384/500 [05:06<01:35,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 385/500 [05:06<01:34,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 386/500 [05:07<01:34,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 387/500 [05:08<01:33,  1.21it/s]\u001b[A\n",
            "Iteration:  78% 388/500 [05:09<01:32,  1.21it/s]\u001b[A\n",
            "Iteration:  78% 389/500 [05:10<01:31,  1.21it/s]\u001b[A\n",
            "Iteration:  78% 390/500 [05:11<01:30,  1.21it/s]\u001b[A\n",
            "Iteration:  78% 391/500 [05:11<01:30,  1.21it/s]\u001b[A\n",
            "Iteration:  78% 392/500 [05:12<01:29,  1.21it/s]\u001b[A\n",
            "Iteration:  79% 393/500 [05:13<01:28,  1.21it/s]\u001b[A\n",
            "Iteration:  79% 394/500 [05:14<01:27,  1.21it/s]\u001b[A\n",
            "Iteration:  79% 395/500 [05:15<01:27,  1.21it/s]\u001b[A\n",
            "Iteration:  79% 396/500 [05:16<01:26,  1.21it/s]\u001b[A\n",
            "Iteration:  79% 397/500 [05:16<01:25,  1.21it/s]\u001b[A\n",
            "Iteration:  80% 398/500 [05:17<01:24,  1.21it/s]\u001b[A\n",
            "Iteration:  80% 399/500 [05:18<01:23,  1.21it/s]\u001b[A{\"learning_rate\": 6e-05, \"loss\": 0.9633276921510696, \"step\": 400}\n",
            "\n",
            "Iteration:  80% 400/500 [05:19<01:22,  1.21it/s]\u001b[A\n",
            "Iteration:  80% 401/500 [05:20<01:22,  1.20it/s]\u001b[A\n",
            "Iteration:  80% 402/500 [05:21<01:21,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 403/500 [05:21<01:20,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 404/500 [05:22<01:19,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 405/500 [05:23<01:18,  1.21it/s]\u001b[A\n",
            "Iteration:  81% 406/500 [05:24<01:17,  1.21it/s]\u001b[A\n",
            "Iteration:  81% 407/500 [05:25<01:17,  1.21it/s]\u001b[A\n",
            "Iteration:  82% 408/500 [05:25<01:16,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 409/500 [05:26<01:15,  1.21it/s]\u001b[A\n",
            "Iteration:  82% 410/500 [05:27<01:14,  1.21it/s]\u001b[A\n",
            "Iteration:  82% 411/500 [05:28<01:14,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 412/500 [05:29<01:13,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 413/500 [05:30<01:12,  1.21it/s]\u001b[A\n",
            "Iteration:  83% 414/500 [05:30<01:11,  1.21it/s]\u001b[A\n",
            "Iteration:  83% 415/500 [05:31<01:10,  1.21it/s]\u001b[A\n",
            "Iteration:  83% 416/500 [05:32<01:09,  1.21it/s]\u001b[A\n",
            "Iteration:  83% 417/500 [05:33<01:08,  1.21it/s]\u001b[A\n",
            "Iteration:  84% 418/500 [05:34<01:07,  1.21it/s]\u001b[A\n",
            "Iteration:  84% 419/500 [05:35<01:07,  1.21it/s]\u001b[A\n",
            "Iteration:  84% 420/500 [05:35<01:06,  1.21it/s]\u001b[A\n",
            "Iteration:  84% 421/500 [05:36<01:05,  1.21it/s]\u001b[A\n",
            "Iteration:  84% 422/500 [05:37<01:04,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 423/500 [05:38<01:03,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 424/500 [05:39<01:02,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 425/500 [05:40<01:02,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 426/500 [05:40<01:01,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 427/500 [05:41<01:00,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 428/500 [05:42<00:59,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 429/500 [05:43<00:58,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 430/500 [05:44<00:57,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 431/500 [05:45<00:56,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 432/500 [05:45<00:56,  1.21it/s]\u001b[A\n",
            "Iteration:  87% 433/500 [05:46<00:55,  1.22it/s]\u001b[A\n",
            "Iteration:  87% 434/500 [05:47<00:54,  1.21it/s]\u001b[A\n",
            "Iteration:  87% 435/500 [05:48<00:53,  1.21it/s]\u001b[A\n",
            "Iteration:  87% 436/500 [05:49<00:52,  1.22it/s]\u001b[A\n",
            "Iteration:  87% 437/500 [05:49<00:52,  1.21it/s]\u001b[A\n",
            "Iteration:  88% 438/500 [05:50<00:51,  1.21it/s]\u001b[A\n",
            "Iteration:  88% 439/500 [05:51<00:50,  1.22it/s]\u001b[A\n",
            "Iteration:  88% 440/500 [05:52<00:49,  1.21it/s]\u001b[A\n",
            "Iteration:  88% 441/500 [05:53<00:48,  1.21it/s]\u001b[A\n",
            "Iteration:  88% 442/500 [05:54<00:47,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 443/500 [05:54<00:47,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 444/500 [05:55<00:46,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 445/500 [05:56<00:45,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 446/500 [05:57<00:44,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 447/500 [05:58<00:43,  1.21it/s]\u001b[A\n",
            "Iteration:  90% 448/500 [05:59<00:43,  1.21it/s]\u001b[A\n",
            "Iteration:  90% 449/500 [05:59<00:42,  1.21it/s]\u001b[A{\"learning_rate\": 5.500000000000001e-05, \"loss\": 0.9490384989976883, \"step\": 450}\n",
            "\n",
            "Iteration:  90% 450/500 [06:00<00:41,  1.21it/s]\u001b[A\n",
            "Iteration:  90% 451/500 [06:01<00:40,  1.21it/s]\u001b[A\n",
            "Iteration:  90% 452/500 [06:02<00:39,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 453/500 [06:03<00:38,  1.21it/s]\u001b[A\n",
            "Iteration:  91% 454/500 [06:04<00:38,  1.21it/s]\u001b[A\n",
            "Iteration:  91% 455/500 [06:04<00:37,  1.21it/s]\u001b[A\n",
            "Iteration:  91% 456/500 [06:05<00:36,  1.21it/s]\u001b[A\n",
            "Iteration:  91% 457/500 [06:06<00:35,  1.21it/s]\u001b[A\n",
            "Iteration:  92% 458/500 [06:07<00:34,  1.21it/s]\u001b[A\n",
            "Iteration:  92% 459/500 [06:08<00:34,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 460/500 [06:09<00:33,  1.21it/s]\u001b[A\n",
            "Iteration:  92% 461/500 [06:09<00:32,  1.21it/s]\u001b[A\n",
            "Iteration:  92% 462/500 [06:10<00:31,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 463/500 [06:11<00:30,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 464/500 [06:12<00:29,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 465/500 [06:13<00:28,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 466/500 [06:13<00:28,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 467/500 [06:14<00:27,  1.21it/s]\u001b[A\n",
            "Iteration:  94% 468/500 [06:15<00:26,  1.21it/s]\u001b[A\n",
            "Iteration:  94% 469/500 [06:16<00:25,  1.21it/s]\u001b[A\n",
            "Iteration:  94% 470/500 [06:17<00:24,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 471/500 [06:18<00:23,  1.21it/s]\u001b[A\n",
            "Iteration:  94% 472/500 [06:18<00:23,  1.21it/s]\u001b[A\n",
            "Iteration:  95% 473/500 [06:19<00:22,  1.21it/s]\u001b[A\n",
            "Iteration:  95% 474/500 [06:20<00:21,  1.21it/s]\u001b[A\n",
            "Iteration:  95% 475/500 [06:21<00:20,  1.21it/s]\u001b[A\n",
            "Iteration:  95% 476/500 [06:22<00:19,  1.21it/s]\u001b[A\n",
            "Iteration:  95% 477/500 [06:23<00:19,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 478/500 [06:23<00:18,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 479/500 [06:24<00:17,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 480/500 [06:25<00:16,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 481/500 [06:26<00:15,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 482/500 [06:27<00:14,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 483/500 [06:28<00:14,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 484/500 [06:28<00:13,  1.21it/s]\u001b[A\n",
            "Iteration:  97% 485/500 [06:29<00:12,  1.21it/s]\u001b[A\n",
            "Iteration:  97% 486/500 [06:30<00:11,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 487/500 [06:31<00:10,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 488/500 [06:32<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 489/500 [06:33<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 490/500 [06:33<00:08,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 491/500 [06:34<00:07,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 492/500 [06:35<00:06,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 493/500 [06:36<00:05,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 494/500 [06:37<00:04,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 495/500 [06:37<00:04,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 496/500 [06:38<00:03,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 497/500 [06:39<00:02,  1.21it/s]\u001b[A\n",
            "Iteration: 100% 498/500 [06:40<00:01,  1.21it/s]\u001b[A\n",
            "Iteration: 100% 499/500 [06:41<00:00,  1.20it/s]\u001b[A{\"learning_rate\": 5e-05, \"loss\": 0.9213245272636413, \"step\": 500}\n",
            "\n",
            "Iteration: 100% 500/500 [06:42<00:00,  1.24it/s]\n",
            "Epoch:  50% 1/2 [06:42<06:42, 402.13s/it]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/500 [00:00<06:45,  1.23it/s]\u001b[A\n",
            "Iteration:   0% 2/500 [00:01<06:48,  1.22it/s]\u001b[A\n",
            "Iteration:   1% 3/500 [00:02<06:48,  1.22it/s]\u001b[A\n",
            "Iteration:   1% 4/500 [00:03<06:49,  1.21it/s]\u001b[A\n",
            "Iteration:   1% 5/500 [00:04<06:49,  1.21it/s]\u001b[A\n",
            "Iteration:   1% 6/500 [00:04<06:48,  1.21it/s]\u001b[A\n",
            "Iteration:   1% 7/500 [00:05<06:47,  1.21it/s]\u001b[A\n",
            "Iteration:   2% 8/500 [00:06<06:46,  1.21it/s]\u001b[A\n",
            "Iteration:   2% 9/500 [00:07<06:46,  1.21it/s]\u001b[A\n",
            "Iteration:   2% 10/500 [00:08<06:45,  1.21it/s]\u001b[A\n",
            "Iteration:   2% 11/500 [00:09<06:45,  1.21it/s]\u001b[A\n",
            "Iteration:   2% 12/500 [00:09<06:44,  1.21it/s]\u001b[A\n",
            "Iteration:   3% 13/500 [00:10<06:44,  1.20it/s]\u001b[A\n",
            "Iteration:   3% 14/500 [00:11<06:44,  1.20it/s]\u001b[A\n",
            "Iteration:   3% 15/500 [00:12<06:43,  1.20it/s]\u001b[A\n",
            "Iteration:   3% 16/500 [00:13<06:41,  1.21it/s]\u001b[A\n",
            "Iteration:   3% 17/500 [00:14<06:40,  1.21it/s]\u001b[A\n",
            "Iteration:   4% 18/500 [00:14<06:40,  1.20it/s]\u001b[A\n",
            "Iteration:   4% 19/500 [00:15<06:38,  1.21it/s]\u001b[A\n",
            "Iteration:   4% 20/500 [00:16<06:37,  1.21it/s]\u001b[A\n",
            "Iteration:   4% 21/500 [00:17<06:36,  1.21it/s]\u001b[A\n",
            "Iteration:   4% 22/500 [00:18<06:33,  1.21it/s]\u001b[A\n",
            "Iteration:   5% 23/500 [00:19<06:37,  1.20it/s]\u001b[A\n",
            "Iteration:   5% 24/500 [00:19<06:35,  1.20it/s]\u001b[A\n",
            "Iteration:   5% 25/500 [00:20<06:33,  1.21it/s]\u001b[A\n",
            "Iteration:   5% 26/500 [00:21<06:34,  1.20it/s]\u001b[A\n",
            "Iteration:   5% 27/500 [00:22<06:34,  1.20it/s]\u001b[A\n",
            "Iteration:   6% 28/500 [00:23<06:31,  1.20it/s]\u001b[A\n",
            "Iteration:   6% 29/500 [00:24<06:31,  1.20it/s]\u001b[A\n",
            "Iteration:   6% 30/500 [00:24<06:30,  1.20it/s]\u001b[A\n",
            "Iteration:   6% 31/500 [00:25<06:28,  1.21it/s]\u001b[A\n",
            "Iteration:   6% 32/500 [00:26<06:27,  1.21it/s]\u001b[A\n",
            "Iteration:   7% 33/500 [00:27<06:27,  1.20it/s]\u001b[A\n",
            "Iteration:   7% 34/500 [00:28<06:27,  1.20it/s]\u001b[A\n",
            "Iteration:   7% 35/500 [00:29<06:25,  1.21it/s]\u001b[A\n",
            "Iteration:   7% 36/500 [00:29<06:24,  1.21it/s]\u001b[A\n",
            "Iteration:   7% 37/500 [00:30<06:24,  1.20it/s]\u001b[A\n",
            "Iteration:   8% 38/500 [00:31<06:23,  1.21it/s]\u001b[A\n",
            "Iteration:   8% 39/500 [00:32<06:23,  1.20it/s]\u001b[A\n",
            "Iteration:   8% 40/500 [00:33<06:22,  1.20it/s]\u001b[A\n",
            "Iteration:   8% 41/500 [00:34<06:21,  1.20it/s]\u001b[A\n",
            "Iteration:   8% 42/500 [00:34<06:20,  1.20it/s]\u001b[A\n",
            "Iteration:   9% 43/500 [00:35<06:20,  1.20it/s]\u001b[A\n",
            "Iteration:   9% 44/500 [00:36<06:19,  1.20it/s]\u001b[A\n",
            "Iteration:   9% 45/500 [00:37<06:17,  1.21it/s]\u001b[A\n",
            "Iteration:   9% 46/500 [00:38<06:17,  1.20it/s]\u001b[A\n",
            "Iteration:   9% 47/500 [00:39<06:17,  1.20it/s]\u001b[A\n",
            "Iteration:  10% 48/500 [00:39<06:16,  1.20it/s]\u001b[A\n",
            "Iteration:  10% 49/500 [00:40<06:15,  1.20it/s]\u001b[A{\"learning_rate\": 4.5e-05, \"loss\": 0.6924638837575913, \"step\": 550}\n",
            "\n",
            "Iteration:  10% 50/500 [00:41<06:14,  1.20it/s]\u001b[A\n",
            "Iteration:  10% 51/500 [00:42<06:13,  1.20it/s]\u001b[A\n",
            "Iteration:  10% 52/500 [00:43<06:11,  1.21it/s]\u001b[A\n",
            "Iteration:  11% 53/500 [00:43<06:11,  1.20it/s]\u001b[A\n",
            "Iteration:  11% 54/500 [00:44<06:11,  1.20it/s]\u001b[A\n",
            "Iteration:  11% 55/500 [00:45<06:09,  1.20it/s]\u001b[A\n",
            "Iteration:  11% 56/500 [00:46<06:08,  1.20it/s]\u001b[A\n",
            "Iteration:  11% 57/500 [00:47<06:09,  1.20it/s]\u001b[A\n",
            "Iteration:  12% 58/500 [00:48<06:07,  1.20it/s]\u001b[A\n",
            "Iteration:  12% 59/500 [00:48<06:06,  1.20it/s]\u001b[A\n",
            "Iteration:  12% 60/500 [00:49<06:05,  1.20it/s]\u001b[A\n",
            "Iteration:  12% 61/500 [00:50<06:05,  1.20it/s]\u001b[A\n",
            "Iteration:  12% 62/500 [00:51<06:06,  1.20it/s]\u001b[A\n",
            "Iteration:  13% 63/500 [00:52<06:03,  1.20it/s]\u001b[A\n",
            "Iteration:  13% 64/500 [00:53<06:02,  1.20it/s]\u001b[A\n",
            "Iteration:  13% 65/500 [00:53<06:01,  1.20it/s]\u001b[A\n",
            "Iteration:  13% 66/500 [00:54<06:01,  1.20it/s]\u001b[A\n",
            "Iteration:  13% 67/500 [00:55<06:00,  1.20it/s]\u001b[A\n",
            "Iteration:  14% 68/500 [00:56<05:59,  1.20it/s]\u001b[A\n",
            "Iteration:  14% 69/500 [00:57<05:59,  1.20it/s]\u001b[A\n",
            "Iteration:  14% 70/500 [00:58<05:57,  1.20it/s]\u001b[A\n",
            "Iteration:  14% 71/500 [00:58<05:56,  1.20it/s]\u001b[A\n",
            "Iteration:  14% 72/500 [00:59<05:55,  1.20it/s]\u001b[A\n",
            "Iteration:  15% 73/500 [01:00<05:54,  1.20it/s]\u001b[A\n",
            "Iteration:  15% 74/500 [01:01<05:53,  1.21it/s]\u001b[A\n",
            "Iteration:  15% 75/500 [01:02<05:53,  1.20it/s]\u001b[A\n",
            "Iteration:  15% 76/500 [01:03<05:52,  1.20it/s]\u001b[A\n",
            "Iteration:  15% 77/500 [01:03<05:52,  1.20it/s]\u001b[A\n",
            "Iteration:  16% 78/500 [01:04<05:49,  1.21it/s]\u001b[A\n",
            "Iteration:  16% 79/500 [01:05<05:47,  1.21it/s]\u001b[A\n",
            "Iteration:  16% 80/500 [01:06<05:47,  1.21it/s]\u001b[A\n",
            "Iteration:  16% 81/500 [01:07<05:46,  1.21it/s]\u001b[A\n",
            "Iteration:  16% 82/500 [01:08<05:45,  1.21it/s]\u001b[A\n",
            "Iteration:  17% 83/500 [01:08<05:45,  1.21it/s]\u001b[A\n",
            "Iteration:  17% 84/500 [01:09<05:43,  1.21it/s]\u001b[A\n",
            "Iteration:  17% 85/500 [01:10<05:43,  1.21it/s]\u001b[A\n",
            "Iteration:  17% 86/500 [01:11<05:44,  1.20it/s]\u001b[A\n",
            "Iteration:  17% 87/500 [01:12<05:42,  1.21it/s]\u001b[A\n",
            "Iteration:  18% 88/500 [01:13<05:41,  1.21it/s]\u001b[A\n",
            "Iteration:  18% 89/500 [01:13<05:41,  1.20it/s]\u001b[A\n",
            "Iteration:  18% 90/500 [01:14<05:40,  1.20it/s]\u001b[A\n",
            "Iteration:  18% 91/500 [01:15<05:39,  1.20it/s]\u001b[A\n",
            "Iteration:  18% 92/500 [01:16<05:38,  1.20it/s]\u001b[A\n",
            "Iteration:  19% 93/500 [01:17<05:38,  1.20it/s]\u001b[A\n",
            "Iteration:  19% 94/500 [01:18<05:37,  1.20it/s]\u001b[A\n",
            "Iteration:  19% 95/500 [01:18<05:37,  1.20it/s]\u001b[A\n",
            "Iteration:  19% 96/500 [01:19<05:35,  1.21it/s]\u001b[A\n",
            "Iteration:  19% 97/500 [01:20<05:34,  1.20it/s]\u001b[A\n",
            "Iteration:  20% 98/500 [01:21<05:34,  1.20it/s]\u001b[A\n",
            "Iteration:  20% 99/500 [01:22<05:33,  1.20it/s]\u001b[A{\"learning_rate\": 4e-05, \"loss\": 0.7055860403180122, \"step\": 600}\n",
            "\n",
            "Iteration:  20% 100/500 [01:23<05:32,  1.20it/s]\u001b[A\n",
            "Iteration:  20% 101/500 [01:23<05:31,  1.20it/s]\u001b[A\n",
            "Iteration:  20% 102/500 [01:24<05:31,  1.20it/s]\u001b[A\n",
            "Iteration:  21% 103/500 [01:25<05:30,  1.20it/s]\u001b[A\n",
            "Iteration:  21% 104/500 [01:26<05:28,  1.21it/s]\u001b[A\n",
            "Iteration:  21% 105/500 [01:27<05:27,  1.21it/s]\u001b[A\n",
            "Iteration:  21% 106/500 [01:28<05:26,  1.21it/s]\u001b[A\n",
            "Iteration:  21% 107/500 [01:28<05:26,  1.20it/s]\u001b[A\n",
            "Iteration:  22% 108/500 [01:29<05:26,  1.20it/s]\u001b[A\n",
            "Iteration:  22% 109/500 [01:30<05:24,  1.20it/s]\u001b[A\n",
            "Iteration:  22% 110/500 [01:31<05:24,  1.20it/s]\u001b[A\n",
            "Iteration:  22% 111/500 [01:32<05:22,  1.21it/s]\u001b[A\n",
            "Iteration:  22% 112/500 [01:32<05:21,  1.21it/s]\u001b[A\n",
            "Iteration:  23% 113/500 [01:33<05:19,  1.21it/s]\u001b[A\n",
            "Iteration:  23% 114/500 [01:34<05:19,  1.21it/s]\u001b[A\n",
            "Iteration:  23% 115/500 [01:35<05:19,  1.20it/s]\u001b[A\n",
            "Iteration:  23% 116/500 [01:36<05:19,  1.20it/s]\u001b[A\n",
            "Iteration:  23% 117/500 [01:37<05:17,  1.21it/s]\u001b[A\n",
            "Iteration:  24% 118/500 [01:37<05:16,  1.21it/s]\u001b[A\n",
            "Iteration:  24% 119/500 [01:38<05:16,  1.20it/s]\u001b[A\n",
            "Iteration:  24% 120/500 [01:39<05:15,  1.20it/s]\u001b[A\n",
            "Iteration:  24% 121/500 [01:40<05:14,  1.20it/s]\u001b[A\n",
            "Iteration:  24% 122/500 [01:41<05:13,  1.20it/s]\u001b[A\n",
            "Iteration:  25% 123/500 [01:42<05:11,  1.21it/s]\u001b[A\n",
            "Iteration:  25% 124/500 [01:42<05:10,  1.21it/s]\u001b[A\n",
            "Iteration:  25% 125/500 [01:43<05:10,  1.21it/s]\u001b[A\n",
            "Iteration:  25% 126/500 [01:44<05:11,  1.20it/s]\u001b[A\n",
            "Iteration:  25% 127/500 [01:45<05:08,  1.21it/s]\u001b[A\n",
            "Iteration:  26% 128/500 [01:46<05:09,  1.20it/s]\u001b[A\n",
            "Iteration:  26% 129/500 [01:47<05:08,  1.20it/s]\u001b[A\n",
            "Iteration:  26% 130/500 [01:47<05:07,  1.20it/s]\u001b[A\n",
            "Iteration:  26% 131/500 [01:48<05:07,  1.20it/s]\u001b[A\n",
            "Iteration:  26% 132/500 [01:49<05:05,  1.20it/s]\u001b[A\n",
            "Iteration:  27% 133/500 [01:50<05:03,  1.21it/s]\u001b[A\n",
            "Iteration:  27% 134/500 [01:51<05:02,  1.21it/s]\u001b[A\n",
            "Iteration:  27% 135/500 [01:52<05:02,  1.21it/s]\u001b[A\n",
            "Iteration:  27% 136/500 [01:52<05:02,  1.20it/s]\u001b[A\n",
            "Iteration:  27% 137/500 [01:53<05:01,  1.20it/s]\u001b[A\n",
            "Iteration:  28% 138/500 [01:54<05:01,  1.20it/s]\u001b[A\n",
            "Iteration:  28% 139/500 [01:55<05:00,  1.20it/s]\u001b[A\n",
            "Iteration:  28% 140/500 [01:56<04:59,  1.20it/s]\u001b[A\n",
            "Iteration:  28% 141/500 [01:57<04:58,  1.20it/s]\u001b[A\n",
            "Iteration:  28% 142/500 [01:57<04:57,  1.20it/s]\u001b[A\n",
            "Iteration:  29% 143/500 [01:58<04:57,  1.20it/s]\u001b[A\n",
            "Iteration:  29% 144/500 [01:59<04:56,  1.20it/s]\u001b[A\n",
            "Iteration:  29% 145/500 [02:00<04:55,  1.20it/s]\u001b[A\n",
            "Iteration:  29% 146/500 [02:01<04:53,  1.20it/s]\u001b[A\n",
            "Iteration:  29% 147/500 [02:02<04:51,  1.21it/s]\u001b[A\n",
            "Iteration:  30% 148/500 [02:02<04:51,  1.21it/s]\u001b[A\n",
            "Iteration:  30% 149/500 [02:03<04:49,  1.21it/s]\u001b[A{\"learning_rate\": 3.5e-05, \"loss\": 0.6733231019973754, \"step\": 650}\n",
            "\n",
            "Iteration:  30% 150/500 [02:04<04:49,  1.21it/s]\u001b[A\n",
            "Iteration:  30% 151/500 [02:05<04:48,  1.21it/s]\u001b[A\n",
            "Iteration:  30% 152/500 [02:06<04:48,  1.21it/s]\u001b[A\n",
            "Iteration:  31% 153/500 [02:07<04:48,  1.20it/s]\u001b[A\n",
            "Iteration:  31% 154/500 [02:07<04:46,  1.21it/s]\u001b[A\n",
            "Iteration:  31% 155/500 [02:08<04:45,  1.21it/s]\u001b[A\n",
            "Iteration:  31% 156/500 [02:09<04:46,  1.20it/s]\u001b[A\n",
            "Iteration:  31% 157/500 [02:10<04:45,  1.20it/s]\u001b[A\n",
            "Iteration:  32% 158/500 [02:11<04:44,  1.20it/s]\u001b[A\n",
            "Iteration:  32% 159/500 [02:12<04:42,  1.21it/s]\u001b[A\n",
            "Iteration:  32% 160/500 [02:12<04:41,  1.21it/s]\u001b[A\n",
            "Iteration:  32% 161/500 [02:13<04:42,  1.20it/s]\u001b[A\n",
            "Iteration:  32% 162/500 [02:14<04:42,  1.20it/s]\u001b[A\n",
            "Iteration:  33% 163/500 [02:15<04:39,  1.20it/s]\u001b[A\n",
            "Iteration:  33% 164/500 [02:16<04:39,  1.20it/s]\u001b[A\n",
            "Iteration:  33% 165/500 [02:16<04:38,  1.20it/s]\u001b[A\n",
            "Iteration:  33% 166/500 [02:17<04:37,  1.20it/s]\u001b[A\n",
            "Iteration:  33% 167/500 [02:18<04:36,  1.20it/s]\u001b[A\n",
            "Iteration:  34% 168/500 [02:19<04:35,  1.20it/s]\u001b[A\n",
            "Iteration:  34% 169/500 [02:20<04:35,  1.20it/s]\u001b[A\n",
            "Iteration:  34% 170/500 [02:21<04:34,  1.20it/s]\u001b[A\n",
            "Iteration:  34% 171/500 [02:21<04:33,  1.20it/s]\u001b[A\n",
            "Iteration:  34% 172/500 [02:22<04:32,  1.20it/s]\u001b[A\n",
            "Iteration:  35% 173/500 [02:23<04:31,  1.21it/s]\u001b[A\n",
            "Iteration:  35% 174/500 [02:24<04:30,  1.20it/s]\u001b[A\n",
            "Iteration:  35% 175/500 [02:25<04:30,  1.20it/s]\u001b[A\n",
            "Iteration:  35% 176/500 [02:26<04:29,  1.20it/s]\u001b[A\n",
            "Iteration:  35% 177/500 [02:26<04:28,  1.20it/s]\u001b[A\n",
            "Iteration:  36% 178/500 [02:27<04:27,  1.20it/s]\u001b[A\n",
            "Iteration:  36% 179/500 [02:28<04:26,  1.20it/s]\u001b[A\n",
            "Iteration:  36% 180/500 [02:29<04:26,  1.20it/s]\u001b[A\n",
            "Iteration:  36% 181/500 [02:30<04:25,  1.20it/s]\u001b[A\n",
            "Iteration:  36% 182/500 [02:31<04:24,  1.20it/s]\u001b[A\n",
            "Iteration:  37% 183/500 [02:31<04:23,  1.20it/s]\u001b[A\n",
            "Iteration:  37% 184/500 [02:32<04:22,  1.20it/s]\u001b[A\n",
            "Iteration:  37% 185/500 [02:33<04:21,  1.21it/s]\u001b[A\n",
            "Iteration:  37% 186/500 [02:34<04:21,  1.20it/s]\u001b[A\n",
            "Iteration:  37% 187/500 [02:35<04:20,  1.20it/s]\u001b[A\n",
            "Iteration:  38% 188/500 [02:36<04:18,  1.21it/s]\u001b[A\n",
            "Iteration:  38% 189/500 [02:36<04:18,  1.20it/s]\u001b[A\n",
            "Iteration:  38% 190/500 [02:37<04:17,  1.20it/s]\u001b[A\n",
            "Iteration:  38% 191/500 [02:38<04:16,  1.20it/s]\u001b[A\n",
            "Iteration:  38% 192/500 [02:39<04:15,  1.20it/s]\u001b[A\n",
            "Iteration:  39% 193/500 [02:40<04:14,  1.20it/s]\u001b[A\n",
            "Iteration:  39% 194/500 [02:41<04:14,  1.20it/s]\u001b[A\n",
            "Iteration:  39% 195/500 [02:41<04:14,  1.20it/s]\u001b[A\n",
            "Iteration:  39% 196/500 [02:42<04:14,  1.20it/s]\u001b[A\n",
            "Iteration:  39% 197/500 [02:43<04:12,  1.20it/s]\u001b[A\n",
            "Iteration:  40% 198/500 [02:44<04:12,  1.20it/s]\u001b[A\n",
            "Iteration:  40% 199/500 [02:45<04:10,  1.20it/s]\u001b[A{\"learning_rate\": 3e-05, \"loss\": 0.6876810786128044, \"step\": 700}\n",
            "\n",
            "Iteration:  40% 200/500 [02:46<04:10,  1.20it/s]\u001b[A\n",
            "Iteration:  40% 201/500 [02:46<04:08,  1.20it/s]\u001b[A\n",
            "Iteration:  40% 202/500 [02:47<04:07,  1.20it/s]\u001b[A\n",
            "Iteration:  41% 203/500 [02:48<04:06,  1.20it/s]\u001b[A\n",
            "Iteration:  41% 204/500 [02:49<04:05,  1.20it/s]\u001b[A\n",
            "Iteration:  41% 205/500 [02:50<04:04,  1.21it/s]\u001b[A\n",
            "Iteration:  41% 206/500 [02:51<04:04,  1.20it/s]\u001b[A\n",
            "Iteration:  41% 207/500 [02:51<04:03,  1.20it/s]\u001b[A\n",
            "Iteration:  42% 208/500 [02:52<04:02,  1.20it/s]\u001b[A\n",
            "Iteration:  42% 209/500 [02:53<04:01,  1.20it/s]\u001b[A\n",
            "Iteration:  42% 210/500 [02:54<04:00,  1.20it/s]\u001b[A\n",
            "Iteration:  42% 211/500 [02:55<04:00,  1.20it/s]\u001b[A\n",
            "Iteration:  42% 212/500 [02:56<03:59,  1.20it/s]\u001b[A\n",
            "Iteration:  43% 213/500 [02:56<03:58,  1.20it/s]\u001b[A\n",
            "Iteration:  43% 214/500 [02:57<03:58,  1.20it/s]\u001b[A\n",
            "Iteration:  43% 215/500 [02:58<03:56,  1.20it/s]\u001b[A\n",
            "Iteration:  43% 216/500 [02:59<03:54,  1.21it/s]\u001b[A\n",
            "Iteration:  43% 217/500 [03:00<03:54,  1.21it/s]\u001b[A\n",
            "Iteration:  44% 218/500 [03:01<03:53,  1.21it/s]\u001b[A\n",
            "Iteration:  44% 219/500 [03:01<03:52,  1.21it/s]\u001b[A\n",
            "Iteration:  44% 220/500 [03:02<03:52,  1.20it/s]\u001b[A\n",
            "Iteration:  44% 221/500 [03:03<03:51,  1.20it/s]\u001b[A\n",
            "Iteration:  44% 222/500 [03:04<03:50,  1.21it/s]\u001b[A\n",
            "Iteration:  45% 223/500 [03:05<03:50,  1.20it/s]\u001b[A\n",
            "Iteration:  45% 224/500 [03:06<03:49,  1.21it/s]\u001b[A\n",
            "Iteration:  45% 225/500 [03:06<03:48,  1.20it/s]\u001b[A\n",
            "Iteration:  45% 226/500 [03:07<03:47,  1.20it/s]\u001b[A\n",
            "Iteration:  45% 227/500 [03:08<03:47,  1.20it/s]\u001b[A\n",
            "Iteration:  46% 228/500 [03:09<03:45,  1.20it/s]\u001b[A\n",
            "Iteration:  46% 229/500 [03:10<03:43,  1.21it/s]\u001b[A\n",
            "Iteration:  46% 230/500 [03:11<03:43,  1.21it/s]\u001b[A\n",
            "Iteration:  46% 231/500 [03:11<03:43,  1.20it/s]\u001b[A\n",
            "Iteration:  46% 232/500 [03:12<03:41,  1.21it/s]\u001b[A\n",
            "Iteration:  47% 233/500 [03:13<03:40,  1.21it/s]\u001b[A\n",
            "Iteration:  47% 234/500 [03:14<03:39,  1.21it/s]\u001b[A\n",
            "Iteration:  47% 235/500 [03:15<03:39,  1.21it/s]\u001b[A\n",
            "Iteration:  47% 236/500 [03:15<03:37,  1.21it/s]\u001b[A\n",
            "Iteration:  47% 237/500 [03:16<03:37,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 238/500 [03:17<03:37,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 239/500 [03:18<03:35,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 240/500 [03:19<03:34,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 241/500 [03:20<03:33,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 242/500 [03:20<03:33,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 243/500 [03:21<03:32,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 244/500 [03:22<03:31,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 245/500 [03:23<03:30,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 246/500 [03:24<03:29,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 247/500 [03:25<03:30,  1.20it/s]\u001b[A\n",
            "Iteration:  50% 248/500 [03:25<03:28,  1.21it/s]\u001b[A\n",
            "Iteration:  50% 249/500 [03:26<03:28,  1.21it/s]\u001b[A{\"learning_rate\": 2.5e-05, \"loss\": 0.63619777739048, \"step\": 750}\n",
            "\n",
            "Iteration:  50% 250/500 [03:27<03:26,  1.21it/s]\u001b[A\n",
            "Iteration:  50% 251/500 [03:28<03:26,  1.21it/s]\u001b[A\n",
            "Iteration:  50% 252/500 [03:29<03:25,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 253/500 [03:30<03:24,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 254/500 [03:30<03:22,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 255/500 [03:31<03:22,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 256/500 [03:32<03:21,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 257/500 [03:33<03:20,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 258/500 [03:34<03:20,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 259/500 [03:35<03:20,  1.20it/s]\u001b[A\n",
            "Iteration:  52% 260/500 [03:35<03:18,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 261/500 [03:36<03:18,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 262/500 [03:37<03:17,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 263/500 [03:38<03:16,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 264/500 [03:39<03:15,  1.20it/s]\u001b[A\n",
            "Iteration:  53% 265/500 [03:39<03:14,  1.21it/s]\u001b[A\n",
            "Iteration:  53% 266/500 [03:40<03:13,  1.21it/s]\u001b[A\n",
            "Iteration:  53% 267/500 [03:41<03:12,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 268/500 [03:42<03:11,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 269/500 [03:43<03:11,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 270/500 [03:44<03:10,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 271/500 [03:44<03:09,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 272/500 [03:45<03:07,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 273/500 [03:46<03:07,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 274/500 [03:47<03:07,  1.20it/s]\u001b[A\n",
            "Iteration:  55% 275/500 [03:48<03:06,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 276/500 [03:49<03:05,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 277/500 [03:49<03:04,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 278/500 [03:50<03:04,  1.20it/s]\u001b[A\n",
            "Iteration:  56% 279/500 [03:51<03:03,  1.20it/s]\u001b[A\n",
            "Iteration:  56% 280/500 [03:52<03:03,  1.20it/s]\u001b[A\n",
            "Iteration:  56% 281/500 [03:53<03:02,  1.20it/s]\u001b[A\n",
            "Iteration:  56% 282/500 [03:54<03:01,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 283/500 [03:54<02:59,  1.21it/s]\u001b[A\n",
            "Iteration:  57% 284/500 [03:55<02:59,  1.21it/s]\u001b[A\n",
            "Iteration:  57% 285/500 [03:56<02:58,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 286/500 [03:57<02:57,  1.20it/s]\u001b[A\n",
            "Iteration:  57% 287/500 [03:58<02:58,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 288/500 [03:59<02:57,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 289/500 [03:59<02:55,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 290/500 [04:00<02:55,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 291/500 [04:01<02:54,  1.20it/s]\u001b[A\n",
            "Iteration:  58% 292/500 [04:02<02:53,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 293/500 [04:03<02:52,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 294/500 [04:04<02:51,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 295/500 [04:04<02:50,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 296/500 [04:05<02:49,  1.20it/s]\u001b[A\n",
            "Iteration:  59% 297/500 [04:06<02:48,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 298/500 [04:07<02:47,  1.21it/s]\u001b[A\n",
            "Iteration:  60% 299/500 [04:08<02:46,  1.21it/s]\u001b[A{\"learning_rate\": 2e-05, \"loss\": 0.6651107534766197, \"step\": 800}\n",
            "\n",
            "Iteration:  60% 300/500 [04:09<02:46,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 301/500 [04:09<02:45,  1.20it/s]\u001b[A\n",
            "Iteration:  60% 302/500 [04:10<02:44,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 303/500 [04:11<02:43,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 304/500 [04:12<02:43,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 305/500 [04:13<02:42,  1.20it/s]\u001b[A\n",
            "Iteration:  61% 306/500 [04:14<02:40,  1.21it/s]\u001b[A\n",
            "Iteration:  61% 307/500 [04:14<02:40,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 308/500 [04:15<02:39,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 309/500 [04:16<02:39,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 310/500 [04:17<02:38,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 311/500 [04:18<02:37,  1.20it/s]\u001b[A\n",
            "Iteration:  62% 312/500 [04:19<02:37,  1.19it/s]\u001b[A\n",
            "Iteration:  63% 313/500 [04:19<02:36,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 314/500 [04:20<02:35,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 315/500 [04:21<02:34,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 316/500 [04:22<02:33,  1.20it/s]\u001b[A\n",
            "Iteration:  63% 317/500 [04:23<02:32,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 318/500 [04:24<02:31,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 319/500 [04:24<02:30,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 320/500 [04:25<02:29,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 321/500 [04:26<02:29,  1.20it/s]\u001b[A\n",
            "Iteration:  64% 322/500 [04:27<02:28,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 323/500 [04:28<02:27,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 324/500 [04:29<02:26,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 325/500 [04:29<02:25,  1.21it/s]\u001b[A\n",
            "Iteration:  65% 326/500 [04:30<02:24,  1.20it/s]\u001b[A\n",
            "Iteration:  65% 327/500 [04:31<02:23,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 328/500 [04:32<02:22,  1.21it/s]\u001b[A\n",
            "Iteration:  66% 329/500 [04:33<02:22,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 330/500 [04:34<02:21,  1.21it/s]\u001b[A\n",
            "Iteration:  66% 331/500 [04:34<02:20,  1.20it/s]\u001b[A\n",
            "Iteration:  66% 332/500 [04:35<02:19,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 333/500 [04:36<02:18,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 334/500 [04:37<02:17,  1.20it/s]\u001b[A\n",
            "Iteration:  67% 335/500 [04:38<02:16,  1.21it/s]\u001b[A\n",
            "Iteration:  67% 336/500 [04:38<02:15,  1.21it/s]\u001b[A\n",
            "Iteration:  67% 337/500 [04:39<02:15,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 338/500 [04:40<02:14,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 339/500 [04:41<02:13,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 340/500 [04:42<02:13,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 341/500 [04:43<02:12,  1.20it/s]\u001b[A\n",
            "Iteration:  68% 342/500 [04:43<02:11,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 343/500 [04:44<02:10,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 344/500 [04:45<02:09,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 345/500 [04:46<02:08,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 346/500 [04:47<02:08,  1.20it/s]\u001b[A\n",
            "Iteration:  69% 347/500 [04:48<02:07,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 348/500 [04:48<02:06,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 349/500 [04:49<02:06,  1.20it/s]\u001b[A{\"learning_rate\": 1.5e-05, \"loss\": 0.6263788944482803, \"step\": 850}\n",
            "\n",
            "Iteration:  70% 350/500 [04:50<02:05,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 351/500 [04:51<02:04,  1.20it/s]\u001b[A\n",
            "Iteration:  70% 352/500 [04:52<02:04,  1.19it/s]\u001b[A\n",
            "Iteration:  71% 353/500 [04:53<02:02,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 354/500 [04:53<02:01,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 355/500 [04:54<02:00,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 356/500 [04:55<01:59,  1.20it/s]\u001b[A\n",
            "Iteration:  71% 357/500 [04:56<01:58,  1.20it/s]\u001b[A\n",
            "Iteration:  72% 358/500 [04:57<01:58,  1.20it/s]\u001b[A\n",
            "Iteration:  72% 359/500 [04:58<01:57,  1.20it/s]\u001b[A\n",
            "Iteration:  72% 360/500 [04:58<01:56,  1.20it/s]\u001b[A\n",
            "Iteration:  72% 361/500 [04:59<01:55,  1.21it/s]\u001b[A\n",
            "Iteration:  72% 362/500 [05:00<01:54,  1.21it/s]\u001b[A\n",
            "Iteration:  73% 363/500 [05:01<01:53,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 364/500 [05:02<01:53,  1.19it/s]\u001b[A\n",
            "Iteration:  73% 365/500 [05:03<01:52,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 366/500 [05:03<01:52,  1.20it/s]\u001b[A\n",
            "Iteration:  73% 367/500 [05:04<01:51,  1.19it/s]\u001b[A\n",
            "Iteration:  74% 368/500 [05:05<01:50,  1.19it/s]\u001b[A\n",
            "Iteration:  74% 369/500 [05:06<01:49,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 370/500 [05:07<01:48,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 371/500 [05:08<01:47,  1.20it/s]\u001b[A\n",
            "Iteration:  74% 372/500 [05:08<01:46,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 373/500 [05:09<01:45,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 374/500 [05:10<01:45,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 375/500 [05:11<01:44,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 376/500 [05:12<01:43,  1.20it/s]\u001b[A\n",
            "Iteration:  75% 377/500 [05:13<01:42,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 378/500 [05:13<01:41,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 379/500 [05:14<01:40,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 380/500 [05:15<01:39,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 381/500 [05:16<01:38,  1.20it/s]\u001b[A\n",
            "Iteration:  76% 382/500 [05:17<01:38,  1.20it/s]\u001b[A\n",
            "Iteration:  77% 383/500 [05:18<01:37,  1.20it/s]\u001b[A\n",
            "Iteration:  77% 384/500 [05:18<01:36,  1.20it/s]\u001b[A\n",
            "Iteration:  77% 385/500 [05:19<01:35,  1.20it/s]\u001b[A\n",
            "Iteration:  77% 386/500 [05:20<01:34,  1.20it/s]\u001b[A\n",
            "Iteration:  77% 387/500 [05:21<01:34,  1.20it/s]\u001b[A\n",
            "Iteration:  78% 388/500 [05:22<01:33,  1.20it/s]\u001b[A\n",
            "Iteration:  78% 389/500 [05:23<01:32,  1.20it/s]\u001b[A\n",
            "Iteration:  78% 390/500 [05:23<01:31,  1.20it/s]\u001b[A\n",
            "Iteration:  78% 391/500 [05:24<01:30,  1.20it/s]\u001b[A\n",
            "Iteration:  78% 392/500 [05:25<01:29,  1.20it/s]\u001b[A\n",
            "Iteration:  79% 393/500 [05:26<01:29,  1.20it/s]\u001b[A\n",
            "Iteration:  79% 394/500 [05:27<01:28,  1.20it/s]\u001b[A\n",
            "Iteration:  79% 395/500 [05:28<01:28,  1.19it/s]\u001b[A\n",
            "Iteration:  79% 396/500 [05:28<01:27,  1.20it/s]\u001b[A\n",
            "Iteration:  79% 397/500 [05:29<01:25,  1.20it/s]\u001b[A\n",
            "Iteration:  80% 398/500 [05:30<01:24,  1.20it/s]\u001b[A\n",
            "Iteration:  80% 399/500 [05:31<01:24,  1.20it/s]\u001b[A{\"learning_rate\": 1e-05, \"loss\": 0.6680146479606628, \"step\": 900}\n",
            "\n",
            "Iteration:  80% 400/500 [05:32<01:23,  1.20it/s]\u001b[A\n",
            "Iteration:  80% 401/500 [05:33<01:22,  1.20it/s]\u001b[A\n",
            "Iteration:  80% 402/500 [05:33<01:22,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 403/500 [05:34<01:21,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 404/500 [05:35<01:19,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 405/500 [05:36<01:19,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 406/500 [05:37<01:18,  1.20it/s]\u001b[A\n",
            "Iteration:  81% 407/500 [05:38<01:17,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 408/500 [05:38<01:16,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 409/500 [05:39<01:15,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 410/500 [05:40<01:14,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 411/500 [05:41<01:14,  1.20it/s]\u001b[A\n",
            "Iteration:  82% 412/500 [05:42<01:13,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 413/500 [05:43<01:12,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 414/500 [05:43<01:11,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 415/500 [05:44<01:10,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 416/500 [05:45<01:09,  1.20it/s]\u001b[A\n",
            "Iteration:  83% 417/500 [05:46<01:08,  1.20it/s]\u001b[A\n",
            "Iteration:  84% 418/500 [05:47<01:08,  1.20it/s]\u001b[A\n",
            "Iteration:  84% 419/500 [05:48<01:07,  1.19it/s]\u001b[A\n",
            "Iteration:  84% 420/500 [05:48<01:06,  1.20it/s]\u001b[A\n",
            "Iteration:  84% 421/500 [05:49<01:05,  1.20it/s]\u001b[A\n",
            "Iteration:  84% 422/500 [05:50<01:05,  1.20it/s]\u001b[A\n",
            "Iteration:  85% 423/500 [05:51<01:04,  1.20it/s]\u001b[A\n",
            "Iteration:  85% 424/500 [05:52<01:03,  1.20it/s]\u001b[A\n",
            "Iteration:  85% 425/500 [05:53<01:02,  1.20it/s]\u001b[A\n",
            "Iteration:  85% 426/500 [05:53<01:01,  1.20it/s]\u001b[A\n",
            "Iteration:  85% 427/500 [05:54<01:00,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 428/500 [05:55<00:59,  1.20it/s]\u001b[A\n",
            "Iteration:  86% 429/500 [05:56<00:59,  1.20it/s]\u001b[A\n",
            "Iteration:  86% 430/500 [05:57<00:58,  1.20it/s]\u001b[A\n",
            "Iteration:  86% 431/500 [05:58<00:57,  1.20it/s]\u001b[A\n",
            "Iteration:  86% 432/500 [05:58<00:56,  1.20it/s]\u001b[A\n",
            "Iteration:  87% 433/500 [05:59<00:55,  1.20it/s]\u001b[A\n",
            "Iteration:  87% 434/500 [06:00<00:54,  1.20it/s]\u001b[A\n",
            "Iteration:  87% 435/500 [06:01<00:53,  1.20it/s]\u001b[A\n",
            "Iteration:  87% 436/500 [06:02<00:53,  1.20it/s]\u001b[A\n",
            "Iteration:  87% 437/500 [06:03<00:52,  1.20it/s]\u001b[A\n",
            "Iteration:  88% 438/500 [06:03<00:51,  1.20it/s]\u001b[A\n",
            "Iteration:  88% 439/500 [06:04<00:50,  1.20it/s]\u001b[A\n",
            "Iteration:  88% 440/500 [06:05<00:49,  1.20it/s]\u001b[A\n",
            "Iteration:  88% 441/500 [06:06<00:48,  1.20it/s]\u001b[A\n",
            "Iteration:  88% 442/500 [06:07<00:48,  1.20it/s]\u001b[A\n",
            "Iteration:  89% 443/500 [06:08<00:47,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 444/500 [06:08<00:46,  1.20it/s]\u001b[A\n",
            "Iteration:  89% 445/500 [06:09<00:45,  1.20it/s]\u001b[A\n",
            "Iteration:  89% 446/500 [06:10<00:44,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 447/500 [06:11<00:44,  1.20it/s]\u001b[A\n",
            "Iteration:  90% 448/500 [06:12<00:43,  1.20it/s]\u001b[A\n",
            "Iteration:  90% 449/500 [06:13<00:42,  1.20it/s]\u001b[A{\"learning_rate\": 5e-06, \"loss\": 0.5824303787946701, \"step\": 950}\n",
            "\n",
            "Iteration:  90% 450/500 [06:13<00:41,  1.20it/s]\u001b[A\n",
            "Iteration:  90% 451/500 [06:14<00:40,  1.20it/s]\u001b[A\n",
            "Iteration:  90% 452/500 [06:15<00:39,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 453/500 [06:16<00:39,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 454/500 [06:17<00:38,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 455/500 [06:18<00:37,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 456/500 [06:18<00:36,  1.20it/s]\u001b[A\n",
            "Iteration:  91% 457/500 [06:19<00:35,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 458/500 [06:20<00:35,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 459/500 [06:21<00:34,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 460/500 [06:22<00:33,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 461/500 [06:23<00:32,  1.20it/s]\u001b[A\n",
            "Iteration:  92% 462/500 [06:23<00:31,  1.20it/s]\u001b[A\n",
            "Iteration:  93% 463/500 [06:24<00:30,  1.20it/s]\u001b[A\n",
            "Iteration:  93% 464/500 [06:25<00:29,  1.20it/s]\u001b[A\n",
            "Iteration:  93% 465/500 [06:26<00:29,  1.20it/s]\u001b[A\n",
            "Iteration:  93% 466/500 [06:27<00:28,  1.20it/s]\u001b[A\n",
            "Iteration:  93% 467/500 [06:28<00:27,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 468/500 [06:28<00:26,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 469/500 [06:29<00:25,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 470/500 [06:30<00:24,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 471/500 [06:31<00:24,  1.20it/s]\u001b[A\n",
            "Iteration:  94% 472/500 [06:32<00:23,  1.20it/s]\u001b[A\n",
            "Iteration:  95% 473/500 [06:33<00:22,  1.19it/s]\u001b[A\n",
            "Iteration:  95% 474/500 [06:33<00:21,  1.20it/s]\u001b[A\n",
            "Iteration:  95% 475/500 [06:34<00:20,  1.20it/s]\u001b[A\n",
            "Iteration:  95% 476/500 [06:35<00:20,  1.20it/s]\u001b[A\n",
            "Iteration:  95% 477/500 [06:36<00:19,  1.19it/s]\u001b[A\n",
            "Iteration:  96% 478/500 [06:37<00:18,  1.19it/s]\u001b[A\n",
            "Iteration:  96% 479/500 [06:38<00:17,  1.20it/s]\u001b[A\n",
            "Iteration:  96% 480/500 [06:38<00:16,  1.20it/s]\u001b[A\n",
            "Iteration:  96% 481/500 [06:39<00:15,  1.20it/s]\u001b[A\n",
            "Iteration:  96% 482/500 [06:40<00:14,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 483/500 [06:41<00:14,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 484/500 [06:42<00:13,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 485/500 [06:43<00:12,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 486/500 [06:43<00:11,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 487/500 [06:44<00:10,  1.20it/s]\u001b[A\n",
            "Iteration:  98% 488/500 [06:45<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  98% 489/500 [06:46<00:09,  1.20it/s]\u001b[A\n",
            "Iteration:  98% 490/500 [06:47<00:08,  1.20it/s]\u001b[A\n",
            "Iteration:  98% 491/500 [06:48<00:07,  1.20it/s]\u001b[A\n",
            "Iteration:  98% 492/500 [06:48<00:06,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 493/500 [06:49<00:05,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 494/500 [06:50<00:04,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 495/500 [06:51<00:04,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 496/500 [06:52<00:03,  1.20it/s]\u001b[A\n",
            "Iteration:  99% 497/500 [06:53<00:02,  1.20it/s]\u001b[A\n",
            "Iteration: 100% 498/500 [06:53<00:01,  1.20it/s]\u001b[A\n",
            "Iteration: 100% 499/500 [06:54<00:00,  1.20it/s]\u001b[A{\"learning_rate\": 0.0, \"loss\": 0.6410033762454986, \"step\": 1000}\n",
            "\n",
            "Iteration: 100% 500/500 [06:55<00:00,  1.20it/s]\n",
            "Epoch: 100% 2/2 [13:37<00:00, 408.84s/it]\n",
            "06/03/2021 07:10:21 - INFO - __main__ -    global_step = 1000, average loss = 0.8715521307438612\n",
            "06/03/2021 07:10:21 - INFO - utils_ichi -   Creating features from dataset file at ./data/ichi\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   Writing example 0/3000\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   guid: dev-1\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_global_ids: 101 17938 19067 1029 1029 1029 7632 2035 999 1045 2572 2047 2182 2021 2031 2042 24261 2005 2070 2051 1012 2026 26319 2024 1024 3287 3429 1061 2869 1010 1044 25465 2828 2028 1010 10372 2220 3770 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_local_ids: 101 17938 19067 1029 1029 1029 7632 2035 999 1045 2572 2047 2182 2021 2031 2042 24261 2005 2070 2051 1012 2026 26319 2024 1024 3287 3429 1061 2869 1010 1044 25465 2828 2028 1010 10372 2220 3770 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10891 3029 295 187 2403 1 83 20002 229 8 10242 7745 770 1383 5059 20002 315 1491 1957 270 3114\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   label: DISE (id = 1)\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   guid: dev-2\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_global_ids: 101 13408 12436 20876 17962 2026 6513 1998 1045 2074 2288 2083 2383 3348 1998 2014 17962 2024 2200 13408 2054 2071 2023 2022 2013 1029 2054 2064 2057 2079 2000 2131 1996 18348 2091 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_local_ids: 101 13408 12436 20876 17962 2026 6513 1998 1045 2074 2288 2083 2383 3348 1998 2014 17962 2024 2200 13408 2054 2071 2023 2022 2013 1029 2054 2064 2057 2079 2000 2131 1996 18348 2091 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 384 448 8463 8 823 44 66 8463 384 14 6432 3 581 9651\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   label: SOCL (id = 6)\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   guid: dev-3\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_global_ids: 101 5255 3756 2159 2852 1012 1045 2031 6530 3756 21122 2075 2159 2144 2026 9458 2287 1012 2021 2049 2893 2524 1998 2524 1012 2004 1045 1044 3726 9015 2919 6322 1997 2166 2066 2192 3218 1010 28144 21939 2050 1012 1012 1012 1012 1012 2000 2172 2021 1045 2123 1005 1056 2031 2023 5292 10322 4183 2085 1998 28144 21939 2050 2003 2036 2031 2908 1012 2021 2026 2159 2024 3756 1012 1998 1045 2371 2009 2062 2919 4650 2012 2026 2305 2991 2051 1012 2043 1045 2131 2305 2991 2059 2023 3663 2131 2172 2062 2021 2044 1016 2420 2043 1045 2202 2300 2005 5948 2260 2000 2403 3221 2566 2154 2059 2009 2089 2022 5547 1012 1012 1012 1012 1012 1012 1012 1012 1012 20228 2480 12367 2033 2055 2023 4078 19500 5685 3949 1012 2097 2022 2428 18836 2000 2017 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_local_ids: 101 5255 3756 2159 2852 1012 1045 2031 6530 3756 21122 2075 2159 2144 2026 9458 2287 1012 2021 2049 2893 2524 1998 2524 1012 2004 1045 1044 3726 9015 2919 6322 1997 2166 2066 2192 3218 1010 28144 21939 2050 1012 1012 1012 1012 1012 2000 2172 2021 1045 2123 1005 1056 2031 2023 5292 10322 4183 2085 1998 28144 21939 2050 2003 2036 2031 2908 1012 2021 2026 2159 2024 3756 1012 1998 1045 2371 2009 2062 2919 4650 2012 2026 2305 2991 2051 1012 2043 1045 2131 2305 2991 2059 2023 3663 2131 2172 2062 2021 2044 1016 2420 2043 1045 2202 2300 2005 5948 2260 2000 2403 3221 2566 2154 2059 2009 2089 2022 5547 1012 1012 1012 1012 1012 1012 1012 1012 1012 20228 2480 12367 2033 2055 2023 4078 19500 5685 3949 1012 2097 2022 2428 18836 2000 2017 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 643 1612 32 379 3443 1612 20002 32 37 1967 1851 65 149 20002 20002 1036 103 366 159 4 272 20002 57 20002 20002 17 2353 32 20002 174 103 765 8 120 650 20002 3 120 650 640 3 57 28 6 34 515 859 418 683 740 711 6 90 20002 1535 5374 20002 20002 25 4229\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   aspect_indices: 4650 2159 2192 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   label: GOAL (id = 3)\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   guid: dev-4\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_global_ids: 101 4319 3231 1998 1059 2015 7632 1010 1037 2261 6385 3283 1045 2253 2000 1037 5637 3348 20464 12083 1998 5117 1999 5949 2869 25378 1012 1045 10749 21392 2013 1037 3232 1997 4364 1012 1999 1037 2261 2420 1045 2707 1037 2047 3105 1012 2065 1045 2131 1037 4319 3231 1010 2003 2009 2825 2009 2097 2265 2039 3893 2065 1996 2060 4364 2018 2579 1999 5850 1012 1045 2123 1005 1056 2079 5850 1010 2196 2031 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_local_ids: 101 4319 3231 1998 1059 2015 7632 1010 1037 2261 6385 3283 1045 2253 2000 1037 5637 3348 20464 12083 1998 5117 1999 5949 2869 25378 1012 1045 10749 21392 2013 1037 3232 1997 4364 1012 1999 1037 2261 2420 1045 2707 1037 2047 3105 1012 2065 1045 2131 1037 4319 3231 1010 2003 2009 2825 2009 2097 2265 2039 3893 2065 1996 2060 4364 2018 2579 1999 5850 1012 1045 2123 1005 1056 2079 5850 1010 2196 2031 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 432 56 2937 559 120 81 1 49 1322 20002 4799 20002 1 2669 755 200 8684 165 6 1 116 83 3744 137 1 3 432 1816 214 264 419 360 212 3977 1 3966 54 2111\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   label: SOCL (id = 6)\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   *** Example ***\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   guid: dev-5\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_global_ids: 101 1018 2095 2214 2003 2041 1997 2491 2026 1018 2095 2214 2003 1037 10103 1012 2033 1998 2026 3129 2147 2440 2051 1010 2061 1999 1996 2851 2002 2038 2000 2175 2000 2082 1012 2002 2196 4122 2000 2131 5102 1010 2057 2954 2007 2032 2296 2851 1998 2009 2003 2061 2524 2000 2131 2000 2147 2006 2051 2296 2154 999 1996 2851 4627 2007 7491 16142 1998 2049 9643 1012 2002 2097 2707 15209 4303 1010 6886 2477 1012 2002 3504 2005 2477 2000 5466 1012 2002 7807 2673 999 2057 2031 2000 26470 2032 2007 10899 2000 2175 2000 2082 1998 2008 4510 2573 4902 1012 2002 2003 2074 2061 14205 1012 2002 2074 6732 2002 2003 1037 2332 1998 3071 2323 6812 2000 2032 1012 2002 2003 2066 1037 28561 2051 5968 1012 2002 2064 2022 2204 2059 2074 10245 1999 2019 6013 1012 1045 2228 2002 2038 5177 3314 1012 2002 4152 2061 2919 2008 2026 3129 2038 2000 2907 2032 2091 2096 2002 2003 6886 2010 9092 24456 2015 1012 2023 2038 2042 2183 2006 2005 2058 1037 2095 2085 1012 2002 2003 2074 1037 3697 2775 1010 2200 9694 1012 3071 2758 2002 2003 1037 3671 1018 2095 2214 2021 1045 11693 2000 11234 1012 3531 2393 999 2130 2026 3129 2758 2002 2003 3671 2005 2010 2287 1012 2057 2024 2061 13233 2035 1996 2051 2008 2057 2064 2102 3524 2005 2032 2000 4982 2039 999 999 999 999 102 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   input_local_ids: 101 1018 2095 2214 2003 2041 1997 2491 2026 1018 2095 2214 2003 1037 10103 1012 2033 1998 2026 3129 2147 2440 2051 1010 2061 1999 1996 2851 2002 2038 2000 2175 2000 2082 1012 2002 2196 4122 2000 2131 5102 1010 2057 2954 2007 2032 2296 2851 1998 2009 2003 2061 2524 2000 2131 2000 2147 2006 2051 2296 2154 999 1996 2851 4627 2007 7491 16142 1998 2049 9643 1012 2002 2097 2707 15209 4303 1010 6886 2477 1012 2002 3504 2005 2477 2000 5466 1012 2002 7807 2673 999 2057 2031 2000 26470 2032 2007 10899 2000 2175 2000 2082 1998 2008 4510 2573 4902 1012 2002 2003 2074 2061 14205 1012 2002 2074 6732 2002 2003 1037 2332 1998 3071 2323 6812 2000 2032 1012 2002 2003 2066 1037 28561 2051 5968 1012 2002 2064 2022 2204 2059 2074 10245 1999 2019 6013 1012 1045 2228 2002 2038 5177 3314 1012 2002 4152 2061 2919 2008 2026 3129 2038 2000 2907 2032 2091 2096 2002 2003 6886 2010 9092 24456 2015 1012 2023 2038 2042 2183 2006 2005 2058 1037 2095 2085 1012 2002 2003 2074 1037 3697 2775 1010 2200 9694 1012 3071 2758 2002 2003 1037 3671 1018 2095 2214 2021 1045 11693 2000 11234 1012 3531 2393 999 2130 2026 3129 2758 2002 2003 3671 2005 2010 2287 1012 2057 2024 2061 13233 2035 1996 2051 2008 2057 2064 2102 3524 2005 2032 2000 4982 2039 999 999 999 999 102 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 71 2 13 247 71 2 13 11023 135 92 409 342 203 16 649 54 20 3 20002 1127 79 203 149 3 92 9 79 5747 203 116 1213 958 9064 116 9533 12449 1221 1046 106 47 20002 623 5222 20002 914 16 115 1252 92 942 14150 33 6990 387 12314 236 4 20002 9 20002 76 5868 20002 33 1092 1305 3 103 135 686 1221 8247 36 2 262 691 1556 20002 387 48 72 71 2 13 10162 20002 61 346 39 135 48 72 1851 1358 9 255 361 901 5632\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   aspect_indices: 9694 16142 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/03/2021 07:11:01 - INFO - utils_ichi -   label: FAML (id = 5)\n",
            "06/03/2021 07:11:19 - INFO - utils_ichi -   Saving features into cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "06/03/2021 07:11:21 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/03/2021 07:11:21 - INFO - __main__ -     Num examples = 3000\n",
            "06/03/2021 07:11:21 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:51<00:00,  3.64it/s]\n",
            "06/03/2021 07:12:13 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/03/2021 07:12:13 - INFO - __main__ -     acc = 0.6896666666666667\n",
            "06/03/2021 07:12:13 - INFO - __main__ -     f1 = 0.6907437404215795\n",
            "06/03/2021 07:12:13 - INFO - __main__ -   Saving model checkpoint to ./tmp/ichi_bert_base_new\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "06/03/2021 07:12:18 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "06/03/2021 07:12:18 - INFO - __main__ -   Evaluate the following checkpoints: ['./tmp/ichi_bert_base_new']\n",
            "06/03/2021 07:12:21 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "06/03/2021 07:12:22 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/03/2021 07:12:22 - INFO - __main__ -     Num examples = 3000\n",
            "06/03/2021 07:12:22 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:53<00:00,  3.53it/s]\n",
            "06/03/2021 07:13:16 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/03/2021 07:13:16 - INFO - __main__ -     acc = 0.6896666666666667\n",
            "06/03/2021 07:13:16 - INFO - __main__ -     f1 = 0.6907437404215795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01TYmyzS8n4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlJzq0GsRjF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11ukVnhuyD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9QFTiYbc0nA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}