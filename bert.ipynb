{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lcf_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqqBi37-1Oo5",
        "outputId": "f9f5b7ca-25b6-4635-8d9d-2f37b455297e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FDUJSHm3r9M",
        "outputId": "947964ab-c0d8-4005-ecfe-bc94b6a42357"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  5 04:44:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqx9cKKKkqBr",
        "outputId": "d4c31b32-fbc8-477e-d74e-35fa27b9c1ee"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!git checkout 896a0eb1fd861bc37097a9b669ebf4cb8d523de7\n",
        "%cd ..\n",
        "!git clone https://github.com/frozen-walker/ICHI-dataset.git\n",
        "!cp -a ICHI-dataset/. transformers/\n",
        "%cd transformers/\n",
        "!mkdir examples/cadec/\n",
        "!mkdir examples/ichi/\n",
        "!pip install -r requirements.txt\n",
        "!pip install .\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 74023, done.\u001b[K\n",
            "remote: Counting objects: 100% (394/394), done.\u001b[K\n",
            "remote: Compressing objects: 100% (287/287), done.\u001b[K\n",
            "remote: Total 74023 (delta 192), reused 202 (delta 82), pack-reused 73629\u001b[K\n",
            "Receiving objects: 100% (74023/74023), 57.23 MiB | 28.84 MiB/s, done.\n",
            "Resolving deltas: 100% (52575/52575), done.\n",
            "/content/transformers\n",
            "Note: checking out '896a0eb1fd861bc37097a9b669ebf4cb8d523de7'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 896a0eb1f Merge pull request #2459 from Perseus14/patch-4\n",
            "/content\n",
            "Cloning into 'ICHI-dataset'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 68 (delta 29), reused 44 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "/content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/cb/3e8902d528538972873d0e9e4e47a31d1849a98e057009e9d383637c96fb/tokenizers-0.0.11-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 35.9MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c2/7091c0cbff9eeb4afb8ddf22ea2c5d6f27b0cfa5f207f5106b647b6614f4/boto3-1.17.88-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 48.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.88\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/d9/a22d370aba7cc0b454614f440f38c592b806c1903a451c8665811b4f58ad/botocore-1.20.88-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 46.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.88->boto3->-r requirements.txt (line 3)) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.88 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses\n",
            "Successfully installed boto3-1.17.88 botocore-1.20.88 jmespath-0.10.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.0.11\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.19.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.17.88)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.45)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.88 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.20.88)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.88->boto3->transformers==2.3.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp37-none-any.whl size=451173 sha256=15601cc7e6a0f231158ea42e671c7a295680f981fbe2fe3dd1799fda403f392a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q6x6uh5u/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.3.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXTvw__5SYm4",
        "outputId": "04765d75-bc4a-4f3b-f6c6-83c823f0b49e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lRGlTmnR1Oo"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"/content/transformers/new_data/lcf_train.tsv\",sep=\"\\t\")\n",
        "percentage = 0.7\n",
        "Classes = df_train.Category.unique()\n",
        "Classes\n",
        "df_final = pd.DataFrame(columns = ['Category','Title','Question','Concepts'])\n",
        "for i,cat in enumerate(Classes):\n",
        "  if i==0:\n",
        "    df_final = df_train[df_train[\"Category\"] == cat]\n",
        "    df_final = df_final.sample(frac=percentage)\n",
        "  else:\n",
        "    df_temp = df_train[df_train[\"Category\"] == cat]\n",
        "\n",
        "    # here random state is use as seed. See here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
        "    df_temp = df_temp.sample(frac=percentage, random_state=50)\n",
        "    frames = [df_final,df_temp]\n",
        "    df_final = pd.concat(frames)\n",
        "df_final = df_final.sample(frac=1)\n",
        "df_final.to_csv('/content/transformers/new_data/temp_lcf_train.tsv',sep=\"\\t\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hiF4EqmDShge",
        "outputId": "122add6f-e6ec-4980-f87d-37ba28128ee6"
      },
      "source": [
        "\n",
        "\n",
        "df_final_tmp_11112=pd.read_csv(\"/content/transformers/new_data/temp_lcf_train.tsv\",sep=\"\\t\")\n",
        "df_final_tmp_11112"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Question</th>\n",
              "      <th>Concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEMO</td>\n",
              "      <td>I started getting these sharp needle pains  in...</td>\n",
              "      <td>I've started a few days ago getting these need...</td>\n",
              "      <td>detrusor|body parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEMO</td>\n",
              "      <td>What happens here?</td>\n",
              "      <td>I have a gynecologist appointment and I've nev...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Ear ringing, pressure and sore throat</td>\n",
              "      <td>I have neen to two Drs, and one ENT, and I'm s...</td>\n",
              "      <td>body parts|Stern|sore throats|Infarction|Anger...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAML</td>\n",
              "      <td>Partial bowel movement witholding by 4 year old</td>\n",
              "      <td>My 4 y/o grandson will 'hide' and partially po...</td>\n",
              "      <td>body parts|Stern|hip pain|detrusor|omitting|la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>micrdodermabrsion at home</td>\n",
              "      <td>this is crazy i want an at home kit, i live in...</td>\n",
              "      <td>detrusor|body parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>DEMO</td>\n",
              "      <td>blocked pores on nipples</td>\n",
              "      <td>Hi, I have noticed within the last two years t...</td>\n",
              "      <td>body parts|Stern|Infarction|hip pain|is passin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5597</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Scheral Buckle</td>\n",
              "      <td>I am having this surgery tomorrow.I must admit...</td>\n",
              "      <td>detrusor|labor pains|body parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5598</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Does anyone know if you can get TN from bulgin...</td>\n",
              "      <td>I've posted in a few other forums...Basically ...</td>\n",
              "      <td>body parts|detrusor|annal fissure|labor pains|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5599</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Success</td>\n",
              "      <td>I fouond this sight about 5 months ago and spe...</td>\n",
              "      <td>detrusor|labor pains|body parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5600</th>\n",
              "      <td>DISE</td>\n",
              "      <td>PFT normal but Chest x-ray showing copd</td>\n",
              "      <td>I am 39 y/o female and have been diagnosed wit...</td>\n",
              "      <td>body parts|Stern|sore throats|Infarction|Anger...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5601 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                           Concepts\n",
              "0        DEMO  ...                                detrusor|body parts\n",
              "1        DEMO  ...                                                NaN\n",
              "2        DISE  ...  body parts|Stern|sore throats|Infarction|Anger...\n",
              "3        FAML  ...  body parts|Stern|hip pain|detrusor|omitting|la...\n",
              "4        SOCL  ...                                detrusor|body parts\n",
              "...       ...  ...                                                ...\n",
              "5596     DEMO  ...  body parts|Stern|Infarction|hip pain|is passin...\n",
              "5597     GOAL  ...                    detrusor|labor pains|body parts\n",
              "5598     DISE  ...  body parts|detrusor|annal fissure|labor pains|...\n",
              "5599     GOAL  ...                    detrusor|labor pains|body parts\n",
              "5600     DISE  ...  body parts|Stern|sore throats|Infarction|Anger...\n",
              "\n",
              "[5601 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPJ7HeSBu9P4",
        "outputId": "1ed4205f-0af7-4e6d-f2bb-c5873f16559f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  5 04:44:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrW58RPs0OXo"
      },
      "source": [
        "# # ########### Uncomment it to download Glove Vectors\n",
        "\n",
        "# !curl -O -J -L http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdLQyv7_-bPz",
        "outputId": "e075fd16-b121-4252-8cba-30110d4a0b1f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  5 04:44:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    13W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-EzqBB_PvmT"
      },
      "source": [
        "# ########### Uncomment it to download BioASQ Embeddings\n",
        "\n",
        "# !curl -O -J -L http://bioasq.lip6.fr/tools/BioASQword2vec/\n",
        "# !tar -xvzf biomedicalWordVectors.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKzJUfduLaSk"
      },
      "source": [
        "#%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0KtyeJkv6Z"
      },
      "source": [
        "# class ICHIDataset(Dataset):\n",
        "#     def __init__(self, fname, tokenizer):\n",
        "#         fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#         lines = fin.readlines()\n",
        "#         fin.close()\n",
        "\n",
        "#         all_data = []\n",
        "#         for i in range(0, len(lines), 3):\n",
        "#             text_left, _, text_right = [s.lower().strip() for s in lines[i].partition(\"$T$\")]\n",
        "#             aspect = lines[i + 1].lower().strip()\n",
        "#             polarity = lines[i + 2].strip()\n",
        "\n",
        "#             text_raw_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
        "#             text_raw_without_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
        "#             text_left_indices = tokenizer.text_to_sequence(text_left)\n",
        "#             text_left_with_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
        "#             text_right_indices = tokenizer.text_to_sequence(text_right, reverse=True)\n",
        "#             text_right_with_aspect_indices = tokenizer.text_to_sequence(\" \" + aspect + \" \" + text_right, reverse=True)\n",
        "#             aspect_indices = tokenizer.text_to_sequence(aspect)\n",
        "#             left_context_len = np.sum(text_left_indices != 0)\n",
        "#             aspect_len = np.sum(aspect_indices != 0)\n",
        "#             aspect_in_text = torch.tensor([left_context_len.item(), (left_context_len + aspect_len - 1).item()])\n",
        "#             polarity = int(polarity) + 1\n",
        "\n",
        "#             text_bert_indices = tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
        "#             bert_segments_ids = np.asarray([0] * (np.sum(text_raw_indices != 0) + 2) + [1] * (aspect_len + 1))\n",
        "#             bert_segments_ids = pad_and_truncate(bert_segments_ids, tokenizer.max_seq_len)\n",
        "\n",
        "#             text_raw_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
        "#             aspect_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
        "\n",
        "#             data = {\n",
        "#                 'text_bert_indices': text_bert_indices,\n",
        "#                 'bert_segments_ids': bert_segments_ids,\n",
        "#                 'text_raw_bert_indices': text_raw_bert_indices,\n",
        "#                 'aspect_bert_indices': aspect_bert_indices,\n",
        "#                 'text_raw_indices': text_raw_indices,\n",
        "#                 'text_raw_without_aspect_indices': text_raw_without_aspect_indices,\n",
        "#                 'text_left_indices': text_left_indices,\n",
        "#                 'text_left_with_aspect_indices': text_left_with_aspect_indices,\n",
        "#                 'text_right_indices': text_right_indices,\n",
        "#                 'text_right_with_aspect_indices': text_right_with_aspect_indices,\n",
        "#                 'aspect_indices': aspect_indices,\n",
        "#                 'aspect_in_text': aspect_in_text,\n",
        "#                 'polarity': polarity,\n",
        "#             }\n",
        "\n",
        "#             all_data.append(data)\n",
        "#         self.data = all_data\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         return self.data[index]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG8YjUsTm2Eg",
        "outputId": "d38f279b-0521-4010-8ea5-0df7cb3017c8"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyy-AEpoS8Lx",
        "outputId": "2ac45d21-9deb-4a27-83fa-81db67fa6a03"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/utils_ichi.py\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "from transformers.file_utils import is_tf_available \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "if is_tf_available():\n",
        "    import tensorflow as tf\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def acc_and_f1(preds, labels):\n",
        "    acc = simple_accuracy(preds, labels)\n",
        "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    # return {\"acc\": simple_accuracy(preds, labels)}\n",
        "    return acc_and_f1(preds, labels)\n",
        "\n",
        "\n",
        "def pad_and_truncate(sequence, maxlen, dtype='int64', padding='pre', truncating='post', value=0):\n",
        "    x = (np.ones(maxlen) * value).astype(dtype)\n",
        "    if truncating == 'pre':\n",
        "        trunc = sequence[-maxlen:]\n",
        "    else:\n",
        "        trunc = sequence[:maxlen]\n",
        "    trunc = np.asarray(trunc, dtype=dtype)\n",
        "    if padding == 'post':\n",
        "        x[:len(trunc)] = trunc\n",
        "    else:\n",
        "        x[-len(trunc):] = trunc\n",
        "    return x\n",
        "\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, max_seq_len, max_num_words=None,lower=True):\n",
        "        self.lower = lower\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.word2idx = {}\n",
        "        self.word_freq = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx2word[0] = '<PAD>'\n",
        "        self.word2idx['<PAD>'] = 0\n",
        "        self.word_freq['<PAD>'] = 100000\n",
        "        self.idx = 1\n",
        "        self.max_num_words = max_num_words\n",
        "\n",
        "    def fit_on_text(self, text):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = self.idx\n",
        "                self.word_freq[word] = 1\n",
        "                self.idx2word[self.idx] = word\n",
        "                self.idx += 1\n",
        "            else:\n",
        "                self.word_freq[word] = self.word_freq[word] + 1\n",
        "    \n",
        "    def update_tokenizer(self):\n",
        "        if self.max_num_words == None:\n",
        "            return\n",
        "        elif self.max_num_words >= self.idx:\n",
        "            return \n",
        "        else:\n",
        "            del self.word_freq['<PAD>']\n",
        "            self.word_freq = {k: v for k, v in sorted(self.word_freq.items(), key=lambda item: item[1], reverse=True)}\n",
        "            self.word2idx = {}\n",
        "            self.idx2word = {}\n",
        "            self.idx2word[0] = '<PAD>'\n",
        "            self.word2idx['<PAD>'] = 0\n",
        "            self.idx = 1\n",
        "            for i, key in enumerate(self.word_freq):\n",
        "                if i >= self.max_num_words:\n",
        "                    break\n",
        "                else:\n",
        "                    self.word2idx[key] = i+1\n",
        "                    self.idx2word[i+1] = key\n",
        "                    self.idx += 1\n",
        "            self.word_freq['<PAD>'] = 100000\n",
        "\n",
        "\n",
        "\n",
        "    def fit_on_examples(self, examples):\n",
        "        is_tf_dataset = False\n",
        "        if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "            is_tf_dataset = True\n",
        "        processor = ICHIProcessor()\n",
        "        for example in examples:\n",
        "            if is_tf_dataset:\n",
        "                example = processor.get_example_from_tensor_dict(example)\n",
        "                example = processor.tfds_map(example)\n",
        "            self.fit_on_text(example.clean_text)\n",
        "\n",
        "    def text_to_sequence(self, text, reverse=False, padding='pre', truncating='post'):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        unknownidx = len(self.word2idx)+1\n",
        "        if (self.max_num_words == None) or (self.max_num_words >= self.idx):\n",
        "            sequence = [self.word2idx[w] if w in self.word2idx else unknownidx for w in words]\n",
        "        else:\n",
        "            sequence = []\n",
        "            for w in words:\n",
        "                if w in self.word2idx:\n",
        "                    if self.word2idx[w] > self.max_num_words:\n",
        "                        sequence.append(unknownidx)\n",
        "                    else:\n",
        "                        sequence.append(self.word2idx[w])\n",
        "                else:\n",
        "                    sequence.append(unknownidx)\n",
        "        if len(sequence) == 0:\n",
        "            sequence = [0]\n",
        "        if reverse:\n",
        "            sequence = sequence[::-1]\n",
        "        return pad_and_truncate(sequence, self.max_seq_len, padding=padding, truncating=truncating)\n",
        "\n",
        "def _load_word_vec_glove(path, word2idx=None):\n",
        "    fin = open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    word_vec = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split()\n",
        "        if word2idx is None or tokens[0] in word2idx.keys():\n",
        "            try:\n",
        "                word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')\n",
        "            except:\n",
        "                pass\n",
        "    return word_vec\n",
        "    \n",
        "def build_embedding_matrix_glove(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(glove): ', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(glove)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        fname = fname + '/glove.twitter.27B/glove.twitter.27B.' + str(embed_dim) + 'd.txt' \\\n",
        "            if embed_dim != 300 else fname + '/glove.840B.300d.txt'\n",
        "        word_vec = _load_word_vec_glove(fname, word2idx=word2idx)\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            vec = word_vec.get(word)\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def build_embedding_matrix_BioASQ(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(BioASQ):', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(BioASQ)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        f = open(fname + \"/word2vecTools/types.txt\",\"r\")\n",
        "        i = 0\n",
        "        names = []\n",
        "        for line in f:\n",
        "            names.append(line.split('\\n')[0])\n",
        "            i = i + 1\n",
        "        vectors = np.loadtxt(fname + \"/word2vecTools/vectors.txt\")\n",
        "        word_vec = {}\n",
        "        for (index, name) in enumerate(names):\n",
        "            word_vec[name] = index\n",
        "\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            if word in word_vec.keys():\n",
        "                vec = vectors[word_vec[word]]\n",
        "            else:\n",
        "                vec = None\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    tokenizer,\n",
        "    tokenizer_cleantext,\n",
        "    max_length=512,\n",
        "    task=None,\n",
        "    label_list=None,\n",
        "    output_mode=None,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a data file into a list of ``ICHI_InputFeatures``\n",
        "\n",
        "    Args:\n",
        "        examples: List of ``ICHI_InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
        "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
        "        tokenizer_cleantext: Instance of a tokenizer that will tokenize the examples clean text(used for our medical module) \n",
        "        max_length: Maximum example length\n",
        "        task: GLUE task\n",
        "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
        "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
        "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
        "        pad_token: Padding token\n",
        "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
        "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
        "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
        "            actual values)\n",
        "\n",
        "    Returns:\n",
        "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
        "        containing the task-specific features. If the input is a list of ``ICHI_InputExamples``, will return\n",
        "        a list of task-specific ``ICHI_InputFeatures`` which can be fed to the model.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    is_tf_dataset = False\n",
        "    if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "        is_tf_dataset = True\n",
        "\n",
        "    \"\"\"      Initialisation of Data Processor    \"\"\"\n",
        "    if task is not None:\n",
        "        processor = ICHIProcessor()  \n",
        "        if label_list is None:\n",
        "            label_list = processor.get_labels()\n",
        "            logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
        "        if output_mode is None:\n",
        "            output_mode = \"classification\"\n",
        "            logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    \"\"\"      Processing the examples    \"\"\"\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d/%d\" % (ex_index, len(examples)))\n",
        "        if is_tf_dataset:\n",
        "            example = processor.get_example_from_tensor_dict(example)\n",
        "            example = processor.tfds_map(example)\n",
        "        \"\"\"      Assuming that each aspect consist of max 4 tokens hence making sure that aspects total tokens coming from aspects are not greater than max sequence length    \"\"\"\n",
        "        aspect_present = bool(example.aspects is not None)\n",
        "        if aspect_present:\n",
        "            if 4 * len(example.aspects) > max_length:\n",
        "                example.aspects = random.sample(example.aspects, k = int(max_length/4))\n",
        "                \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the global features are encoded as [<special token> + text_tokens + <special token> + heading_tokens + <special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        inputs_global = tokenizer.encode_plus_lcf(example.text, example.heading, example.aspects, add_special_tokens=True, max_length=max_length,) ######## edittttttt\n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the local features(medical module) are encoded as [<special token> + text_tokens + <special token>] \"\"\"\n",
        "        inputs_local = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,)\n",
        "        \"\"\" Generating tokens for the clean_text i.e. tokenising text based on glove or BioASQ \"\"\"\n",
        "        text_clean_indices = tokenizer_cleantext.text_to_sequence(example.clean_text)\n",
        "        \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the aspect_indices are encoded as [<special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        if len(example.aspects) > 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], example.aspects[2:], add_special_tokens=False, max_length=max_length,)\n",
        "        elif len(example.aspects) == 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], add_special_tokens=False, max_length=max_length,)\n",
        "        else:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], add_special_tokens=False, max_length=max_length,)\n",
        "        \n",
        "        input_global_ids, token_global_type_ids = inputs_global[\"input_ids\"], inputs_global[\"token_type_ids\"]\n",
        "        input_local_ids, token_local_type_ids = inputs_local[\"input_ids\"], inputs_local[\"token_type_ids\"]\n",
        "        \n",
        "        aspect_indices = aspect_indices[\"input_ids\"]\n",
        "        padding_length_aspect = max_length - len(aspect_indices)\n",
        "        aspect_indices = aspect_indices + ([pad_token] * padding_length_aspect)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask_global = [1 if mask_padding_with_zero else 0] * len(input_global_ids)\n",
        "        attention_mask_local = [1 if mask_padding_with_zero else 0] * len(input_local_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length_global = max_length - len(input_global_ids)\n",
        "        padding_length_local = max_length - len(input_local_ids)\n",
        "        if pad_on_left:\n",
        "            input_global_ids = ([pad_token] * padding_length_global) + input_global_ids\n",
        "            attention_mask_global = ([0 if mask_padding_with_zero else 1] * padding_length_global) + attention_mask_global\n",
        "            token_global_type_ids = ([pad_token_segment_id] * padding_length_global) + token_global_type_ids\n",
        "            input_local_ids = ([pad_token] * padding_length_local) + input_local_ids\n",
        "            attention_mask_local = ([0 if mask_padding_with_zero else 1] * padding_length_local) + attention_mask_local\n",
        "            token_local_type_ids = ([pad_token_segment_id] * padding_length_local) + token_local_type_ids\n",
        "        else:\n",
        "            input_global_ids = input_global_ids + ([pad_token] * padding_length_global)\n",
        "            attention_mask_global = attention_mask_global + ([0 if mask_padding_with_zero else 1] * padding_length_global)\n",
        "            token_global_type_ids = token_global_type_ids + ([pad_token_segment_id] * padding_length_global)\n",
        "            input_local_ids = input_local_ids + ([pad_token] * padding_length_local)\n",
        "            attention_mask_local = attention_mask_local + ([0 if mask_padding_with_zero else 1] * padding_length_local)\n",
        "            token_local_type_ids = token_local_type_ids + ([pad_token_segment_id] * padding_length_local)\n",
        "\n",
        "        assert len(input_global_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_global_ids), max_length)\n",
        "        assert len(input_local_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_local_ids), max_length)\n",
        "        assert len(attention_mask_global) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_global), max_length\n",
        "        )\n",
        "        assert len(attention_mask_local) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_local), max_length\n",
        "        )\n",
        "        assert len(token_global_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_global_type_ids), max_length\n",
        "        )\n",
        "        assert len(token_local_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_local_type_ids), max_length\n",
        "        )\n",
        "\n",
        "        if output_mode == \"classification\":\n",
        "            label = label_map[example.label]\n",
        "        elif output_mode == \"regression\":\n",
        "            label = float(example.label)\n",
        "        else:\n",
        "            raise KeyError(output_mode)\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"input_global_ids: %s\" % \" \".join([str(x) for x in input_global_ids]))\n",
        "            logger.info(\"attention_mask_global: %s\" % \" \".join([str(x) for x in attention_mask_global]))\n",
        "            logger.info(\"token_global_type_ids: %s\" % \" \".join([str(x) for x in token_global_type_ids]))\n",
        "            logger.info(\"input_local_ids: %s\" % \" \".join([str(x) for x in input_local_ids]))\n",
        "            logger.info(\"attention_mask_local: %s\" % \" \".join([str(x) for x in attention_mask_local]))\n",
        "            logger.info(\"token_local_type_ids: %s\" % \" \".join([str(x) for x in token_local_type_ids]))\n",
        "            logger.info(\"text_clean_indices: %s\" % \" \".join([str(x) for x in text_clean_indices]))\n",
        "            logger.info(\"aspect_indices: %s\" % \" \".join([str(x) for x in aspect_indices]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (example.label, label))\n",
        "\n",
        "        features.append(\n",
        "            ICHI_InputFeatures(\n",
        "                input_global_ids=input_global_ids, input_local_ids=input_local_ids, attention_mask_global=attention_mask_global, attention_mask_local=attention_mask_local,\n",
        "                token_global_type_ids=token_global_type_ids, token_local_type_ids=token_local_type_ids, text_clean_indices=text_clean_indices, aspect_indices=aspect_indices, label=label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if is_tf_available() and is_tf_dataset:\n",
        "\n",
        "        def gen():\n",
        "            for ex in features:\n",
        "                yield (\n",
        "                    {\n",
        "                        \"input_global_ids\": ex.input_global_ids,\n",
        "                        \"input_local_ids\": ex.input_local_ids,\n",
        "                        \"attention_mask_global\": ex.attention_mask_global,\n",
        "                        \"attention_mask_local\": ex.attention_mask_local,\n",
        "                        \"token_global_type_ids\": ex.token_global_type_ids,\n",
        "                        \"token_local_type_ids\": ex.token_local_type_ids,\n",
        "                        \"text_clean_indices\": ex.text_clean_indices,\n",
        "                        \"aspect_indices\": ex.aspect_indices,\n",
        "                    },\n",
        "                    ex.label,\n",
        "                )\n",
        "\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            gen,\n",
        "            ({\"input_global_ids\": tf.int32, \"input_local_ids\": tf.int32, \"attention_mask_global\": tf.int32, \"attention_mask_local\": tf.int32, \"token_global_type_ids\": tf.int32, \"token_local_type_ids\": tf.int32, \"text_clean_indices\": tf.int32, \"aspect_indices\": tf.int32}, tf.int64),\n",
        "            (\n",
        "                {\n",
        "                    \"input_global_ids\": tf.TensorShape([None]),\n",
        "                    \"input_local_ids\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_global\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_local\": tf.TensorShape([None]),\n",
        "                    \"token_global_type_ids\": tf.TensorShape([None]),\n",
        "                    \"token_local_type_ids\": tf.TensorShape([None]),\n",
        "                    \"text_clean_indices\": tf.TensorShape([None]),\n",
        "                    \"aspect_indices\": tf.TensorShape([None]),\n",
        "                },\n",
        "                tf.TensorShape([]),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    return features\n",
        "\n",
        "class ICHIProcessor(object):\n",
        "    \"\"\"Processor for the ICHI data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return ICHI_InputExample(tensor_dict['idx'].numpy(),\n",
        "                            tensor_dict['heading'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['clean_text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['aspects'].numpy().decode('utf-8'),\n",
        "                            str(tensor_dict['label'].numpy()))\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"temp_lcf_train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"lcf_test.tsv\")),\n",
        "            \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"DEMO\", \"DISE\", \"TRMT\", \"GOAL\", \"PREG\", \"FAML\", \"SOCL\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            label = line[0]\n",
        "            heading = None\n",
        "            text = line[1] + ' ' + line[2]\n",
        "            try:\n",
        "                aspects = [' ' + x for x in line[3].split('|')]\n",
        "                temp_clean_text = \" \".join(line[3].split('|'))\n",
        "            except:\n",
        "                aspects = None\n",
        "                temp_clean_text = \"\"\n",
        "                print(\"Sed\")\n",
        "            \n",
        "            # print(aspects)\n",
        "            \"\"\"    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT   \"\"\"\n",
        "            clean_text = self.clean_str( text, lemmatizer) ######## for using glove embeddings over sentence\n",
        "            # clean_text = self.clean_str( temp_clean_text, lemmatizer) ##### for using BioASQ embeddings in aspects\n",
        "            examples.append(\n",
        "                ICHI_InputExample(guid=guid, heading=heading, text=text, clean_text=clean_text, aspects=aspects, label=label))\n",
        "        return examples\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are.\n",
        "        This method converts examples to the correct format.\"\"\"\n",
        "        if len(self.get_labels()) > 1:\n",
        "            example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    def clean_str(self, string1, lemmatizer):\n",
        "        \"\"\"\n",
        "        Tokenization/string cleaning for dataset\n",
        "        Every dataset is lower cased except\n",
        "        \"\"\"\n",
        "        str_stop = \"\"\n",
        "        string1 = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '',string1)\n",
        "        string1 = re.sub(r\"\\\\\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\'\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\\"\", \" \", string1)   \n",
        "        string1 = re.sub(r'(\\W)\\1+', r'\\1', string1)\n",
        "        word_list=string1.split(\" \")\n",
        "        filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
        "        for kj in filtered_words:\n",
        "            new=lemmatizer.lemmatize(str(kj)) \n",
        "            str_stop=str_stop +\" \"+new\n",
        "            str_stop.encode('utf-8')\n",
        "        return str_stop.strip().lower()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))\n",
        "\n",
        "class ICHI_InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        heading: string. The untokenized heading of the sequence\n",
        "        text: string. The untokenized text part of the sequence.\n",
        "        clean_text: string. The untokenized text part of the sequence used for medical module(as tokenization will be different for glove and BioASQ than BERT).\n",
        "        aspects: list of string. The untokenized aspects for the sequence as a list of strings\n",
        "        Only must be specified for sequence pair tasks.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, heading, text, clean_text, aspects, label=None):\n",
        "        self.guid = guid\n",
        "        self.heading = heading\n",
        "        self.text = text\n",
        "        self.clean_text = clean_text\n",
        "        self.aspects = aspects\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class ICHI_InputFeatures(object):\n",
        "    \"\"\"\n",
        "    A single set of features of data.\n",
        "\n",
        "    Args:\n",
        "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
        "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
        "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
        "        label: Label corresponding to the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_global_ids, input_local_ids, attention_mask_global=None, attention_mask_local=None, token_global_type_ids=None, token_local_type_ids=None, text_clean_indices=None, aspect_indices=None, label=None):\n",
        "        self.input_global_ids = input_global_ids\n",
        "        self.attention_mask_global = attention_mask_global\n",
        "        self.token_global_type_ids = token_global_type_ids\n",
        "        self.input_local_ids = input_local_ids\n",
        "        self.attention_mask_local = attention_mask_local\n",
        "        self.token_local_type_ids = token_local_type_ids\n",
        "        self.text_clean_indices = text_clean_indices\n",
        "        self.aspect_indices = aspect_indices\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, task, tokenizer, tokenizer_cleantext, evaluate=False):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    processor = ICHIProcessor()  \n",
        "    output_mode = \"classification\"\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}_{}\".format(\n",
        "            \"dev\" if evaluate else \"train\",\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_length),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    \"\"\" Load saved tokenizer for the clean_text\"\"\"\n",
        "    cached_tokenizer_cleantext_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedtokenizer_{}_{}_{}\".format(\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.embedding_type),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "    \"\"\" if overwrite cache is disabled and saved feature and tokenizer file exists then load from the saved file else process them \"\"\"\n",
        "    if os.path.exists(cached_features_file) and os.path.exists(cached_tokenizer_cleantext_file) and not args.overwrite_cache:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "        tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "        if task in [\"mnli\", \"mnli-mm\"] and args.model_type in [\"roberta\", \"xlmroberta\"]:\n",
        "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
        "            label_list[1], label_list[2] = label_list[2], label_list[1]\n",
        "        examples = (\n",
        "            processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
        "        )\n",
        "        if (not evaluate):\n",
        "            tokenizer_cleantext.fit_on_examples(examples)\n",
        "            tokenizer_cleantext.update_tokenizer()\n",
        "        \"\"\" features are created using this function which is defined above\"\"\"\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            tokenizer_cleantext,\n",
        "            label_list=label_list,\n",
        "            max_length=args.max_seq_length,\n",
        "            output_mode=output_mode,\n",
        "            pad_on_left=bool(args.model_type in [\"xlnet\"]),  # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "            pickle.dump(tokenizer_cleantext, open(cached_tokenizer_cleantext_file, 'wb'))\n",
        "\n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_global_ids = torch.tensor([f.input_global_ids for f in features], dtype=torch.long)\n",
        "    all_input_local_ids = torch.tensor([f.input_local_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask_global = torch.tensor([f.attention_mask_global for f in features], dtype=torch.long)\n",
        "    all_attention_mask_local = torch.tensor([f.attention_mask_local for f in features], dtype=torch.long)\n",
        "    all_token_global_type_ids = torch.tensor([f.token_global_type_ids for f in features], dtype=torch.long)\n",
        "    all_token_local_type_ids = torch.tensor([f.token_local_type_ids for f in features], dtype=torch.long)\n",
        "    all_text_clean_indices = torch.tensor([f.text_clean_indices for f in features], dtype=torch.long)\n",
        "    all_aspect_indices = torch.tensor([f.aspect_indices for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "    \n",
        "    dataset = TensorDataset(all_input_global_ids, all_input_local_ids, all_attention_mask_global, all_attention_mask_local, all_token_global_type_ids, all_token_local_type_ids, all_text_clean_indices, all_aspect_indices, all_labels)\n",
        "    \n",
        "    return dataset, tokenizer_cleantext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/utils_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ2Y7oT5IRPj",
        "outputId": "6885f191-1d55-4382-bfa0-d06e5bad1f03"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/lcf_ichi.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "from transformers.modeling_bert import BertPooler, BertSelfAttention, BertPreTrainedModel, BertModel\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "def compute_average_with_padding(tensor, padding):\n",
        "    \"\"\"\n",
        "    :param tensor: dimension batch_size, seq_length, hidden_size\n",
        "    :param padding: dimension batch_size, seq_length\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    batch_size, seq_length, emb_size = tensor.shape\n",
        "    entry_sizes = torch.sum(padding, axis=1)\n",
        "    return torch.sum(tensor, axis=1) / entry_sizes\n",
        "\n",
        "\n",
        "class BertMaxPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = compute_average_with_padding(hidden_states, mask)\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config, args):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.args = args\n",
        "        self.SA = BertSelfAttention(config)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        zero_tensor = torch.tensor(np.zeros((inputs.size(0), 1, 1, self.args.max_seq_length),\n",
        "                                            dtype=np.float32), dtype=torch.float32).to(self.args.device)\n",
        "        SA_out = self.SA(inputs, zero_tensor)\n",
        "        return self.tanh(SA_out[0])\n",
        "\n",
        "\n",
        "class lcf_BERT(BertPreTrainedModel):\n",
        "    def __init__(self, config, args):\n",
        "        super(lcf_BERT, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.args = args\n",
        "        self.config =config\n",
        "        self.bert = BertModel(config)\n",
        "        # self.bert_global_focus = self.bert\n",
        "        # self.bert_local_focus = copy.deepcopy(self.bert_global_focus) if args.use_single_bert else self.bert_global_focus\n",
        "        # self.embedder = nn.Embedding.from_pretrained(torch.from_numpy(args.word2vec).float(), freeze=True, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.lstm = nn.LSTM(args.emb_size, 100, 1, batch_first=True, bidirectional=True)\n",
        "        # Co = 100\n",
        "        # self.conv13 = nn.Conv2d(1, Co, (3, 2*args.emb_size))\n",
        "        # self.conv14 = nn.Conv2d(1, Co, (4, 2*args.emb_size))\n",
        "        # self.conv15 = nn.Conv2d(1, Co, (5, 2*args.emb_size))\n",
        "        # self.dropout_1 = nn.Dropout(0.4)\n",
        "        # self.fc1 = nn.Linear(3*Co, config.num_labels)\n",
        "        # self.fc = nn.Linear(200, config.num_labels)\n",
        "        self.bert_SA = SelfAttention(config, args) ### change\n",
        "        self.linear_double_cdm_or_cdw = nn.Linear(config.hidden_size * 2,config.hidden_size)\n",
        "        self.linear_triple_lcf_global = nn.Linear(config.hidden_size * 3, config.hidden_size)\n",
        "        self.bert_pooler_org = BertPooler(config)\n",
        "        self.bert_pooler = BertMaxPooler(config) ### change\n",
        "        self.dense = nn.Linear(config.hidden_size, config.num_labels) #Changed to 1 hidden size\n",
        "        self.init_weights()\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.gelu(conv(x)).squeeze(3) # (n, Co, W)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x\n",
        "\n",
        "    def feature_dynamic_mask(self, text_local_indices, aspect_indices):\n",
        "        texts = text_local_indices\n",
        "        # mask_len = self.args.SRD\n",
        "        masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "                                          dtype=torch.float)\n",
        "        \n",
        "        masked_text_raw_indices[:, 0, :] = torch.ones((text_local_indices.size(0), self.config.hidden_size), dtype=torch.float) \n",
        "        zero_tensor = torch.tensor(0).to(self.args.device)\n",
        "        for i in range(aspect_indices.shape[0]):\n",
        "            for j in range(aspect_indices[i].shape[0]):\n",
        "                if aspect_indices[i][j] == zero_tensor:\n",
        "                    break\n",
        "                else:\n",
        "                    indices = (text_local_indices[i] == aspect_indices[i][j]).nonzero()\n",
        "                    for k in indices:\n",
        "                        masked_text_raw_indices[i][k] = torch.ones(self.config.hidden_size, dtype=torch.float)\n",
        "        return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    # # create the weights tensor for local context features\n",
        "    # def feature_dynamic_weighted(self, text_local_indices, aspect_indices):\n",
        "    #     texts = text_local_indices\n",
        "    #     asps = aspect_indices\n",
        "    #     # mask_len = self.args.SRD\n",
        "    #     masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "    #                                       dtype=torch.float)\n",
        "    #     for text_i, asp_i in zip(range(len(texts)), range(len(asps))):\n",
        "    #         asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "    #         try:\n",
        "    #             asp_begin = np.argwhere(texts[text_i] == asps[asp_i][1])[0][0]\n",
        "    #             asp_avg_index = (asp_begin * 2 + asp_len) / 2\n",
        "    #         except:\n",
        "    #             continue\n",
        "    #         distances = np.zeros(np.count_nonzero(texts[text_i]), dtype=np.float32)\n",
        "    #         for i in range(1, np.count_nonzero(texts[text_i])-1):\n",
        "    #             if abs(i - asp_avg_index) + asp_len / 2 > self.args.SRD:\n",
        "    #                 distances[i] = 1 - (abs(i - asp_avg_index)+asp_len/2\n",
        "    #                                     - self.args.SRD)/np.count_nonzero(texts[text_i])\n",
        "    #             else:\n",
        "    #                 distances[i] = 1\n",
        "    #         for i in range(len(distances)):\n",
        "    #             masked_text_raw_indices[text_i][i] = masked_text_raw_indices[text_i][i] * distances[i]\n",
        "    #     # masked_text_raw_indices = torch.from_numpy(masked_text_raw_indices)\n",
        "    #     return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_global_ids=None,\n",
        "        attention_mask_global=None,\n",
        "        token_global_type_ids=None,\n",
        "        input_local_ids=None,\n",
        "        attention_mask_local=None,\n",
        "        token_local_type_ids=None,\n",
        "        text_clean_indices=None,\n",
        "        aspect_indices=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        # word_vectors = self.embedder(text_clean_indices)\n",
        "        # self.lstm.flatten_parameters()\n",
        "        # out, _ = self.lstm(word_vectors)\n",
        "        # # out = out.unsqueeze(1)   #### for using CNN\n",
        "        # # print(out.size())\n",
        "        # # print(out)\n",
        "        # logits = self.fc(out[:, -1, :])\n",
        "        # # print(logits.size())\n",
        "        # # print(logits)\n",
        "        # # raise ValueError\n",
        "        # # logits = self.fc(torch.div(word_vectors.sum(axis=1), word_vectors.shape[1]))\n",
        "\n",
        "        global_outputs, _ = self.bert(\n",
        "            input_global_ids,\n",
        "            attention_mask=attention_mask_global,\n",
        "            token_type_ids=token_global_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        local_outputs, _ = self.bert(\n",
        "            input_local_ids,\n",
        "            attention_mask=attention_mask_local,\n",
        "            token_type_ids=token_local_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        global_outputs= self.dropout(global_outputs)\n",
        "        local_outputs= self.dropout(local_outputs)\n",
        "        \n",
        "        if self.args.local_context_focus == 'cdm':\n",
        "            masked_local_text_vec = self.feature_dynamic_mask(input_local_ids, aspect_indices)\n",
        "            local_outputs = torch.mul(local_outputs, masked_local_text_vec)\n",
        "            # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "            # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        elif self.args.local_context_focus == 'cdw':\n",
        "            weighted_text_local_features = self.feature_dynamic_weighted(input_local_ids, aspect_indices)\n",
        "            local_outputs = torch.mul(local_outputs, weighted_text_local_features)\n",
        "            out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "            out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        elif self.args.local_context_focus == 'lcf_fusion':\n",
        "            masked_local_text_vec = self.feature_dynamic_mask(text_local_indices, aspect_indices)\n",
        "            masked_local_out = torch.mul(local_outputs, masked_local_text_vec)\n",
        "            weighted_text_local_features = self.feature_dynamic_weighted(text_local_indices, aspect_indices)\n",
        "            weighted_local_out = torch.mul(local_outputs, weighted_text_local_features)\n",
        "            out_cat = torch.cat((masked_local_out, global_outputs, weighted_local_out), dim=-1)\n",
        "            out_cat = self.linear_triple_lcf_global(out_cat)\n",
        "\n",
        "        # self_attention_out = self.bert_SA(local_outputs)\n",
        "        rep_cat= torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        mean_pool = self.linear_double_cdm_or_cdw(rep_cat)\n",
        "        self_attention_out= self.bert_SA(mean_pool)\n",
        "        pooled_out= self.bert_pooler_org(self_attention_out)\n",
        "        logits = self.dense(pooled_out)\n",
        "        outputs = (logits,)\n",
        "\n",
        "        '''\n",
        "        self_attention_out = self.dropout(local_outputs)\n",
        "        local_pooled_out = self.bert_pooler(self_attention_out, masked_local_text_vec)\n",
        "        self_attention_out = self.dropout(global_outputs)\n",
        "        global_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        pooled_out = torch.cat((local_pooled_out, global_pooled_out), dim=-1)\n",
        "        \n",
        "        #Additional code April 16, 2021\n",
        "        mean_pool = self.linear_double_cdm_or_cdw(pooled_out)\n",
        "        #self_attention_out1 = self.bert_SA(mean_pool)\n",
        "        #pooled_out1 = self.bert_pooler(self_attention_out1)\n",
        "        logits = self.dense(mean_pool)\n",
        "        outputs = (logits,)\n",
        "        '''\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/lcf_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWhlcZgHS8a9",
        "outputId": "cd5a73e0-1c9e-4ef1-d040-808065c7edf9"
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/run_ichi.py\n",
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AlbertConfig,\n",
        "    AlbertForSequenceClassification,\n",
        "    AlbertTokenizer,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    XLMConfig,\n",
        "    XLMForSequenceClassification,\n",
        "    XLMRobertaConfig,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMTokenizer,\n",
        "    XLNetConfig,\n",
        "    XLNetForSequenceClassification,\n",
        "    XLNetTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from lcf_ichi import lcf_BERT#, lcf_XLNET, lcf_XLM, lcf_Roberta, lcf_DistilBert, lcf_Albert, lcf_XLMRoberta\n",
        "from utils_ichi import convert_examples_to_features, ICHIProcessor, compute_metrics, load_and_cache_examples, Tokenizer, pad_and_truncate, build_embedding_matrix_glove, build_embedding_matrix_BioASQ\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ALL_MODELS = sum(\n",
        "    (\n",
        "        tuple(conf.pretrained_config_archive_map.keys())\n",
        "        for conf in (\n",
        "            BertConfig,\n",
        "            XLNetConfig,\n",
        "            XLMConfig,\n",
        "            RobertaConfig,\n",
        "            DistilBertConfig,\n",
        "            AlbertConfig,\n",
        "            XLMRobertaConfig,\n",
        "        )\n",
        "    ),\n",
        "    (),\n",
        ")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer, lcf_BERT),\n",
        "}\n",
        "#     \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer, lcf_XLNET),\n",
        "#     \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer, lcf_XLM),\n",
        "#     \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, lcf_Roberta),\n",
        "#     \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer, lcf_DistilBert),\n",
        "#     \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, lcf_Albert),\n",
        "#     \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer, lcf_XLMRoberta),\n",
        "# }\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def train(args, train_dataset, model, tokenizer, tokenizer_cleantext):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True,\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        # set global_step to gobal_step of last saved checkpoint from model path\n",
        "        global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
        "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0],\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_global_type_ids\"] = (\n",
        "                    batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "                inputs[\"token_local_type_ids\"] = (\n",
        "                    batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "            # inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            # if args.model_type != \"distilbert\":\n",
        "            #     inputs[\"token_type_ids\"] = (\n",
        "            #         batch[2] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "            #     )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                #     # Save model checkpoint\n",
        "                #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                #     if not os.path.exists(output_dir):\n",
        "                #         os.makedirs(output_dir)\n",
        "                #     # model_to_save = (\n",
        "                #     #     model.module if hasattr(model, \"module\") else model\n",
        "                #     # )  # Take care of distributed/parallel training\n",
        "                #     # model_to_save.save_pretrained(output_dir)\n",
        "                #     torch.save(model.state_dict(), args.output_dir)\n",
        "                #     tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                #     torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                #     torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                #     logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "\n",
        "def evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_task_names = (\"ichi\",)\n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "\n",
        "    results = {}\n",
        "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
        "        eval_dataset, tokenizer_cleantext = load_and_cache_examples(args, eval_task, tokenizer, tokenizer_cleantext, evaluate=True)\n",
        "\n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        # Note that DistributedSampler samples randomly\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        # multi-gpu eval\n",
        "        if args.n_gpu > 1:\n",
        "            model = torch.nn.DataParallel(model)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        preds_original = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "                if args.model_type != \"distilbert\":\n",
        "                    inputs[\"token_global_type_ids\"] = (\n",
        "                        batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )\n",
        "                    inputs[\"token_local_type_ids\"] = (\n",
        "                        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                preds_original = logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                preds_original = np.append(preds_original, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        result = compute_metrics(preds, out_label_ids) ######################update kar !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "            # for a in preds:\n",
        "            #     writer.write(str(a)+'\\n')\n",
        "            writer.write('[')\n",
        "            for a in preds_original:\n",
        "                writer.write('[')\n",
        "                for c in range(len(a)):\n",
        "                    b = a[c]\n",
        "                    if c!=6:\n",
        "                        writer.write(str(b)+',')\n",
        "                    else:\n",
        "                        writer.write(str(b))\n",
        "                writer.write(']')\n",
        "                writer.write('\\n')\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_type\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "        \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--embedding_dim_word2vec\",\n",
        "        default=300,\n",
        "        type=int,\n",
        "        help=\"embedding dimension for the word vectors in the medical module\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\", action=\"store_true\", help=\"Rul evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=10000, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Prepare GLUE task\n",
        "    args.task_name = 'ichi'\n",
        "    processor = ICHIProcessor()\n",
        "    args.output_mode = \"classification\"\n",
        "    label_list = processor.get_labels()\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class, lcf_model = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(\n",
        "        args.config_name if args.config_name else args.model_name_or_path,\n",
        "        num_labels=num_labels,\n",
        "        finetuning_task=args.task_name,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer_cleantext = Tokenizer(max_seq_len = 1600, max_num_words=20000,lower=True)\n",
        "    # model = model_class.from_pretrained(\n",
        "    #     args.model_name_or_path,\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    args.use_single_bert = False\n",
        "    args.local_context_focus = 'cdm'\n",
        "    args.embedding_type = 'glove'\n",
        "\n",
        "    cached_embeddingmatrix_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedword2vec_{}_{}\".format(\n",
        "            str(args.task_name),\n",
        "            str(\"glove\"),\n",
        "        ),\n",
        "    )\n",
        "    cached_embeddingmatrix_path = \".\"\n",
        "    \n",
        "    train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "    # embedding_matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_embeddingmatrix_file, cached_embeddingmatrix_path)\n",
        "    # print(embedding_matrix.shape)\n",
        "    # print(tokenizer_cleantext.word2idx)\n",
        "    \n",
        "    # args.word2vec = embedding_matrix\n",
        "    # args.emb_size = embedding_matrix.shape[1]\n",
        "    model = lcf_model.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        args=args,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    # model = lcf_Roberta.from_pretrained(\n",
        "    #     \"/home/bt1/17CS10037/new_transformers/transformers/roberta-large-pytorch_model.bin\",\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     args=args,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "    \n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        # train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "        # matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_glove_embeddingmatrix_file, cached_glove_embeddingmatrix_path)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, tokenizer_cleantext)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    result = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        # model_to_save = (\n",
        "        #     model.module if hasattr(model, \"module\") else model\n",
        "        # )  # Take care of distributed/parallel training\n",
        "        # model_to_save.save_pretrained(args.output_dir)\n",
        "        model_name = \"{}.pt\".format(args.model_type)\n",
        "        torch.save(model.state_dict(), os.path.join(args.output_dir,model_name))\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        # model = model_class.from_pretrained(args.output_dir)\n",
        "        model = lcf_model(config, args)\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        cached_tokenizer_cleantext_file = os.path.join(\n",
        "            args.data_dir,\n",
        "            \"cachedtokenizer_{}_{}_{}\".format(\n",
        "                list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "                str(args.embedding_type),\n",
        "                str(args.task_name),\n",
        "            ),\n",
        "        )\n",
        "        if os.path.exists(cached_tokenizer_cleantext_file):\n",
        "            print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "            tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            # model = model_class.from_pretrained(checkpoint)\n",
        "            # model = lcf_model.from_pretrained(\n",
        "            #     args.model_name_or_path,\n",
        "            #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "            #     config=config,\n",
        "            #     args=args,\n",
        "            #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "            # )\n",
        "\n",
        "            model = lcf_model(config, args)\n",
        "            model_name = \"{}.pt\".format(args.model_type)\n",
        "            model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/run_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmpFdc6sbALY",
        "outputId": "0cc58e23-dc40-4f0f-ed5c-01977834320e"
      },
      "source": [
        "!python ./examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir ./new_data --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 1e-4 --num_train_epochs 2 --output_dir ./tmp/ichi_bert_base_new --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-05 04:44:48.968214: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/05/2021 04:44:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/05/2021 04:44:50 - INFO - filelock -   Lock 140197936755152 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9ncz4hvy\n",
            "Downloading: 100% 433/433 [00:00<00:00, 590kB/s]\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/05/2021 04:44:50 - INFO - filelock -   Lock 140197936755152 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "06/05/2021 04:44:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "06/05/2021 04:44:50 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"ichi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "06/05/2021 04:44:50 - INFO - filelock -   Lock 140197843909264 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5axr5_d6\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 14.2MB/s]\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/05/2021 04:44:50 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/05/2021 04:44:50 - INFO - filelock -   Lock 140197843909264 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "06/05/2021 04:44:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "06/05/2021 04:44:50 - INFO - utils_ichi -   Creating features from dataset file at ./new_data\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   Writing example 0/5601\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   guid: train-1\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_global_ids: 101 1045 2318 2893 2122 4629 12201 20398 1999 2026 16148 2003 2009 1037 2668 18856 4140 1045 1005 2310 2318 1037 2261 2420 3283 2893 2122 12201 20398 1999 2026 2849 1045 1005 1049 2656 1998 1037 5610 2099 2005 2385 1061 2869 1045 2196 2018 1037 2668 18856 4140 2077 1998 1045 2123 1005 1056 2113 2065 2023 2003 2028 2515 3087 2113 2054 1037 2668 18856 4140 5683 2066 2030 2065 1045 2031 2028 1029 102 20010 7946 2953 102 2303 3033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_local_ids: 101 1045 2318 2893 2122 4629 12201 20398 1999 2026 16148 2003 2009 1037 2668 18856 4140 1045 1005 2310 2318 1037 2261 2420 3283 2893 2122 12201 20398 1999 2026 2849 1045 1005 1049 2656 1998 1037 5610 2099 2005 2385 1061 2869 1045 2196 2018 1037 2668 18856 4140 2077 1998 1045 2123 1005 1056 2113 2065 2023 2003 2028 2515 3087 2113 2054 1037 2668 18856 4140 5683 2066 2030 2065 1045 2031 2028 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 40 65 837 1896 19 6066 77 1317 1 40 5 79 65 1896 19 460 1 1897 2700 685 171 1 54 77 1317 1 6 11 50 6 77 1317 20 4 1 5079\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   aspect_indices: 20010 7946 2953 2303 3033 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   label: DEMO (id = 0)\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   guid: train-2\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_global_ids: 101 2054 6433 2182 1029 1045 2031 1037 1043 9654 25778 22522 6098 1998 1045 1005 2310 2196 2042 2045 2077 1998 1045 2215 2000 2113 2054 1996 3460 2003 2183 2000 2079 2000 2033 1012 102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_local_ids: 101 2054 6433 2182 1029 1045 2031 1037 1043 9654 25778 22522 6098 1998 1045 1005 2310 2196 2042 2045 2077 1998 1045 2215 2000 2113 2054 1996 3460 2003 2183 2000 2079 2000 2033 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 73 628 2374 1 3664 562 1 54 1 23 6 29 39 126\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   label: DEMO (id = 0)\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   guid: train-3\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_global_ids: 101 4540 13060 1010 3778 1998 14699 3759 1045 2031 7663 2078 2000 2048 2852 2015 1010 1998 2028 4372 2102 1010 1998 1045 1005 1049 2145 2383 1996 2168 3471 2044 2635 1018 2367 24479 1998 1017 5352 1997 3653 10521 5643 1012 1996 4372 2102 2056 1045 2031 8331 2006 2026 4540 1998 2009 3504 2066 2035 2121 17252 4298 1011 2043 2002 2246 2039 1999 2026 4451 2007 1037 23967 1010 1996 2157 2217 2001 5122 1012 1045 2001 2035 24395 7718 1998 2409 1045 2123 1005 1056 2031 2151 1012 1045 2074 3706 2091 2013 2322 11460 1016 2595 2154 2000 2320 1037 2154 1010 2007 1996 3653 2094 8977 5643 1010 1998 2035 1996 3471 1011 2029 2018 5407 2488 1011 2513 1012 1045 2031 1996 13060 1999 2026 2157 4540 1010 2157 2217 1997 2132 5683 2440 1010 2227 2917 5730 14417 2003 8616 1010 3759 2003 14699 1998 1045 2514 5399 14849 1998 2074 3227 2009 1005 1055 3697 2000 4287 2006 2651 1012 1045 2031 1037 4937 13594 5115 1999 2184 2420 2138 2002 2359 2033 2488 2005 2009 1012 1045 2170 1996 102 2303 3033 102 8665 102 14699 3759 2015 102 1999 14971 7542 102 4963 2968 102 5099 3255 102 2003 4458 102 1998 1051 18447 8163 102 19124 102 20010 7946 2953 102 6887 22684 6633 28426 9031 102 4698 2140 27424 28632 102 18168 12474 2075 102 4450 20398 102 17984 2015 102 17758 16183 2075 18589 16892 6593 16940 102 16769 102\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   input_local_ids: 101 4540 13060 1010 3778 1998 14699 3759 1045 2031 7663 2078 2000 2048 2852 2015 1010 1998 2028 4372 2102 1010 1998 1045 1005 1049 2145 2383 1996 2168 3471 2044 2635 1018 2367 24479 1998 1017 5352 1997 3653 10521 5643 1012 1996 4372 2102 2056 1045 2031 8331 2006 2026 4540 1998 2009 3504 2066 2035 2121 17252 4298 1011 2043 2002 2246 2039 1999 2026 4451 2007 1037 23967 1010 1996 2157 2217 2001 5122 1012 1045 2001 2035 24395 7718 1998 2409 1045 2123 1005 1056 2031 2151 1012 1045 2074 3706 2091 2013 2322 11460 1016 2595 2154 2000 2320 1037 2154 1010 2007 1996 3653 2094 8977 5643 1010 1998 2035 1996 3471 1011 2029 2018 5407 2488 1011 2513 1012 1045 2031 1996 13060 1999 2026 2157 4540 1010 2157 2217 1997 2132 5683 2440 1010 2227 2917 5730 14417 2003 8616 1010 3759 2003 14699 1998 1045 2514 5399 14849 1998 2074 3227 2009 1005 1055 3697 2000 4287 2006 2651 1012 1045 2031 1037 4937 13594 5115 1999 2184 2420 2138 2002 2359 2033 2488 2005 2009 1012 1045 2170 1996 4372 2102 1998 2027 2031 2033 2746 2067 1999 1999 1019 2420 1006 999 1007 2000 2022 28667 5369 18141 1012 1012 1012 1045 2342 4335 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 677 8830 418 257 729 1 20002 63 20002 11 20002 1 31 51 88 70 229 765 42 613 20002 10 2701 25 1 642 677 106 4 1144 20002 374 838 20002 41 110 20002 1 1144 441 36 1 5501 1 7620 333 678 3665 5 452 13737 20002 407 13738 8831 1 5080 41 6724 41 110 174 20 8832 404 20002 4410 729 257 1 20 1477 1448 1643 637 1681 1258 1 1710 550 1030 151 5 240 211 90 1 260 2701 316 24 68 20002 20002 1 44 3157\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   aspect_indices: 2303 3033 8665 14699 3759 2015 1999 14971 7542 4963 2968 5099 3255 2003 4458 1998 1051 18447 8163 19124 20010 7946 2953 6887 22684 6633 28426 9031 4698 2140 27424 28632 18168 12474 2075 4450 20398 17984 2015 17758 16183 2075 18589 16892 6593 16940 16769 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:07 - INFO - utils_ichi -   label: DISE (id = 1)\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   guid: train-4\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   input_global_ids: 101 7704 6812 2884 2929 2007 11614 2075 2011 1018 2095 2214 1000 2026 1018 1061 1013 1051 7631 2097 1005 5342 1005 1998 6822 13433 7361 1999 2010 14236 1012 2002 15839 7314 2000 2131 2006 1996 4012 5302 3207 1006 6524 1007 1025 2021 18074 2127 2619 1999 1996 2155 1005 14747 1005 1996 19255 1012 2059 1037 2502 3066 2003 2081 2041 1997 2032 2025 4129 3087 2030 2025 2183 2000 1996 8962 3723 2370 1012 2788 2002 2097 2059 2022 29502 2008 2002 2987 1005 1056 1000 1000 2342 2000 2175 1000 1000 1012 1012 999 999 2664 1996 3350 2003 2045 1999 2010 14236 1012 1012 999 999 2055 2431 1996 2051 2002 2097 2022 3140 2000 4133 2006 1996 11848 2127 2002 2515 2175 1012 1012 1012 1012 2009 2003 2025 5866 2005 2032 2000 2031 2000 4133 2005 2382 2781 2030 2062 1012 1012 1012 2029 1045 2228 2003 9092 15464 21723 2000 8639 1012 1012 1012 1998 2010 2210 3456 4982 15903 1998 2002 4152 1037 2417 2057 7096 2006 1996 2067 1997 2010 3456 2013 1996 2835 1012 1045 4081 1037 2775 1005 1055 22936 11848 3614 2065 2023 3218 2003 2000 3613 1012 2026 2060 10293 2001 2000 1005 8487 2243 1005 2032 1037 3232 1997 16949 2006 2010 10007 2296 2051 1006 3374 1010 1045 1005 1049 2013 1996 1005 2214 2082 1000 102 2303 3033 102 8665 102 5099 3255 102 20010 7946 2953 102 18168 12474 2075 102 4450 20398 102 16769 102\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   input_local_ids: 101 7704 6812 2884 2929 2007 11614 2075 2011 1018 2095 2214 1000 2026 1018 1061 1013 1051 7631 2097 1005 5342 1005 1998 6822 13433 7361 1999 2010 14236 1012 2002 15839 7314 2000 2131 2006 1996 4012 5302 3207 1006 6524 1007 1025 2021 18074 2127 2619 1999 1996 2155 1005 14747 1005 1996 19255 1012 2059 1037 2502 3066 2003 2081 2041 1997 2032 2025 4129 3087 2030 2025 2183 2000 1996 8962 3723 2370 1012 2788 2002 2097 2059 2022 29502 2008 2002 2987 1005 1056 1000 1000 2342 2000 2175 1000 1000 1012 1012 999 999 2664 1996 3350 2003 2045 1999 2010 14236 1012 1012 999 999 2055 2431 1996 2051 2002 2097 2022 3140 2000 4133 2006 1996 11848 2127 2002 2515 2175 1012 1012 1012 1012 2009 2003 2025 5866 2005 2032 2000 2031 2000 4133 2005 2382 2781 2030 2062 1012 1012 1012 2029 1045 2228 2003 9092 15464 21723 2000 8639 1012 1012 1012 1998 2010 2210 3456 4982 15903 1998 2002 4152 1037 2417 2057 7096 2006 1996 2067 1997 2010 3456 2013 1996 2835 1012 1045 4081 1037 2775 1005 1055 22936 11848 3614 2065 2023 3218 2003 2000 3613 1012 2026 2060 10293 2001 2000 1005 8487 2243 1005 2032 1037 3232 1997 16949 2006 2010 10007 2296 2051 1006 3374 1010 1045 1005 1049 2013 1996 1005 2214 2082 1000 1000 1007 2004 2027 4033 1005 1056 2699 14265 7750 1012 1012 1012 1012 2074 1037 2843 1997 5554 4748 8202 102\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1500 952 906 20002 70 2 13 7 70 3871 1342 1754 6725 1644 4411 12 8833 7621 3 20002 20002 343 139 201 658 3478 389 279 574 200 500 50 39 883 2240 242 20002 44 18 20002 359 1838 20002 554 327 9 2702 579 907 13739 2241 579 385 395 20002 1 37 20002 20002 58 280 860 1711 3 216 10643 24 280 10644 1 744 66 13740 907 2119 1898 10645 7 529 6726 189 1533 1899 76 9 13741 1 13 113 1343 116 20002 20002 123 8834 20002 1 336 188 20002 1900 297 20002 12 7622 10646 76 149 3666 5502 178 1092 78 96 348 536 13742 20002 1478 26 23 543 20002 475 168 294 20002 231 467 20002 2538 1597 380 1598 5081 162 20002 2305 490 185 94 97 20002 54 589\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   aspect_indices: 2303 3033 8665 5099 3255 20010 7946 2953 18168 12474 2075 4450 20398 16769 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   label: FAML (id = 5)\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   guid: train-5\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   input_global_ids: 101 23025 20683 4063 2863 19892 10992 2012 2188 2023 2003 4689 1045 2215 2019 2012 2188 8934 1010 1045 2444 1999 17151 1998 1045 2562 4531 3924 2008 2180 2102 2022 2741 2041 2000 17151 1010 2031 6971 2000 4965 2009 2013 1037 2367 1998 2059 2123 2102 4839 2064 2619 2393 2033 1029 1029 102 20010 7946 2953 102 2303 3033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   input_local_ids: 101 23025 20683 4063 2863 19892 10992 2012 2188 2023 2003 4689 1045 2215 2019 2012 2188 8934 1010 1045 2444 1999 17151 1998 1045 2562 4531 3924 2008 2180 2102 2022 2741 2041 2000 17151 1010 2031 6971 2000 4965 2009 2013 1037 2367 1998 2059 2123 2102 4839 2064 2619 2393 2033 1029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 20002 133 953 23 133 13743 338 20002 141 747 11 618 575 20002 1479 1068 229 82 7623 139 17 788\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   aspect_indices: 20010 7946 2953 2303 3033 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 04:46:08 - INFO - utils_ichi -   label: SOCL (id = 6)\n",
            "06/05/2021 04:46:44 - INFO - utils_ichi -   Saving features into cached file ./new_data/cached_train_bert-base-uncased_256_ichi\n",
            "06/05/2021 04:46:48 - INFO - filelock -   Lock 140197344745232 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "06/05/2021 04:46:48 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp3zk8as8_\n",
            "Downloading: 100% 440M/440M [00:07<00:00, 58.1MB/s]\n",
            "06/05/2021 04:46:56 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/05/2021 04:46:56 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/05/2021 04:46:56 - INFO - filelock -   Lock 140197344745232 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "06/05/2021 04:46:56 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "06/05/2021 04:46:59 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "06/05/2021 04:46:59 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "06/05/2021 04:47:10 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./new_data', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='./tmp/ichi_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='ichi', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "06/05/2021 04:47:10 - INFO - __main__ -   ***** Running training *****\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Num examples = 5601\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Num Epochs = 2\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "06/05/2021 04:47:10 - INFO - __main__ -     Total optimization steps = 702\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/351 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   0% 1/351 [00:01<10:00,  1.72s/it]\u001b[A\n",
            "Iteration:   1% 2/351 [00:03<09:28,  1.63s/it]\u001b[A\n",
            "Iteration:   1% 3/351 [00:04<09:06,  1.57s/it]\u001b[A\n",
            "Iteration:   1% 4/351 [00:06<08:51,  1.53s/it]\u001b[A\n",
            "Iteration:   1% 5/351 [00:07<08:41,  1.51s/it]\u001b[A\n",
            "Iteration:   2% 6/351 [00:08<08:33,  1.49s/it]\u001b[A\n",
            "Iteration:   2% 7/351 [00:10<08:28,  1.48s/it]\u001b[A\n",
            "Iteration:   2% 8/351 [00:11<08:24,  1.47s/it]\u001b[A\n",
            "Iteration:   3% 9/351 [00:13<08:19,  1.46s/it]\u001b[A\n",
            "Iteration:   3% 10/351 [00:14<08:17,  1.46s/it]\u001b[A\n",
            "Iteration:   3% 11/351 [00:16<08:15,  1.46s/it]\u001b[A\n",
            "Iteration:   3% 12/351 [00:17<08:15,  1.46s/it]\u001b[A\n",
            "Iteration:   4% 13/351 [00:19<08:13,  1.46s/it]\u001b[A\n",
            "Iteration:   4% 14/351 [00:20<08:13,  1.46s/it]\u001b[A\n",
            "Iteration:   4% 15/351 [00:22<08:12,  1.47s/it]\u001b[A\n",
            "Iteration:   5% 16/351 [00:23<08:11,  1.47s/it]\u001b[A\n",
            "Iteration:   5% 17/351 [00:24<08:09,  1.47s/it]\u001b[A\n",
            "Iteration:   5% 18/351 [00:26<08:10,  1.47s/it]\u001b[A\n",
            "Iteration:   5% 19/351 [00:27<08:11,  1.48s/it]\u001b[A\n",
            "Iteration:   6% 20/351 [00:29<08:11,  1.49s/it]\u001b[A\n",
            "Iteration:   6% 21/351 [00:30<08:13,  1.49s/it]\u001b[A\n",
            "Iteration:   6% 22/351 [00:32<08:11,  1.49s/it]\u001b[A\n",
            "Iteration:   7% 23/351 [00:33<08:09,  1.49s/it]\u001b[A\n",
            "Iteration:   7% 24/351 [00:35<08:09,  1.50s/it]\u001b[A\n",
            "Iteration:   7% 25/351 [00:36<08:09,  1.50s/it]\u001b[A\n",
            "Iteration:   7% 26/351 [00:38<08:10,  1.51s/it]\u001b[A\n",
            "Iteration:   8% 27/351 [00:40<08:09,  1.51s/it]\u001b[A\n",
            "Iteration:   8% 28/351 [00:41<08:11,  1.52s/it]\u001b[A\n",
            "Iteration:   8% 29/351 [00:43<08:08,  1.52s/it]\u001b[A\n",
            "Iteration:   9% 30/351 [00:44<08:06,  1.52s/it]\u001b[A\n",
            "Iteration:   9% 31/351 [00:46<08:05,  1.52s/it]\u001b[A\n",
            "Iteration:   9% 32/351 [00:47<08:05,  1.52s/it]\u001b[A\n",
            "Iteration:   9% 33/351 [00:49<08:05,  1.53s/it]\u001b[A\n",
            "Iteration:  10% 34/351 [00:50<08:05,  1.53s/it]\u001b[A\n",
            "Iteration:  10% 35/351 [00:52<08:04,  1.53s/it]\u001b[A\n",
            "Iteration:  10% 36/351 [00:53<08:05,  1.54s/it]\u001b[A\n",
            "Iteration:  11% 37/351 [00:55<08:06,  1.55s/it]\u001b[A\n",
            "Iteration:  11% 38/351 [00:56<08:05,  1.55s/it]\u001b[A\n",
            "Iteration:  11% 39/351 [00:58<08:05,  1.55s/it]\u001b[A\n",
            "Iteration:  11% 40/351 [01:00<08:04,  1.56s/it]\u001b[A\n",
            "Iteration:  12% 41/351 [01:01<08:03,  1.56s/it]\u001b[A\n",
            "Iteration:  12% 42/351 [01:03<08:06,  1.57s/it]\u001b[A\n",
            "Iteration:  12% 43/351 [01:04<08:05,  1.58s/it]\u001b[A\n",
            "Iteration:  13% 44/351 [01:06<08:05,  1.58s/it]\u001b[A\n",
            "Iteration:  13% 45/351 [01:07<08:03,  1.58s/it]\u001b[A\n",
            "Iteration:  13% 46/351 [01:09<08:02,  1.58s/it]\u001b[A\n",
            "Iteration:  13% 47/351 [01:11<08:03,  1.59s/it]\u001b[A\n",
            "Iteration:  14% 48/351 [01:12<08:05,  1.60s/it]\u001b[A\n",
            "Iteration:  14% 49/351 [01:14<08:03,  1.60s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"learning_rate\": 9.287749287749287e-05, \"loss\": 1.4799833548069001, \"step\": 50}\n",
            "\n",
            "Iteration:  14% 50/351 [01:16<08:01,  1.60s/it]\u001b[A\n",
            "Iteration:  15% 51/351 [01:17<08:01,  1.61s/it]\u001b[A\n",
            "Iteration:  15% 52/351 [01:19<08:01,  1.61s/it]\u001b[A\n",
            "Iteration:  15% 53/351 [01:20<08:00,  1.61s/it]\u001b[A\n",
            "Iteration:  15% 54/351 [01:22<08:01,  1.62s/it]\u001b[A\n",
            "Iteration:  16% 55/351 [01:24<08:00,  1.62s/it]\u001b[A\n",
            "Iteration:  16% 56/351 [01:25<08:01,  1.63s/it]\u001b[A\n",
            "Iteration:  16% 57/351 [01:27<08:00,  1.64s/it]\u001b[A\n",
            "Iteration:  17% 58/351 [01:29<08:02,  1.65s/it]\u001b[A\n",
            "Iteration:  17% 59/351 [01:30<08:04,  1.66s/it]\u001b[A\n",
            "Iteration:  17% 60/351 [01:32<08:04,  1.66s/it]\u001b[A\n",
            "Iteration:  17% 61/351 [01:34<08:05,  1.67s/it]\u001b[A\n",
            "Iteration:  18% 62/351 [01:35<08:08,  1.69s/it]\u001b[A\n",
            "Iteration:  18% 63/351 [01:37<08:07,  1.69s/it]\u001b[A\n",
            "Iteration:  18% 64/351 [01:39<08:08,  1.70s/it]\u001b[A\n",
            "Iteration:  19% 65/351 [01:41<08:08,  1.71s/it]\u001b[A\n",
            "Iteration:  19% 66/351 [01:42<08:07,  1.71s/it]\u001b[A\n",
            "Iteration:  19% 67/351 [01:44<08:06,  1.71s/it]\u001b[A\n",
            "Iteration:  19% 68/351 [01:46<08:05,  1.72s/it]\u001b[A\n",
            "Iteration:  20% 69/351 [01:47<08:05,  1.72s/it]\u001b[A\n",
            "Iteration:  20% 70/351 [01:49<08:04,  1.72s/it]\u001b[A\n",
            "Iteration:  20% 71/351 [01:51<08:02,  1.72s/it]\u001b[A\n",
            "Iteration:  21% 72/351 [01:53<07:59,  1.72s/it]\u001b[A\n",
            "Iteration:  21% 73/351 [01:54<07:57,  1.72s/it]\u001b[A\n",
            "Iteration:  21% 74/351 [01:56<07:53,  1.71s/it]\u001b[A\n",
            "Iteration:  21% 75/351 [01:58<07:49,  1.70s/it]\u001b[A\n",
            "Iteration:  22% 76/351 [01:59<07:46,  1.69s/it]\u001b[A\n",
            "Iteration:  22% 77/351 [02:01<07:43,  1.69s/it]\u001b[A\n",
            "Iteration:  22% 78/351 [02:03<07:40,  1.69s/it]\u001b[A\n",
            "Iteration:  23% 79/351 [02:04<07:38,  1.69s/it]\u001b[A\n",
            "Iteration:  23% 80/351 [02:06<07:35,  1.68s/it]\u001b[A\n",
            "Iteration:  23% 81/351 [02:08<07:32,  1.68s/it]\u001b[A\n",
            "Iteration:  23% 82/351 [02:09<07:27,  1.66s/it]\u001b[A\n",
            "Iteration:  24% 83/351 [02:11<07:23,  1.65s/it]\u001b[A\n",
            "Iteration:  24% 84/351 [02:13<07:20,  1.65s/it]\u001b[A\n",
            "Iteration:  24% 85/351 [02:14<07:18,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 86/351 [02:16<07:16,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 87/351 [02:18<07:12,  1.64s/it]\u001b[A\n",
            "Iteration:  25% 88/351 [02:19<07:10,  1.64s/it]\u001b[A\n",
            "Iteration:  25% 89/351 [02:21<07:07,  1.63s/it]\u001b[A\n",
            "Iteration:  26% 90/351 [02:22<07:04,  1.62s/it]\u001b[A\n",
            "Iteration:  26% 91/351 [02:24<07:06,  1.64s/it]\u001b[A\n",
            "Iteration:  26% 92/351 [02:26<07:01,  1.63s/it]\u001b[A\n",
            "Iteration:  26% 93/351 [02:27<07:02,  1.64s/it]\u001b[A\n",
            "Iteration:  27% 94/351 [02:29<06:59,  1.63s/it]\u001b[A\n",
            "Iteration:  27% 95/351 [02:31<06:57,  1.63s/it]\u001b[A\n",
            "Iteration:  27% 96/351 [02:32<06:55,  1.63s/it]\u001b[A\n",
            "Iteration:  28% 97/351 [02:34<06:53,  1.63s/it]\u001b[A\n",
            "Iteration:  28% 98/351 [02:35<06:51,  1.63s/it]\u001b[A\n",
            "Iteration:  28% 99/351 [02:37<06:49,  1.63s/it]\u001b[A{\"learning_rate\": 8.575498575498576e-05, \"loss\": 1.3202385020256042, \"step\": 100}\n",
            "\n",
            "Iteration:  28% 100/351 [02:39<06:47,  1.62s/it]\u001b[A\n",
            "Iteration:  29% 101/351 [02:40<06:46,  1.62s/it]\u001b[A\n",
            "Iteration:  29% 102/351 [02:42<06:44,  1.63s/it]\u001b[A\n",
            "Iteration:  29% 103/351 [02:44<06:44,  1.63s/it]\u001b[A\n",
            "Iteration:  30% 104/351 [02:45<06:45,  1.64s/it]\u001b[A\n",
            "Iteration:  30% 105/351 [02:47<06:43,  1.64s/it]\u001b[A\n",
            "Iteration:  30% 106/351 [02:49<06:42,  1.64s/it]\u001b[A\n",
            "Iteration:  30% 107/351 [02:50<06:41,  1.65s/it]\u001b[A\n",
            "Iteration:  31% 108/351 [02:52<06:40,  1.65s/it]\u001b[A\n",
            "Iteration:  31% 109/351 [02:53<06:37,  1.64s/it]\u001b[A\n",
            "Iteration:  31% 110/351 [02:55<06:38,  1.65s/it]\u001b[A\n",
            "Iteration:  32% 111/351 [02:57<06:39,  1.66s/it]\u001b[A\n",
            "Iteration:  32% 112/351 [02:59<06:37,  1.67s/it]\u001b[A\n",
            "Iteration:  32% 113/351 [03:00<06:37,  1.67s/it]\u001b[A\n",
            "Iteration:  32% 114/351 [03:02<06:35,  1.67s/it]\u001b[A\n",
            "Iteration:  33% 115/351 [03:04<06:35,  1.68s/it]\u001b[A\n",
            "Iteration:  33% 116/351 [03:05<06:37,  1.69s/it]\u001b[A\n",
            "Iteration:  33% 117/351 [03:07<06:34,  1.69s/it]\u001b[A\n",
            "Iteration:  34% 118/351 [03:09<06:31,  1.68s/it]\u001b[A\n",
            "Iteration:  34% 119/351 [03:10<06:30,  1.68s/it]\u001b[A\n",
            "Iteration:  34% 120/351 [03:12<06:28,  1.68s/it]\u001b[A\n",
            "Iteration:  34% 121/351 [03:14<06:27,  1.68s/it]\u001b[A\n",
            "Iteration:  35% 122/351 [03:15<06:25,  1.68s/it]\u001b[A\n",
            "Iteration:  35% 123/351 [03:17<06:23,  1.68s/it]\u001b[A\n",
            "Iteration:  35% 124/351 [03:19<06:21,  1.68s/it]\u001b[A\n",
            "Iteration:  36% 125/351 [03:20<06:19,  1.68s/it]\u001b[A\n",
            "Iteration:  36% 126/351 [03:22<06:18,  1.68s/it]\u001b[A\n",
            "Iteration:  36% 127/351 [03:24<06:17,  1.68s/it]\u001b[A\n",
            "Iteration:  36% 128/351 [03:25<06:15,  1.68s/it]\u001b[A\n",
            "Iteration:  37% 129/351 [03:27<06:13,  1.68s/it]\u001b[A\n",
            "Iteration:  37% 130/351 [03:29<06:10,  1.68s/it]\u001b[A\n",
            "Iteration:  37% 131/351 [03:30<06:09,  1.68s/it]\u001b[A\n",
            "Iteration:  38% 132/351 [03:32<06:05,  1.67s/it]\u001b[A\n",
            "Iteration:  38% 133/351 [03:34<06:02,  1.66s/it]\u001b[A\n",
            "Iteration:  38% 134/351 [03:35<06:01,  1.66s/it]\u001b[A\n",
            "Iteration:  38% 135/351 [03:37<05:59,  1.67s/it]\u001b[A\n",
            "Iteration:  39% 136/351 [03:39<05:57,  1.66s/it]\u001b[A\n",
            "Iteration:  39% 137/351 [03:40<05:54,  1.66s/it]\u001b[A\n",
            "Iteration:  39% 138/351 [03:42<05:52,  1.65s/it]\u001b[A\n",
            "Iteration:  40% 139/351 [03:44<05:49,  1.65s/it]\u001b[A\n",
            "Iteration:  40% 140/351 [03:45<05:46,  1.64s/it]\u001b[A\n",
            "Iteration:  40% 141/351 [03:47<05:45,  1.64s/it]\u001b[A\n",
            "Iteration:  40% 142/351 [03:49<05:41,  1.63s/it]\u001b[A\n",
            "Iteration:  41% 143/351 [03:50<05:39,  1.63s/it]\u001b[A\n",
            "Iteration:  41% 144/351 [03:52<05:39,  1.64s/it]\u001b[A\n",
            "Iteration:  41% 145/351 [03:54<05:38,  1.64s/it]\u001b[A\n",
            "Iteration:  42% 146/351 [03:55<05:34,  1.63s/it]\u001b[A\n",
            "Iteration:  42% 147/351 [03:57<05:33,  1.63s/it]\u001b[A\n",
            "Iteration:  42% 148/351 [03:58<05:32,  1.64s/it]\u001b[A\n",
            "Iteration:  42% 149/351 [04:00<05:29,  1.63s/it]\u001b[A{\"learning_rate\": 7.863247863247864e-05, \"loss\": 1.167209621667862, \"step\": 150}\n",
            "\n",
            "Iteration:  43% 150/351 [04:02<05:28,  1.64s/it]\u001b[A\n",
            "Iteration:  43% 151/351 [04:03<05:27,  1.64s/it]\u001b[A\n",
            "Iteration:  43% 152/351 [04:05<05:28,  1.65s/it]\u001b[A\n",
            "Iteration:  44% 153/351 [04:07<05:25,  1.64s/it]\u001b[A\n",
            "Iteration:  44% 154/351 [04:08<05:24,  1.65s/it]\u001b[A\n",
            "Iteration:  44% 155/351 [04:10<05:23,  1.65s/it]\u001b[A\n",
            "Iteration:  44% 156/351 [04:12<05:20,  1.65s/it]\u001b[A\n",
            "Iteration:  45% 157/351 [04:13<05:21,  1.66s/it]\u001b[A\n",
            "Iteration:  45% 158/351 [04:15<05:19,  1.65s/it]\u001b[A\n",
            "Iteration:  45% 159/351 [04:17<05:19,  1.67s/it]\u001b[A\n",
            "Iteration:  46% 160/351 [04:18<05:17,  1.66s/it]\u001b[A\n",
            "Iteration:  46% 161/351 [04:20<05:15,  1.66s/it]\u001b[A\n",
            "Iteration:  46% 162/351 [04:22<05:13,  1.66s/it]\u001b[A\n",
            "Iteration:  46% 163/351 [04:23<05:13,  1.67s/it]\u001b[A\n",
            "Iteration:  47% 164/351 [04:25<05:11,  1.67s/it]\u001b[A\n",
            "Iteration:  47% 165/351 [04:27<05:11,  1.68s/it]\u001b[A\n",
            "Iteration:  47% 166/351 [04:28<05:10,  1.68s/it]\u001b[A\n",
            "Iteration:  48% 167/351 [04:30<05:08,  1.68s/it]\u001b[A\n",
            "Iteration:  48% 168/351 [04:32<05:08,  1.68s/it]\u001b[A\n",
            "Iteration:  48% 169/351 [04:33<05:05,  1.68s/it]\u001b[A\n",
            "Iteration:  48% 170/351 [04:35<05:05,  1.69s/it]\u001b[A\n",
            "Iteration:  49% 171/351 [04:37<05:02,  1.68s/it]\u001b[A\n",
            "Iteration:  49% 172/351 [04:38<05:00,  1.68s/it]\u001b[A\n",
            "Iteration:  49% 173/351 [04:40<04:59,  1.68s/it]\u001b[A\n",
            "Iteration:  50% 174/351 [04:42<04:57,  1.68s/it]\u001b[A\n",
            "Iteration:  50% 175/351 [04:43<04:56,  1.68s/it]\u001b[A\n",
            "Iteration:  50% 176/351 [04:45<04:54,  1.68s/it]\u001b[A\n",
            "Iteration:  50% 177/351 [04:47<04:52,  1.68s/it]\u001b[A\n",
            "Iteration:  51% 178/351 [04:48<04:51,  1.69s/it]\u001b[A\n",
            "Iteration:  51% 179/351 [04:50<04:49,  1.68s/it]\u001b[A\n",
            "Iteration:  51% 180/351 [04:52<04:47,  1.68s/it]\u001b[A\n",
            "Iteration:  52% 181/351 [04:54<04:45,  1.68s/it]\u001b[A\n",
            "Iteration:  52% 182/351 [04:55<04:42,  1.67s/it]\u001b[A\n",
            "Iteration:  52% 183/351 [04:57<04:41,  1.67s/it]\u001b[A\n",
            "Iteration:  52% 184/351 [04:59<04:38,  1.67s/it]\u001b[A\n",
            "Iteration:  53% 185/351 [05:00<04:37,  1.67s/it]\u001b[A\n",
            "Iteration:  53% 186/351 [05:02<04:34,  1.66s/it]\u001b[A\n",
            "Iteration:  53% 187/351 [05:04<04:33,  1.67s/it]\u001b[A\n",
            "Iteration:  54% 188/351 [05:05<04:31,  1.66s/it]\u001b[A\n",
            "Iteration:  54% 189/351 [05:07<04:28,  1.66s/it]\u001b[A\n",
            "Iteration:  54% 190/351 [05:08<04:25,  1.65s/it]\u001b[A\n",
            "Iteration:  54% 191/351 [05:10<04:24,  1.65s/it]\u001b[A\n",
            "Iteration:  55% 192/351 [05:12<04:23,  1.65s/it]\u001b[A\n",
            "Iteration:  55% 193/351 [05:13<04:21,  1.66s/it]\u001b[A\n",
            "Iteration:  55% 194/351 [05:15<04:20,  1.66s/it]\u001b[A\n",
            "Iteration:  56% 195/351 [05:17<04:17,  1.65s/it]\u001b[A\n",
            "Iteration:  56% 196/351 [05:18<04:17,  1.66s/it]\u001b[A\n",
            "Iteration:  56% 197/351 [05:20<04:15,  1.66s/it]\u001b[A\n",
            "Iteration:  56% 198/351 [05:22<04:12,  1.65s/it]\u001b[A\n",
            "Iteration:  57% 199/351 [05:23<04:11,  1.65s/it]\u001b[A{\"learning_rate\": 7.150997150997152e-05, \"loss\": 1.0925088489055634, \"step\": 200}\n",
            "\n",
            "Iteration:  57% 200/351 [05:25<04:08,  1.65s/it]\u001b[A\n",
            "Iteration:  57% 201/351 [05:27<04:07,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 202/351 [05:28<04:05,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 203/351 [05:30<04:03,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 204/351 [05:32<04:01,  1.64s/it]\u001b[A\n",
            "Iteration:  58% 205/351 [05:33<04:00,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 206/351 [05:35<03:58,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 207/351 [05:37<03:57,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 208/351 [05:38<03:55,  1.65s/it]\u001b[A\n",
            "Iteration:  60% 209/351 [05:40<03:53,  1.65s/it]\u001b[A\n",
            "Iteration:  60% 210/351 [05:41<03:52,  1.65s/it]\u001b[A\n",
            "Iteration:  60% 211/351 [05:43<03:51,  1.65s/it]\u001b[A\n",
            "Iteration:  60% 212/351 [05:45<03:49,  1.65s/it]\u001b[A\n",
            "Iteration:  61% 213/351 [05:46<03:48,  1.65s/it]\u001b[A\n",
            "Iteration:  61% 214/351 [05:48<03:45,  1.65s/it]\u001b[A\n",
            "Iteration:  61% 215/351 [05:50<03:43,  1.64s/it]\u001b[A\n",
            "Iteration:  62% 216/351 [05:51<03:42,  1.65s/it]\u001b[A\n",
            "Iteration:  62% 217/351 [05:53<03:41,  1.66s/it]\u001b[A\n",
            "Iteration:  62% 218/351 [05:55<03:40,  1.65s/it]\u001b[A\n",
            "Iteration:  62% 219/351 [05:56<03:38,  1.65s/it]\u001b[A\n",
            "Iteration:  63% 220/351 [05:58<03:36,  1.65s/it]\u001b[A\n",
            "Iteration:  63% 221/351 [06:00<03:35,  1.66s/it]\u001b[A\n",
            "Iteration:  63% 222/351 [06:01<03:33,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 223/351 [06:03<03:31,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 224/351 [06:05<03:29,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 225/351 [06:06<03:27,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 226/351 [06:08<03:25,  1.65s/it]\u001b[A\n",
            "Iteration:  65% 227/351 [06:10<03:24,  1.65s/it]\u001b[A\n",
            "Iteration:  65% 228/351 [06:11<03:22,  1.65s/it]\u001b[A\n",
            "Iteration:  65% 229/351 [06:13<03:20,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 230/351 [06:14<03:19,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 231/351 [06:16<03:17,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 232/351 [06:18<03:16,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 233/351 [06:19<03:14,  1.65s/it]\u001b[A\n",
            "Iteration:  67% 234/351 [06:21<03:12,  1.65s/it]\u001b[A\n",
            "Iteration:  67% 235/351 [06:23<03:10,  1.64s/it]\u001b[A\n",
            "Iteration:  67% 236/351 [06:24<03:08,  1.64s/it]\u001b[A\n",
            "Iteration:  68% 237/351 [06:26<03:07,  1.64s/it]\u001b[A\n",
            "Iteration:  68% 238/351 [06:28<03:05,  1.64s/it]\u001b[A\n",
            "Iteration:  68% 239/351 [06:29<03:04,  1.65s/it]\u001b[A\n",
            "Iteration:  68% 240/351 [06:31<03:02,  1.65s/it]\u001b[A\n",
            "Iteration:  69% 241/351 [06:33<03:01,  1.65s/it]\u001b[A\n",
            "Iteration:  69% 242/351 [06:34<03:00,  1.65s/it]\u001b[A\n",
            "Iteration:  69% 243/351 [06:36<02:58,  1.65s/it]\u001b[A\n",
            "Iteration:  70% 244/351 [06:38<02:56,  1.65s/it]\u001b[A\n",
            "Iteration:  70% 245/351 [06:39<02:55,  1.66s/it]\u001b[A\n",
            "Iteration:  70% 246/351 [06:41<02:53,  1.66s/it]\u001b[A\n",
            "Iteration:  70% 247/351 [06:43<02:52,  1.66s/it]\u001b[A\n",
            "Iteration:  71% 248/351 [06:44<02:50,  1.66s/it]\u001b[A\n",
            "Iteration:  71% 249/351 [06:46<02:49,  1.66s/it]\u001b[A{\"learning_rate\": 6.438746438746439e-05, \"loss\": 1.0629353594779969, \"step\": 250}\n",
            "\n",
            "Iteration:  71% 250/351 [06:48<02:47,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 251/351 [06:49<02:46,  1.67s/it]\u001b[A\n",
            "Iteration:  72% 252/351 [06:51<02:44,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 253/351 [06:53<02:43,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 254/351 [06:54<02:41,  1.66s/it]\u001b[A\n",
            "Iteration:  73% 255/351 [06:56<02:39,  1.67s/it]\u001b[A\n",
            "Iteration:  73% 256/351 [06:58<02:38,  1.67s/it]\u001b[A\n",
            "Iteration:  73% 257/351 [06:59<02:36,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 258/351 [07:01<02:35,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 259/351 [07:03<02:34,  1.68s/it]\u001b[A\n",
            "Iteration:  74% 260/351 [07:04<02:32,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 261/351 [07:06<02:29,  1.66s/it]\u001b[A\n",
            "Iteration:  75% 262/351 [07:08<02:28,  1.67s/it]\u001b[A\n",
            "Iteration:  75% 263/351 [07:09<02:26,  1.67s/it]\u001b[A\n",
            "Iteration:  75% 264/351 [07:11<02:25,  1.67s/it]\u001b[A\n",
            "Iteration:  75% 265/351 [07:13<02:23,  1.67s/it]\u001b[A\n",
            "Iteration:  76% 266/351 [07:14<02:21,  1.67s/it]\u001b[A\n",
            "Iteration:  76% 267/351 [07:16<02:21,  1.68s/it]\u001b[A\n",
            "Iteration:  76% 268/351 [07:18<02:18,  1.67s/it]\u001b[A\n",
            "Iteration:  77% 269/351 [07:19<02:16,  1.67s/it]\u001b[A\n",
            "Iteration:  77% 270/351 [07:21<02:14,  1.66s/it]\u001b[A\n",
            "Iteration:  77% 271/351 [07:23<02:13,  1.67s/it]\u001b[A\n",
            "Iteration:  77% 272/351 [07:24<02:11,  1.66s/it]\u001b[A\n",
            "Iteration:  78% 273/351 [07:26<02:10,  1.67s/it]\u001b[A\n",
            "Iteration:  78% 274/351 [07:28<02:08,  1.66s/it]\u001b[A\n",
            "Iteration:  78% 275/351 [07:29<02:06,  1.67s/it]\u001b[A\n",
            "Iteration:  79% 276/351 [07:31<02:05,  1.67s/it]\u001b[A\n",
            "Iteration:  79% 277/351 [07:33<02:02,  1.66s/it]\u001b[A\n",
            "Iteration:  79% 278/351 [07:34<02:00,  1.66s/it]\u001b[A\n",
            "Iteration:  79% 279/351 [07:36<01:59,  1.66s/it]\u001b[A\n",
            "Iteration:  80% 280/351 [07:38<01:57,  1.66s/it]\u001b[A\n",
            "Iteration:  80% 281/351 [07:39<01:55,  1.65s/it]\u001b[A\n",
            "Iteration:  80% 282/351 [07:41<01:54,  1.66s/it]\u001b[A\n",
            "Iteration:  81% 283/351 [07:42<01:52,  1.65s/it]\u001b[A\n",
            "Iteration:  81% 284/351 [07:44<01:50,  1.65s/it]\u001b[A\n",
            "Iteration:  81% 285/351 [07:46<01:49,  1.65s/it]\u001b[A\n",
            "Iteration:  81% 286/351 [07:47<01:47,  1.65s/it]\u001b[A\n",
            "Iteration:  82% 287/351 [07:49<01:45,  1.65s/it]\u001b[A\n",
            "Iteration:  82% 288/351 [07:51<01:43,  1.65s/it]\u001b[A\n",
            "Iteration:  82% 289/351 [07:52<01:41,  1.64s/it]\u001b[A\n",
            "Iteration:  83% 290/351 [07:54<01:40,  1.64s/it]\u001b[A\n",
            "Iteration:  83% 291/351 [07:56<01:38,  1.64s/it]\u001b[A\n",
            "Iteration:  83% 292/351 [07:57<01:36,  1.64s/it]\u001b[A\n",
            "Iteration:  83% 293/351 [07:59<01:35,  1.64s/it]\u001b[A\n",
            "Iteration:  84% 294/351 [08:00<01:33,  1.63s/it]\u001b[A\n",
            "Iteration:  84% 295/351 [08:02<01:32,  1.64s/it]\u001b[A\n",
            "Iteration:  84% 296/351 [08:04<01:30,  1.64s/it]\u001b[A\n",
            "Iteration:  85% 297/351 [08:05<01:28,  1.64s/it]\u001b[A\n",
            "Iteration:  85% 298/351 [08:07<01:27,  1.65s/it]\u001b[A\n",
            "Iteration:  85% 299/351 [08:09<01:25,  1.64s/it]\u001b[A{\"learning_rate\": 5.726495726495726e-05, \"loss\": 1.0191065049171448, \"step\": 300}\n",
            "\n",
            "Iteration:  85% 300/351 [08:10<01:24,  1.65s/it]\u001b[A\n",
            "Iteration:  86% 301/351 [08:12<01:22,  1.65s/it]\u001b[A\n",
            "Iteration:  86% 302/351 [08:14<01:21,  1.66s/it]\u001b[A\n",
            "Iteration:  86% 303/351 [08:15<01:19,  1.65s/it]\u001b[A\n",
            "Iteration:  87% 304/351 [08:17<01:17,  1.65s/it]\u001b[A\n",
            "Iteration:  87% 305/351 [08:19<01:15,  1.65s/it]\u001b[A\n",
            "Iteration:  87% 306/351 [08:20<01:14,  1.65s/it]\u001b[A\n",
            "Iteration:  87% 307/351 [08:22<01:12,  1.65s/it]\u001b[A\n",
            "Iteration:  88% 308/351 [08:24<01:10,  1.65s/it]\u001b[A\n",
            "Iteration:  88% 309/351 [08:25<01:09,  1.66s/it]\u001b[A\n",
            "Iteration:  88% 310/351 [08:27<01:08,  1.66s/it]\u001b[A\n",
            "Iteration:  89% 311/351 [08:29<01:06,  1.66s/it]\u001b[A\n",
            "Iteration:  89% 312/351 [08:30<01:04,  1.67s/it]\u001b[A\n",
            "Iteration:  89% 313/351 [08:32<01:03,  1.67s/it]\u001b[A\n",
            "Iteration:  89% 314/351 [08:34<01:01,  1.66s/it]\u001b[A\n",
            "Iteration:  90% 315/351 [08:35<00:59,  1.67s/it]\u001b[A\n",
            "Iteration:  90% 316/351 [08:37<00:58,  1.68s/it]\u001b[A\n",
            "Iteration:  90% 317/351 [08:39<00:56,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 318/351 [08:40<00:54,  1.66s/it]\u001b[A\n",
            "Iteration:  91% 319/351 [08:42<00:53,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 320/351 [08:44<00:51,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 321/351 [08:45<00:50,  1.67s/it]\u001b[A\n",
            "Iteration:  92% 322/351 [08:47<00:48,  1.68s/it]\u001b[A\n",
            "Iteration:  92% 323/351 [08:49<00:46,  1.67s/it]\u001b[A\n",
            "Iteration:  92% 324/351 [08:50<00:45,  1.67s/it]\u001b[A\n",
            "Iteration:  93% 325/351 [08:52<00:43,  1.67s/it]\u001b[A\n",
            "Iteration:  93% 326/351 [08:54<00:41,  1.68s/it]\u001b[A\n",
            "Iteration:  93% 327/351 [08:55<00:40,  1.67s/it]\u001b[A\n",
            "Iteration:  93% 328/351 [08:57<00:38,  1.68s/it]\u001b[A\n",
            "Iteration:  94% 329/351 [08:59<00:36,  1.68s/it]\u001b[A\n",
            "Iteration:  94% 330/351 [09:00<00:35,  1.67s/it]\u001b[A\n",
            "Iteration:  94% 331/351 [09:02<00:33,  1.67s/it]\u001b[A\n",
            "Iteration:  95% 332/351 [09:04<00:31,  1.67s/it]\u001b[A\n",
            "Iteration:  95% 333/351 [09:05<00:29,  1.66s/it]\u001b[A\n",
            "Iteration:  95% 334/351 [09:07<00:28,  1.66s/it]\u001b[A\n",
            "Iteration:  95% 335/351 [09:09<00:26,  1.66s/it]\u001b[A\n",
            "Iteration:  96% 336/351 [09:10<00:24,  1.67s/it]\u001b[A\n",
            "Iteration:  96% 337/351 [09:12<00:23,  1.66s/it]\u001b[A\n",
            "Iteration:  96% 338/351 [09:14<00:21,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 339/351 [09:15<00:19,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 340/351 [09:17<00:18,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 341/351 [09:19<00:16,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 342/351 [09:20<00:14,  1.66s/it]\u001b[A\n",
            "Iteration:  98% 343/351 [09:22<00:13,  1.65s/it]\u001b[A\n",
            "Iteration:  98% 344/351 [09:24<00:11,  1.65s/it]\u001b[A\n",
            "Iteration:  98% 345/351 [09:25<00:09,  1.65s/it]\u001b[A\n",
            "Iteration:  99% 346/351 [09:27<00:08,  1.64s/it]\u001b[A\n",
            "Iteration:  99% 347/351 [09:29<00:06,  1.64s/it]\u001b[A\n",
            "Iteration:  99% 348/351 [09:30<00:04,  1.64s/it]\u001b[A\n",
            "Iteration:  99% 349/351 [09:32<00:03,  1.65s/it]\u001b[A{\"learning_rate\": 5.0142450142450145e-05, \"loss\": 1.0192191451787949, \"step\": 350}\n",
            "\n",
            "Iteration: 100% 350/351 [09:33<00:01,  1.64s/it]\u001b[A\n",
            "Iteration: 100% 351/351 [09:34<00:00,  1.64s/it]\n",
            "Epoch:  50% 1/2 [09:34<09:34, 574.13s/it]\n",
            "Iteration:   0% 0/351 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/351 [00:01<09:36,  1.65s/it]\u001b[A\n",
            "Iteration:   1% 2/351 [00:03<09:33,  1.64s/it]\u001b[A\n",
            "Iteration:   1% 3/351 [00:04<09:33,  1.65s/it]\u001b[A\n",
            "Iteration:   1% 4/351 [00:06<09:30,  1.64s/it]\u001b[A\n",
            "Iteration:   1% 5/351 [00:08<09:28,  1.64s/it]\u001b[A\n",
            "Iteration:   2% 6/351 [00:09<09:27,  1.64s/it]\u001b[A\n",
            "Iteration:   2% 7/351 [00:11<09:25,  1.64s/it]\u001b[A\n",
            "Iteration:   2% 8/351 [00:13<09:24,  1.65s/it]\u001b[A\n",
            "Iteration:   3% 9/351 [00:14<09:20,  1.64s/it]\u001b[A\n",
            "Iteration:   3% 10/351 [00:16<09:20,  1.64s/it]\u001b[A\n",
            "Iteration:   3% 11/351 [00:18<09:19,  1.65s/it]\u001b[A\n",
            "Iteration:   3% 12/351 [00:19<09:18,  1.65s/it]\u001b[A\n",
            "Iteration:   4% 13/351 [00:21<09:18,  1.65s/it]\u001b[A\n",
            "Iteration:   4% 14/351 [00:23<09:18,  1.66s/it]\u001b[A\n",
            "Iteration:   4% 15/351 [00:24<09:14,  1.65s/it]\u001b[A\n",
            "Iteration:   5% 16/351 [00:26<09:14,  1.66s/it]\u001b[A\n",
            "Iteration:   5% 17/351 [00:28<09:13,  1.66s/it]\u001b[A\n",
            "Iteration:   5% 18/351 [00:29<09:11,  1.66s/it]\u001b[A\n",
            "Iteration:   5% 19/351 [00:31<09:08,  1.65s/it]\u001b[A\n",
            "Iteration:   6% 20/351 [00:32<09:08,  1.66s/it]\u001b[A\n",
            "Iteration:   6% 21/351 [00:34<09:06,  1.66s/it]\u001b[A\n",
            "Iteration:   6% 22/351 [00:36<09:04,  1.65s/it]\u001b[A\n",
            "Iteration:   7% 23/351 [00:37<09:02,  1.65s/it]\u001b[A\n",
            "Iteration:   7% 24/351 [00:39<09:02,  1.66s/it]\u001b[A\n",
            "Iteration:   7% 25/351 [00:41<09:01,  1.66s/it]\u001b[A\n",
            "Iteration:   7% 26/351 [00:42<08:59,  1.66s/it]\u001b[A\n",
            "Iteration:   8% 27/351 [00:44<08:59,  1.66s/it]\u001b[A\n",
            "Iteration:   8% 28/351 [00:46<08:56,  1.66s/it]\u001b[A\n",
            "Iteration:   8% 29/351 [00:47<08:54,  1.66s/it]\u001b[A\n",
            "Iteration:   9% 30/351 [00:49<08:55,  1.67s/it]\u001b[A\n",
            "Iteration:   9% 31/351 [00:51<08:51,  1.66s/it]\u001b[A\n",
            "Iteration:   9% 32/351 [00:52<08:49,  1.66s/it]\u001b[A\n",
            "Iteration:   9% 33/351 [00:54<08:48,  1.66s/it]\u001b[A\n",
            "Iteration:  10% 34/351 [00:56<08:46,  1.66s/it]\u001b[A\n",
            "Iteration:  10% 35/351 [00:57<08:45,  1.66s/it]\u001b[A\n",
            "Iteration:  10% 36/351 [00:59<08:43,  1.66s/it]\u001b[A\n",
            "Iteration:  11% 37/351 [01:01<08:41,  1.66s/it]\u001b[A\n",
            "Iteration:  11% 38/351 [01:02<08:39,  1.66s/it]\u001b[A\n",
            "Iteration:  11% 39/351 [01:04<08:37,  1.66s/it]\u001b[A\n",
            "Iteration:  11% 40/351 [01:06<08:36,  1.66s/it]\u001b[A\n",
            "Iteration:  12% 41/351 [01:07<08:34,  1.66s/it]\u001b[A\n",
            "Iteration:  12% 42/351 [01:09<08:34,  1.67s/it]\u001b[A\n",
            "Iteration:  12% 43/351 [01:11<08:31,  1.66s/it]\u001b[A\n",
            "Iteration:  13% 44/351 [01:12<08:30,  1.66s/it]\u001b[A\n",
            "Iteration:  13% 45/351 [01:14<08:29,  1.66s/it]\u001b[A\n",
            "Iteration:  13% 46/351 [01:16<08:26,  1.66s/it]\u001b[A\n",
            "Iteration:  13% 47/351 [01:17<08:29,  1.68s/it]\u001b[A\n",
            "Iteration:  14% 48/351 [01:19<08:24,  1.66s/it]\u001b[A{\"learning_rate\": 4.301994301994302e-05, \"loss\": 0.7312154769897461, \"step\": 400}\n",
            "\n",
            "Iteration:  14% 49/351 [01:21<08:22,  1.66s/it]\u001b[A\n",
            "Iteration:  14% 50/351 [01:22<08:21,  1.67s/it]\u001b[A\n",
            "Iteration:  15% 51/351 [01:24<08:19,  1.66s/it]\u001b[A\n",
            "Iteration:  15% 52/351 [01:26<08:18,  1.67s/it]\u001b[A\n",
            "Iteration:  15% 53/351 [01:27<08:15,  1.66s/it]\u001b[A\n",
            "Iteration:  15% 54/351 [01:29<08:14,  1.66s/it]\u001b[A\n",
            "Iteration:  16% 55/351 [01:31<08:10,  1.66s/it]\u001b[A\n",
            "Iteration:  16% 56/351 [01:32<08:08,  1.66s/it]\u001b[A\n",
            "Iteration:  16% 57/351 [01:34<08:06,  1.66s/it]\u001b[A\n",
            "Iteration:  17% 58/351 [01:36<08:05,  1.66s/it]\u001b[A\n",
            "Iteration:  17% 59/351 [01:37<08:02,  1.65s/it]\u001b[A\n",
            "Iteration:  17% 60/351 [01:39<07:59,  1.65s/it]\u001b[A\n",
            "Iteration:  17% 61/351 [01:41<07:57,  1.65s/it]\u001b[A\n",
            "Iteration:  18% 62/351 [01:42<07:55,  1.65s/it]\u001b[A\n",
            "Iteration:  18% 63/351 [01:44<07:54,  1.65s/it]\u001b[A\n",
            "Iteration:  18% 64/351 [01:45<07:52,  1.65s/it]\u001b[A\n",
            "Iteration:  19% 65/351 [01:47<07:53,  1.66s/it]\u001b[A\n",
            "Iteration:  19% 66/351 [01:49<07:51,  1.65s/it]\u001b[A\n",
            "Iteration:  19% 67/351 [01:50<07:49,  1.65s/it]\u001b[A\n",
            "Iteration:  19% 68/351 [01:52<07:48,  1.66s/it]\u001b[A\n",
            "Iteration:  20% 69/351 [01:54<07:45,  1.65s/it]\u001b[A\n",
            "Iteration:  20% 70/351 [01:55<07:46,  1.66s/it]\u001b[A\n",
            "Iteration:  20% 71/351 [01:57<07:44,  1.66s/it]\u001b[A\n",
            "Iteration:  21% 72/351 [01:59<07:41,  1.65s/it]\u001b[A\n",
            "Iteration:  21% 73/351 [02:00<07:39,  1.65s/it]\u001b[A\n",
            "Iteration:  21% 74/351 [02:02<07:38,  1.66s/it]\u001b[A\n",
            "Iteration:  21% 75/351 [02:04<07:37,  1.66s/it]\u001b[A\n",
            "Iteration:  22% 76/351 [02:05<07:34,  1.65s/it]\u001b[A\n",
            "Iteration:  22% 77/351 [02:07<07:32,  1.65s/it]\u001b[A\n",
            "Iteration:  22% 78/351 [02:09<07:29,  1.65s/it]\u001b[A\n",
            "Iteration:  23% 79/351 [02:10<07:28,  1.65s/it]\u001b[A\n",
            "Iteration:  23% 80/351 [02:12<07:27,  1.65s/it]\u001b[A\n",
            "Iteration:  23% 81/351 [02:14<07:25,  1.65s/it]\u001b[A\n",
            "Iteration:  23% 82/351 [02:15<07:24,  1.65s/it]\u001b[A\n",
            "Iteration:  24% 83/351 [02:17<07:22,  1.65s/it]\u001b[A\n",
            "Iteration:  24% 84/351 [02:19<07:22,  1.66s/it]\u001b[A\n",
            "Iteration:  24% 85/351 [02:20<07:19,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 86/351 [02:22<07:17,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 87/351 [02:24<07:16,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 88/351 [02:25<07:13,  1.65s/it]\u001b[A\n",
            "Iteration:  25% 89/351 [02:27<07:12,  1.65s/it]\u001b[A\n",
            "Iteration:  26% 90/351 [02:28<07:10,  1.65s/it]\u001b[A\n",
            "Iteration:  26% 91/351 [02:30<07:08,  1.65s/it]\u001b[A\n",
            "Iteration:  26% 92/351 [02:32<07:07,  1.65s/it]\u001b[A\n",
            "Iteration:  26% 93/351 [02:33<07:06,  1.65s/it]\u001b[A\n",
            "Iteration:  27% 94/351 [02:35<07:03,  1.65s/it]\u001b[A\n",
            "Iteration:  27% 95/351 [02:37<07:02,  1.65s/it]\u001b[A\n",
            "Iteration:  27% 96/351 [02:38<06:59,  1.65s/it]\u001b[A\n",
            "Iteration:  28% 97/351 [02:40<06:59,  1.65s/it]\u001b[A\n",
            "Iteration:  28% 98/351 [02:42<06:56,  1.65s/it]\u001b[A{\"learning_rate\": 3.58974358974359e-05, \"loss\": 0.7816406440734863, \"step\": 450}\n",
            "\n",
            "Iteration:  28% 99/351 [02:43<06:55,  1.65s/it]\u001b[A\n",
            "Iteration:  28% 100/351 [02:45<06:57,  1.66s/it]\u001b[A\n",
            "Iteration:  29% 101/351 [02:47<06:53,  1.66s/it]\u001b[A\n",
            "Iteration:  29% 102/351 [02:48<06:50,  1.65s/it]\u001b[A\n",
            "Iteration:  29% 103/351 [02:50<06:49,  1.65s/it]\u001b[A\n",
            "Iteration:  30% 104/351 [02:52<06:47,  1.65s/it]\u001b[A\n",
            "Iteration:  30% 105/351 [02:53<06:47,  1.66s/it]\u001b[A\n",
            "Iteration:  30% 106/351 [02:55<06:43,  1.65s/it]\u001b[A\n",
            "Iteration:  30% 107/351 [02:57<06:42,  1.65s/it]\u001b[A\n",
            "Iteration:  31% 108/351 [02:58<06:41,  1.65s/it]\u001b[A\n",
            "Iteration:  31% 109/351 [03:00<06:41,  1.66s/it]\u001b[A\n",
            "Iteration:  31% 110/351 [03:02<06:37,  1.65s/it]\u001b[A\n",
            "Iteration:  32% 111/351 [03:03<06:37,  1.66s/it]\u001b[A\n",
            "Iteration:  32% 112/351 [03:05<06:34,  1.65s/it]\u001b[A\n",
            "Iteration:  32% 113/351 [03:06<06:33,  1.65s/it]\u001b[A\n",
            "Iteration:  32% 114/351 [03:08<06:31,  1.65s/it]\u001b[A\n",
            "Iteration:  33% 115/351 [03:10<06:31,  1.66s/it]\u001b[A\n",
            "Iteration:  33% 116/351 [03:11<06:29,  1.66s/it]\u001b[A\n",
            "Iteration:  33% 117/351 [03:13<06:29,  1.66s/it]\u001b[A\n",
            "Iteration:  34% 118/351 [03:15<06:28,  1.67s/it]\u001b[A\n",
            "Iteration:  34% 119/351 [03:16<06:25,  1.66s/it]\u001b[A\n",
            "Iteration:  34% 120/351 [03:18<06:25,  1.67s/it]\u001b[A\n",
            "Iteration:  34% 121/351 [03:20<06:23,  1.67s/it]\u001b[A\n",
            "Iteration:  35% 122/351 [03:21<06:21,  1.67s/it]\u001b[A\n",
            "Iteration:  35% 123/351 [03:23<06:20,  1.67s/it]\u001b[A\n",
            "Iteration:  35% 124/351 [03:25<06:18,  1.67s/it]\u001b[A\n",
            "Iteration:  36% 125/351 [03:27<06:18,  1.67s/it]\u001b[A\n",
            "Iteration:  36% 126/351 [03:28<06:16,  1.67s/it]\u001b[A\n",
            "Iteration:  36% 127/351 [03:30<06:14,  1.67s/it]\u001b[A\n",
            "Iteration:  36% 128/351 [03:32<06:12,  1.67s/it]\u001b[A\n",
            "Iteration:  37% 129/351 [03:33<06:11,  1.67s/it]\u001b[A\n",
            "Iteration:  37% 130/351 [03:35<06:09,  1.67s/it]\u001b[A\n",
            "Iteration:  37% 131/351 [03:37<06:07,  1.67s/it]\u001b[A\n",
            "Iteration:  38% 132/351 [03:38<06:04,  1.67s/it]\u001b[A\n",
            "Iteration:  38% 133/351 [03:40<06:03,  1.67s/it]\u001b[A\n",
            "Iteration:  38% 134/351 [03:42<06:00,  1.66s/it]\u001b[A\n",
            "Iteration:  38% 135/351 [03:43<05:58,  1.66s/it]\u001b[A\n",
            "Iteration:  39% 136/351 [03:45<05:57,  1.66s/it]\u001b[A\n",
            "Iteration:  39% 137/351 [03:46<05:55,  1.66s/it]\u001b[A\n",
            "Iteration:  39% 138/351 [03:48<05:54,  1.67s/it]\u001b[A\n",
            "Iteration:  40% 139/351 [03:50<05:51,  1.66s/it]\u001b[A\n",
            "Iteration:  40% 140/351 [03:51<05:49,  1.66s/it]\u001b[A\n",
            "Iteration:  40% 141/351 [03:53<05:47,  1.66s/it]\u001b[A\n",
            "Iteration:  40% 142/351 [03:55<05:47,  1.66s/it]\u001b[A\n",
            "Iteration:  41% 143/351 [03:56<05:46,  1.67s/it]\u001b[A\n",
            "Iteration:  41% 144/351 [03:58<05:45,  1.67s/it]\u001b[A\n",
            "Iteration:  41% 145/351 [04:00<05:44,  1.67s/it]\u001b[A\n",
            "Iteration:  42% 146/351 [04:01<05:40,  1.66s/it]\u001b[A\n",
            "Iteration:  42% 147/351 [04:03<05:39,  1.66s/it]\u001b[A\n",
            "Iteration:  42% 148/351 [04:05<05:38,  1.67s/it]\u001b[A{\"learning_rate\": 2.8774928774928778e-05, \"loss\": 0.6996167552471161, \"step\": 500}\n",
            "\n",
            "Iteration:  42% 149/351 [04:06<05:34,  1.66s/it]\u001b[A\n",
            "Iteration:  43% 150/351 [04:08<05:33,  1.66s/it]\u001b[A\n",
            "Iteration:  43% 151/351 [04:10<05:31,  1.66s/it]\u001b[A\n",
            "Iteration:  43% 152/351 [04:11<05:30,  1.66s/it]\u001b[A\n",
            "Iteration:  44% 153/351 [04:13<05:28,  1.66s/it]\u001b[A\n",
            "Iteration:  44% 154/351 [04:15<05:26,  1.66s/it]\u001b[A\n",
            "Iteration:  44% 155/351 [04:16<05:24,  1.65s/it]\u001b[A\n",
            "Iteration:  44% 156/351 [04:18<05:24,  1.66s/it]\u001b[A\n",
            "Iteration:  45% 157/351 [04:20<05:22,  1.66s/it]\u001b[A\n",
            "Iteration:  45% 158/351 [04:21<05:21,  1.67s/it]\u001b[A\n",
            "Iteration:  45% 159/351 [04:23<05:20,  1.67s/it]\u001b[A\n",
            "Iteration:  46% 160/351 [04:25<05:19,  1.67s/it]\u001b[A\n",
            "Iteration:  46% 161/351 [04:26<05:15,  1.66s/it]\u001b[A\n",
            "Iteration:  46% 162/351 [04:28<05:15,  1.67s/it]\u001b[A\n",
            "Iteration:  46% 163/351 [04:30<05:12,  1.66s/it]\u001b[A\n",
            "Iteration:  47% 164/351 [04:31<05:10,  1.66s/it]\u001b[A\n",
            "Iteration:  47% 165/351 [04:33<05:08,  1.66s/it]\u001b[A\n",
            "Iteration:  47% 166/351 [04:35<05:07,  1.66s/it]\u001b[A\n",
            "Iteration:  48% 167/351 [04:36<05:05,  1.66s/it]\u001b[A\n",
            "Iteration:  48% 168/351 [04:38<05:02,  1.66s/it]\u001b[A\n",
            "Iteration:  48% 169/351 [04:40<05:02,  1.66s/it]\u001b[A\n",
            "Iteration:  48% 170/351 [04:41<05:01,  1.66s/it]\u001b[A\n",
            "Iteration:  49% 171/351 [04:43<04:59,  1.66s/it]\u001b[A\n",
            "Iteration:  49% 172/351 [04:45<04:56,  1.66s/it]\u001b[A\n",
            "Iteration:  49% 173/351 [04:46<04:55,  1.66s/it]\u001b[A\n",
            "Iteration:  50% 174/351 [04:48<04:53,  1.66s/it]\u001b[A\n",
            "Iteration:  50% 175/351 [04:50<04:52,  1.66s/it]\u001b[A\n",
            "Iteration:  50% 176/351 [04:51<04:50,  1.66s/it]\u001b[A\n",
            "Iteration:  50% 177/351 [04:53<04:49,  1.66s/it]\u001b[A\n",
            "Iteration:  51% 178/351 [04:55<04:46,  1.65s/it]\u001b[A\n",
            "Iteration:  51% 179/351 [04:56<04:44,  1.66s/it]\u001b[A\n",
            "Iteration:  51% 180/351 [04:58<04:44,  1.66s/it]\u001b[A\n",
            "Iteration:  52% 181/351 [05:00<04:40,  1.65s/it]\u001b[A\n",
            "Iteration:  52% 182/351 [05:01<04:38,  1.65s/it]\u001b[A\n",
            "Iteration:  52% 183/351 [05:03<04:38,  1.66s/it]\u001b[A\n",
            "Iteration:  52% 184/351 [05:05<04:36,  1.66s/it]\u001b[A\n",
            "Iteration:  53% 185/351 [05:06<04:34,  1.65s/it]\u001b[A\n",
            "Iteration:  53% 186/351 [05:08<04:32,  1.65s/it]\u001b[A\n",
            "Iteration:  53% 187/351 [05:09<04:30,  1.65s/it]\u001b[A\n",
            "Iteration:  54% 188/351 [05:11<04:27,  1.64s/it]\u001b[A\n",
            "Iteration:  54% 189/351 [05:13<04:26,  1.65s/it]\u001b[A\n",
            "Iteration:  54% 190/351 [05:14<04:25,  1.65s/it]\u001b[A\n",
            "Iteration:  54% 191/351 [05:16<04:23,  1.65s/it]\u001b[A\n",
            "Iteration:  55% 192/351 [05:18<04:22,  1.65s/it]\u001b[A\n",
            "Iteration:  55% 193/351 [05:19<04:20,  1.65s/it]\u001b[A\n",
            "Iteration:  55% 194/351 [05:21<04:18,  1.65s/it]\u001b[A\n",
            "Iteration:  56% 195/351 [05:23<04:17,  1.65s/it]\u001b[A\n",
            "Iteration:  56% 196/351 [05:24<04:17,  1.66s/it]\u001b[A\n",
            "Iteration:  56% 197/351 [05:26<04:14,  1.65s/it]\u001b[A\n",
            "Iteration:  56% 198/351 [05:28<04:12,  1.65s/it]\u001b[A{\"learning_rate\": 2.1652421652421653e-05, \"loss\": 0.680016334950924, \"step\": 550}\n",
            "\n",
            "Iteration:  57% 199/351 [05:29<04:10,  1.65s/it]\u001b[A\n",
            "Iteration:  57% 200/351 [05:31<04:09,  1.65s/it]\u001b[A\n",
            "Iteration:  57% 201/351 [05:33<04:07,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 202/351 [05:34<04:06,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 203/351 [05:36<04:04,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 204/351 [05:38<04:03,  1.65s/it]\u001b[A\n",
            "Iteration:  58% 205/351 [05:39<04:00,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 206/351 [05:41<03:59,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 207/351 [05:42<03:57,  1.65s/it]\u001b[A\n",
            "Iteration:  59% 208/351 [05:44<03:57,  1.66s/it]\u001b[A\n",
            "Iteration:  60% 209/351 [05:46<03:55,  1.66s/it]\u001b[A\n",
            "Iteration:  60% 210/351 [05:47<03:54,  1.66s/it]\u001b[A\n",
            "Iteration:  60% 211/351 [05:49<03:52,  1.66s/it]\u001b[A\n",
            "Iteration:  60% 212/351 [05:51<03:50,  1.66s/it]\u001b[A\n",
            "Iteration:  61% 213/351 [05:52<03:48,  1.66s/it]\u001b[A\n",
            "Iteration:  61% 214/351 [05:54<03:47,  1.66s/it]\u001b[A\n",
            "Iteration:  61% 215/351 [05:56<03:46,  1.66s/it]\u001b[A\n",
            "Iteration:  62% 216/351 [05:57<03:43,  1.66s/it]\u001b[A\n",
            "Iteration:  62% 217/351 [05:59<03:43,  1.67s/it]\u001b[A\n",
            "Iteration:  62% 218/351 [06:01<03:40,  1.66s/it]\u001b[A\n",
            "Iteration:  62% 219/351 [06:02<03:38,  1.65s/it]\u001b[A\n",
            "Iteration:  63% 220/351 [06:04<03:36,  1.65s/it]\u001b[A\n",
            "Iteration:  63% 221/351 [06:06<03:34,  1.65s/it]\u001b[A\n",
            "Iteration:  63% 222/351 [06:07<03:32,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 223/351 [06:09<03:30,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 224/351 [06:11<03:28,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 225/351 [06:12<03:27,  1.65s/it]\u001b[A\n",
            "Iteration:  64% 226/351 [06:14<03:25,  1.65s/it]\u001b[A\n",
            "Iteration:  65% 227/351 [06:16<03:25,  1.66s/it]\u001b[A\n",
            "Iteration:  65% 228/351 [06:17<03:23,  1.65s/it]\u001b[A\n",
            "Iteration:  65% 229/351 [06:19<03:21,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 230/351 [06:21<03:20,  1.66s/it]\u001b[A\n",
            "Iteration:  66% 231/351 [06:22<03:18,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 232/351 [06:24<03:16,  1.65s/it]\u001b[A\n",
            "Iteration:  66% 233/351 [06:25<03:14,  1.65s/it]\u001b[A\n",
            "Iteration:  67% 234/351 [06:27<03:12,  1.64s/it]\u001b[A\n",
            "Iteration:  67% 235/351 [06:29<03:11,  1.65s/it]\u001b[A\n",
            "Iteration:  67% 236/351 [06:30<03:09,  1.65s/it]\u001b[A\n",
            "Iteration:  68% 237/351 [06:32<03:07,  1.65s/it]\u001b[A\n",
            "Iteration:  68% 238/351 [06:34<03:06,  1.65s/it]\u001b[A\n",
            "Iteration:  68% 239/351 [06:35<03:05,  1.66s/it]\u001b[A\n",
            "Iteration:  68% 240/351 [06:37<03:04,  1.66s/it]\u001b[A\n",
            "Iteration:  69% 241/351 [06:39<03:02,  1.66s/it]\u001b[A\n",
            "Iteration:  69% 242/351 [06:40<03:01,  1.66s/it]\u001b[A\n",
            "Iteration:  69% 243/351 [06:42<02:59,  1.66s/it]\u001b[A\n",
            "Iteration:  70% 244/351 [06:44<02:57,  1.66s/it]\u001b[A\n",
            "Iteration:  70% 245/351 [06:45<02:56,  1.66s/it]\u001b[A\n",
            "Iteration:  70% 246/351 [06:47<02:55,  1.67s/it]\u001b[A\n",
            "Iteration:  70% 247/351 [06:49<02:53,  1.66s/it]\u001b[A\n",
            "Iteration:  71% 248/351 [06:50<02:51,  1.66s/it]\u001b[A{\"learning_rate\": 1.4529914529914531e-05, \"loss\": 0.702691405415535, \"step\": 600}\n",
            "\n",
            "Iteration:  71% 249/351 [06:52<02:49,  1.66s/it]\u001b[A\n",
            "Iteration:  71% 250/351 [06:54<02:47,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 251/351 [06:55<02:45,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 252/351 [06:57<02:44,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 253/351 [06:59<02:42,  1.66s/it]\u001b[A\n",
            "Iteration:  72% 254/351 [07:00<02:41,  1.66s/it]\u001b[A\n",
            "Iteration:  73% 255/351 [07:02<02:39,  1.66s/it]\u001b[A\n",
            "Iteration:  73% 256/351 [07:04<02:37,  1.66s/it]\u001b[A\n",
            "Iteration:  73% 257/351 [07:05<02:36,  1.66s/it]\u001b[A\n",
            "Iteration:  74% 258/351 [07:07<02:34,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 259/351 [07:09<02:33,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 260/351 [07:10<02:31,  1.67s/it]\u001b[A\n",
            "Iteration:  74% 261/351 [07:12<02:29,  1.66s/it]\u001b[A\n",
            "Iteration:  75% 262/351 [07:14<02:28,  1.67s/it]\u001b[A\n",
            "Iteration:  75% 263/351 [07:15<02:26,  1.66s/it]\u001b[A\n",
            "Iteration:  75% 264/351 [07:17<02:24,  1.66s/it]\u001b[A\n",
            "Iteration:  75% 265/351 [07:19<02:22,  1.66s/it]\u001b[A\n",
            "Iteration:  76% 266/351 [07:20<02:21,  1.66s/it]\u001b[A\n",
            "Iteration:  76% 267/351 [07:22<02:19,  1.66s/it]\u001b[A\n",
            "Iteration:  76% 268/351 [07:24<02:18,  1.66s/it]\u001b[A\n",
            "Iteration:  77% 269/351 [07:25<02:15,  1.66s/it]\u001b[A\n",
            "Iteration:  77% 270/351 [07:27<02:14,  1.66s/it]\u001b[A\n",
            "Iteration:  77% 271/351 [07:29<02:12,  1.65s/it]\u001b[A\n",
            "Iteration:  77% 272/351 [07:30<02:10,  1.65s/it]\u001b[A\n",
            "Iteration:  78% 273/351 [07:32<02:08,  1.65s/it]\u001b[A\n",
            "Iteration:  78% 274/351 [07:34<02:06,  1.65s/it]\u001b[A\n",
            "Iteration:  78% 275/351 [07:35<02:05,  1.64s/it]\u001b[A\n",
            "Iteration:  79% 276/351 [07:37<02:04,  1.65s/it]\u001b[A\n",
            "Iteration:  79% 277/351 [07:38<02:01,  1.65s/it]\u001b[A\n",
            "Iteration:  79% 278/351 [07:40<02:00,  1.65s/it]\u001b[A\n",
            "Iteration:  79% 279/351 [07:42<01:58,  1.64s/it]\u001b[A\n",
            "Iteration:  80% 280/351 [07:43<01:56,  1.64s/it]\u001b[A\n",
            "Iteration:  80% 281/351 [07:45<01:55,  1.64s/it]\u001b[A\n",
            "Iteration:  80% 282/351 [07:47<01:53,  1.64s/it]\u001b[A\n",
            "Iteration:  81% 283/351 [07:48<01:51,  1.64s/it]\u001b[A\n",
            "Iteration:  81% 284/351 [07:50<01:49,  1.64s/it]\u001b[A\n",
            "Iteration:  81% 285/351 [07:52<01:48,  1.64s/it]\u001b[A\n",
            "Iteration:  81% 286/351 [07:53<01:46,  1.64s/it]\u001b[A\n",
            "Iteration:  82% 287/351 [07:55<01:45,  1.64s/it]\u001b[A\n",
            "Iteration:  82% 288/351 [07:57<01:43,  1.64s/it]\u001b[A\n",
            "Iteration:  82% 289/351 [07:58<01:41,  1.64s/it]\u001b[A\n",
            "Iteration:  83% 290/351 [08:00<01:40,  1.65s/it]\u001b[A\n",
            "Iteration:  83% 291/351 [08:01<01:39,  1.65s/it]\u001b[A\n",
            "Iteration:  83% 292/351 [08:03<01:37,  1.65s/it]\u001b[A\n",
            "Iteration:  83% 293/351 [08:05<01:35,  1.65s/it]\u001b[A\n",
            "Iteration:  84% 294/351 [08:06<01:33,  1.65s/it]\u001b[A\n",
            "Iteration:  84% 295/351 [08:08<01:32,  1.65s/it]\u001b[A\n",
            "Iteration:  84% 296/351 [08:10<01:30,  1.64s/it]\u001b[A\n",
            "Iteration:  85% 297/351 [08:11<01:29,  1.66s/it]\u001b[A\n",
            "Iteration:  85% 298/351 [08:13<01:27,  1.65s/it]\u001b[A{\"learning_rate\": 7.4074074074074075e-06, \"loss\": 0.6615382570028305, \"step\": 650}\n",
            "\n",
            "Iteration:  85% 299/351 [08:15<01:25,  1.65s/it]\u001b[A\n",
            "Iteration:  85% 300/351 [08:16<01:24,  1.66s/it]\u001b[A\n",
            "Iteration:  86% 301/351 [08:18<01:22,  1.65s/it]\u001b[A\n",
            "Iteration:  86% 302/351 [08:20<01:20,  1.65s/it]\u001b[A\n",
            "Iteration:  86% 303/351 [08:21<01:19,  1.66s/it]\u001b[A\n",
            "Iteration:  87% 304/351 [08:23<01:18,  1.66s/it]\u001b[A\n",
            "Iteration:  87% 305/351 [08:25<01:16,  1.67s/it]\u001b[A\n",
            "Iteration:  87% 306/351 [08:26<01:15,  1.67s/it]\u001b[A\n",
            "Iteration:  87% 307/351 [08:28<01:13,  1.66s/it]\u001b[A\n",
            "Iteration:  88% 308/351 [08:30<01:11,  1.66s/it]\u001b[A\n",
            "Iteration:  88% 309/351 [08:31<01:10,  1.67s/it]\u001b[A\n",
            "Iteration:  88% 310/351 [08:33<01:08,  1.66s/it]\u001b[A\n",
            "Iteration:  89% 311/351 [08:35<01:06,  1.67s/it]\u001b[A\n",
            "Iteration:  89% 312/351 [08:36<01:04,  1.66s/it]\u001b[A\n",
            "Iteration:  89% 313/351 [08:38<01:03,  1.67s/it]\u001b[A\n",
            "Iteration:  89% 314/351 [08:40<01:01,  1.67s/it]\u001b[A\n",
            "Iteration:  90% 315/351 [08:41<01:00,  1.68s/it]\u001b[A\n",
            "Iteration:  90% 316/351 [08:43<00:58,  1.68s/it]\u001b[A\n",
            "Iteration:  90% 317/351 [08:45<00:56,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 318/351 [08:46<00:55,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 319/351 [08:48<00:53,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 320/351 [08:50<00:51,  1.67s/it]\u001b[A\n",
            "Iteration:  91% 321/351 [08:51<00:50,  1.67s/it]\u001b[A\n",
            "Iteration:  92% 322/351 [08:53<00:48,  1.67s/it]\u001b[A\n",
            "Iteration:  92% 323/351 [08:55<00:46,  1.66s/it]\u001b[A\n",
            "Iteration:  92% 324/351 [08:56<00:44,  1.66s/it]\u001b[A\n",
            "Iteration:  93% 325/351 [08:58<00:43,  1.66s/it]\u001b[A\n",
            "Iteration:  93% 326/351 [09:00<00:41,  1.67s/it]\u001b[A\n",
            "Iteration:  93% 327/351 [09:01<00:40,  1.67s/it]\u001b[A\n",
            "Iteration:  93% 328/351 [09:03<00:38,  1.67s/it]\u001b[A\n",
            "Iteration:  94% 329/351 [09:05<00:36,  1.67s/it]\u001b[A\n",
            "Iteration:  94% 330/351 [09:06<00:35,  1.67s/it]\u001b[A\n",
            "Iteration:  94% 331/351 [09:08<00:33,  1.67s/it]\u001b[A\n",
            "Iteration:  95% 332/351 [09:10<00:31,  1.66s/it]\u001b[A\n",
            "Iteration:  95% 333/351 [09:11<00:29,  1.66s/it]\u001b[A\n",
            "Iteration:  95% 334/351 [09:13<00:28,  1.66s/it]\u001b[A\n",
            "Iteration:  95% 335/351 [09:15<00:26,  1.67s/it]\u001b[A\n",
            "Iteration:  96% 336/351 [09:16<00:24,  1.66s/it]\u001b[A\n",
            "Iteration:  96% 337/351 [09:18<00:23,  1.66s/it]\u001b[A\n",
            "Iteration:  96% 338/351 [09:20<00:21,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 339/351 [09:21<00:19,  1.66s/it]\u001b[A\n",
            "Iteration:  97% 340/351 [09:23<00:18,  1.65s/it]\u001b[A\n",
            "Iteration:  97% 341/351 [09:25<00:16,  1.65s/it]\u001b[A\n",
            "Iteration:  97% 342/351 [09:26<00:14,  1.65s/it]\u001b[A\n",
            "Iteration:  98% 343/351 [09:28<00:13,  1.65s/it]\u001b[A\n",
            "Iteration:  98% 344/351 [09:30<00:11,  1.65s/it]\u001b[A\n",
            "Iteration:  98% 345/351 [09:31<00:10,  1.67s/it]\u001b[A\n",
            "Iteration:  99% 346/351 [09:33<00:08,  1.66s/it]\u001b[A\n",
            "Iteration:  99% 347/351 [09:35<00:06,  1.67s/it]\u001b[A\n",
            "Iteration:  99% 348/351 [09:36<00:04,  1.66s/it]\u001b[A{\"learning_rate\": 2.8490028490028494e-07, \"loss\": 0.6942309594154358, \"step\": 700}\n",
            "\n",
            "Iteration:  99% 349/351 [09:38<00:03,  1.67s/it]\u001b[A\n",
            "Iteration: 100% 350/351 [09:40<00:01,  1.66s/it]\u001b[A\n",
            "Iteration: 100% 351/351 [09:40<00:00,  1.65s/it]\n",
            "Epoch: 100% 2/2 [19:14<00:00, 577.18s/it]\n",
            "06/05/2021 05:06:25 - INFO - __main__ -    global_step = 702, average loss = 0.9353833923227767\n",
            "06/05/2021 05:06:25 - INFO - utils_ichi -   Creating features from dataset file at ./new_data\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   Writing example 0/3000\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   guid: dev-1\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_global_ids: 101 17938 19067 1029 1029 1029 7632 2035 999 1045 2572 2047 2182 2021 2031 2042 24261 2005 2070 2051 1012 2026 26319 2024 1024 3287 3429 1061 2869 1010 1044 25465 2828 2028 1010 10372 2220 3770 102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_local_ids: 101 17938 19067 1029 1029 1029 7632 2035 999 1045 2572 2047 2182 2021 2031 2042 24261 2005 2070 2051 1012 2026 26319 2024 1024 3287 3429 1061 2869 1010 1044 25465 2828 2028 1010 10372 2220 3770 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8397 3389 288 180 2277 1 84 20002 241 7 9360 7230 732 1345 5439 20002 296 1379 1970 266 2819\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   label: DISE (id = 1)\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   guid: dev-2\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_global_ids: 101 13408 12436 20876 17962 2026 6513 1998 1045 2074 2288 2083 2383 3348 1998 2014 17962 2024 2200 13408 2054 2071 2023 2022 2013 1029 2054 2064 2057 2079 2000 2131 1996 18348 2091 1029 102 19117 21166 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_local_ids: 101 13408 12436 20876 17962 2026 6513 1998 1045 2074 2288 2083 2383 3348 1998 2014 17962 2024 2200 13408 2054 2071 2023 2022 2013 1029 2054 2064 2057 2079 2000 2131 1996 18348 2091 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 349 468 8118 7 839 43 67 8118 349 14 6245 3 570 8680\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   aspect_indices: 19117 21166 2015 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   label: SOCL (id = 6)\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   guid: dev-3\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_global_ids: 101 5255 3756 2159 2852 1012 1045 2031 6530 3756 21122 2075 2159 2144 2026 9458 2287 1012 2021 2049 2893 2524 1998 2524 1012 2004 1045 1044 3726 9015 2919 6322 1997 2166 2066 2192 3218 1010 28144 21939 2050 1012 1012 1012 1012 1012 2000 2172 2021 1045 2123 1005 1056 2031 2023 5292 10322 4183 2085 1998 28144 21939 2050 2003 2036 2031 2908 1012 2021 2026 2159 2024 3756 1012 1998 1045 2371 2009 2062 2919 4650 2012 2026 2305 2991 2051 1012 2043 1045 2131 2305 2991 2059 2023 3663 2131 2172 2062 2021 2044 1016 2420 2043 1045 2202 2300 2005 5948 2260 2000 2403 3221 2566 2154 2059 2009 2089 2022 5547 1012 1012 1012 1012 1012 1012 1012 1012 1012 20228 2480 12367 2033 2055 2023 4078 19500 5685 3949 1012 2097 2022 2428 18836 2000 2017 102 19117 21166 2015 102 3968 14194 3508 102 12411 6499 5649 8346 102 2030 22415 102 2157 3239 21273 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_local_ids: 101 5255 3756 2159 2852 1012 1045 2031 6530 3756 21122 2075 2159 2144 2026 9458 2287 1012 2021 2049 2893 2524 1998 2524 1012 2004 1045 1044 3726 9015 2919 6322 1997 2166 2066 2192 3218 1010 28144 21939 2050 1012 1012 1012 1012 1012 2000 2172 2021 1045 2123 1005 1056 2031 2023 5292 10322 4183 2085 1998 28144 21939 2050 2003 2036 2031 2908 1012 2021 2026 2159 2024 3756 1012 1998 1045 2371 2009 2062 2919 4650 2012 2026 2305 2991 2051 1012 2043 1045 2131 2305 2991 2059 2023 3663 2131 2172 2062 2021 2044 1016 2420 2043 1045 2202 2300 2005 5948 2260 2000 2403 3221 2566 2154 2059 2009 2089 2022 5547 1012 1012 1012 1012 1012 1012 1012 1012 1012 20228 2480 12367 2033 2055 2023 4078 19500 5685 3949 1012 2097 2022 2428 18836 2000 2017 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 629 1439 32 392 3751 1439 20002 32 35 2027 1956 65 155 20002 20002 1037 103 388 160 4 283 20002 57 20002 20002 16 2567 32 20002 179 103 922 7 121 669 20002 3 121 669 619 3 57 28 5 34 517 845 415 752 754 719 5 93 20002 1501 4967 20002 20002 26 4820\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   aspect_indices: 19117 21166 2015 3968 14194 3508 12411 6499 5649 8346 2030 22415 2157 3239 21273 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   label: GOAL (id = 3)\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   guid: dev-4\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_global_ids: 101 4319 3231 1998 1059 2015 7632 1010 1037 2261 6385 3283 1045 2253 2000 1037 5637 3348 20464 12083 1998 5117 1999 5949 2869 25378 1012 1045 10749 21392 2013 1037 3232 1997 4364 1012 1999 1037 2261 2420 1045 2707 1037 2047 3105 1012 2065 1045 2131 1037 4319 3231 1010 2003 2009 2825 2009 2097 2265 2039 3893 2065 1996 2060 4364 2018 2579 1999 5850 1012 1045 2123 1005 1056 2079 5850 1010 2196 2031 1012 102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_local_ids: 101 4319 3231 1998 1059 2015 7632 1010 1037 2261 6385 3283 1045 2253 2000 1037 5637 3348 20464 12083 1998 5117 1999 5949 2869 25378 1012 1045 10749 21392 2013 1037 3232 1997 4364 1012 1999 1037 2261 2420 1045 2707 1037 2047 3105 1012 2065 1045 2131 1037 4319 3231 1010 2003 2009 2825 2009 2097 2265 2039 3893 2065 1996 2060 4364 2018 2579 1999 5850 1012 1045 2123 1005 1056 2079 5850 1010 2196 2031 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 384 64 2733 568 121 79 1 48 1499 20002 3991 20002 1 3176 814 189 8441 167 5 1 115 84 4317 136 1 3 384 1853 222 264 412 413 227 5216 1 3394 54 2268\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   aspect_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   label: SOCL (id = 6)\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   *** Example ***\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   guid: dev-5\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_global_ids: 101 1018 2095 2214 2003 2041 1997 2491 2026 1018 2095 2214 2003 1037 10103 1012 2033 1998 2026 3129 2147 2440 2051 1010 2061 1999 1996 2851 2002 2038 2000 2175 2000 2082 1012 2002 2196 4122 2000 2131 5102 1010 2057 2954 2007 2032 2296 2851 1998 2009 2003 2061 2524 2000 2131 2000 2147 2006 2051 2296 2154 999 1996 2851 4627 2007 7491 16142 1998 2049 9643 1012 2002 2097 2707 15209 4303 1010 6886 2477 1012 2002 3504 2005 2477 2000 5466 1012 2002 7807 2673 999 2057 2031 2000 26470 2032 2007 10899 2000 2175 2000 2082 1998 2008 4510 2573 4902 1012 2002 2003 2074 2061 14205 1012 2002 2074 6732 2002 2003 1037 2332 1998 3071 2323 6812 2000 2032 1012 2002 2003 2066 1037 28561 2051 5968 1012 2002 2064 2022 2204 2059 2074 10245 1999 2019 6013 1012 1045 2228 2002 2038 5177 3314 1012 2002 4152 2061 2919 2008 2026 3129 2038 2000 2907 2032 2091 2096 2002 2003 6886 2010 9092 24456 2015 1012 2023 2038 2042 2183 2006 2005 2058 1037 2095 2085 1012 2002 2003 2074 1037 3697 2775 1010 2200 9694 1012 3071 2758 2002 2003 1037 3671 1018 2095 2214 2021 1045 11693 2000 11234 1012 3531 2393 999 2130 2026 3129 2758 2002 2003 3671 2005 2010 2287 1012 2057 2024 102 19117 21166 2015 102 3968 14194 3508 102 12411 6499 5649 8346 102 2030 22415 102 2157 3239 21273 102 2273 2075 18994 2050 102 26847 102\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_global: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_global_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   input_local_ids: 101 1018 2095 2214 2003 2041 1997 2491 2026 1018 2095 2214 2003 1037 10103 1012 2033 1998 2026 3129 2147 2440 2051 1010 2061 1999 1996 2851 2002 2038 2000 2175 2000 2082 1012 2002 2196 4122 2000 2131 5102 1010 2057 2954 2007 2032 2296 2851 1998 2009 2003 2061 2524 2000 2131 2000 2147 2006 2051 2296 2154 999 1996 2851 4627 2007 7491 16142 1998 2049 9643 1012 2002 2097 2707 15209 4303 1010 6886 2477 1012 2002 3504 2005 2477 2000 5466 1012 2002 7807 2673 999 2057 2031 2000 26470 2032 2007 10899 2000 2175 2000 2082 1998 2008 4510 2573 4902 1012 2002 2003 2074 2061 14205 1012 2002 2074 6732 2002 2003 1037 2332 1998 3071 2323 6812 2000 2032 1012 2002 2003 2066 1037 28561 2051 5968 1012 2002 2064 2022 2204 2059 2074 10245 1999 2019 6013 1012 1045 2228 2002 2038 5177 3314 1012 2002 4152 2061 2919 2008 2026 3129 2038 2000 2907 2032 2091 2096 2002 2003 6886 2010 9092 24456 2015 1012 2023 2038 2042 2183 2006 2005 2058 1037 2095 2085 1012 2002 2003 2074 1037 3697 2775 1010 2200 9694 1012 3071 2758 2002 2003 1037 3671 1018 2095 2214 2021 1045 11693 2000 11234 1012 3531 2393 999 2130 2026 3129 2758 2002 2003 3671 2005 2010 2287 1012 2057 2024 2061 13233 2035 1996 2051 2008 2057 2064 2102 3524 2005 2032 2000 4982 2039 999 999 999 999 102 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   attention_mask_local: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   token_local_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   text_clean_indices: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 70 2 13 273 70 2 13 9285 135 91 383 342 215 18 640 54 23 3 20002 1154 76 215 155 3 91 9 76 5385 215 115 1230 894 8110 115 8241 12927 1205 1017 106 47 20002 580 5766 20002 901 18 113 1201 91 964 16007 37 6325 369 10414 249 4 20002 9 20002 75 7044 20002 37 968 1321 3 103 135 639 1205 6946 39 2 272 637 1494 16225 369 49 72 70 2 13 9288 20002 59 382 33 135 49 72 1956 1268 9 246 343 860 5183\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   aspect_indices: 19117 21166 2015 3968 14194 3508 12411 6499 5649 8346 2030 22415 2157 3239 21273 2273 2075 18994 2050 26847 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/05/2021 05:07:04 - INFO - utils_ichi -   label: FAML (id = 5)\n",
            "06/05/2021 05:07:24 - INFO - utils_ichi -   Saving features into cached file ./new_data/cached_dev_bert-base-uncased_256_ichi\n",
            "06/05/2021 05:07:26 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/05/2021 05:07:26 - INFO - __main__ -     Num examples = 3000\n",
            "06/05/2021 05:07:26 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [01:51<00:00,  1.69it/s]\n",
            "06/05/2021 05:09:17 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/05/2021 05:09:17 - INFO - __main__ -     acc = 0.6796666666666666\n",
            "06/05/2021 05:09:17 - INFO - __main__ -     f1 = 0.6799629203878096\n",
            "06/05/2021 05:09:17 - INFO - __main__ -   Saving model checkpoint to ./tmp/ichi_bert_base_new\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "06/05/2021 05:09:22 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "loading tokenizer from cache: ./new_data/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "06/05/2021 05:09:22 - INFO - __main__ -   Evaluate the following checkpoints: ['./tmp/ichi_bert_base_new']\n",
            "06/05/2021 05:09:25 - INFO - utils_ichi -   Loading features from cached file ./new_data/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./new_data/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "06/05/2021 05:09:27 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/05/2021 05:09:27 - INFO - __main__ -     Num examples = 3000\n",
            "06/05/2021 05:09:27 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [01:51<00:00,  1.69it/s]\n",
            "06/05/2021 05:11:18 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/05/2021 05:11:18 - INFO - __main__ -     acc = 0.6796666666666666\n",
            "06/05/2021 05:11:18 - INFO - __main__ -     f1 = 0.6799629203878096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H01TYmyzS8n4",
        "outputId": "f9d21d2d-8aa7-421d-f825-eaef41bd79a1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  5 05:11:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    42W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlJzq0GsRjF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11ukVnhuyD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9QFTiYbc0nA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}